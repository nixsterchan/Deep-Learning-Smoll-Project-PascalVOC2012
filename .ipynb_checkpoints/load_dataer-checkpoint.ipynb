{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "from sklearn.metrics import average_precision_score\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import FiveCrop, ToTensor, Lambda, Compose, CenterCrop, Normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PascalVOC:\n",
    "    \"\"\"\n",
    "    Handle Pascal VOC dataset\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir):\n",
    "        \"\"\"\n",
    "        Summary: \n",
    "            Init the class with root dir\n",
    "        Args:\n",
    "            root_dir (string): path to your voc dataset\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.img_dir =  os.path.join(root_dir, 'JPEGImages/')\n",
    "        self.ann_dir = os.path.join(root_dir, 'Annotations')\n",
    "        self.set_dir = os.path.join(root_dir, 'ImageSets', 'Main')\n",
    "        self.cache_dir = os.path.join(root_dir, 'csvs')\n",
    "        if not os.path.exists(self.cache_dir):\n",
    "            os.makedirs(self.cache_dir)\n",
    "\n",
    "    def list_image_sets(self):\n",
    "        \"\"\"\n",
    "        Summary: \n",
    "            List all the image sets from Pascal VOC. Don't bother computing\n",
    "            this on the fly, just remember it. It's faster.\n",
    "        \"\"\"\n",
    "        return [\n",
    "            'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "            'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "            'cow', 'diningtable', 'dog', 'horse',\n",
    "            'motorbike', 'person', 'pottedplant',\n",
    "            'sheep', 'sofa', 'train',\n",
    "            'tvmonitor']\n",
    "\n",
    "    def _imgs_from_category(self, cat_name, dataset):\n",
    "        \"\"\"\n",
    "        Summary: \n",
    "        Args:\n",
    "            cat_name (string): Category name as a string (from list_image_sets())\n",
    "            dataset (string): \"train\", \"val\", \"train_val\", or \"test\" (if available)\n",
    "        Returns:\n",
    "            pandas dataframe: pandas DataFrame of all filenames from that category\n",
    "        \"\"\"\n",
    "        filename = os.path.join(self.set_dir, cat_name + \"_\" + dataset + \".txt\")\n",
    "        df = pd.read_csv(\n",
    "            filename,\n",
    "            delim_whitespace=True,\n",
    "            header=None,\n",
    "            names=['filename', cat_name])\n",
    "        return df\n",
    "\n",
    "    def imgs_from_category_as_list(self, cat_name, dataset):\n",
    "        \"\"\"\n",
    "        Summary: \n",
    "            Get a list of filenames for images in a particular category\n",
    "            as a list rather than a pandas dataframe.\n",
    "        Args:\n",
    "            cat_name (string): Category name as a string (from list_image_sets())\n",
    "            dataset (string): \"train\", \"val\", \"train_val\", or \"test\" (if available)\n",
    "        Returns:\n",
    "            list of srings: all filenames from that category\n",
    "        \"\"\"\n",
    "        df = self._imgs_from_category(cat_name, dataset)\n",
    "#         df = df[df['true'] == 1]\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandsomeBinderNet(Dataset):\n",
    "#     def __init__(self, img_root, ins_label_pairs , crop_size, transform=None):\n",
    "    def __init__(self, img_root, classes, pvc, dataset_type, transform=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        img_root: contains the path to the image root folder\n",
    "        ins_label_pairs: instance label pair that contains a list of all the image path names and their respective labels\n",
    "        crop_size: contains desired crop dimensions\n",
    "        transform: contains the transformation procedures to be applied. defaulted to be None\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.img_root = img_root\n",
    "        self.transform = transform\n",
    "        self.classes = classes\n",
    "        self.pvc = pvc\n",
    "        self.dataset_type = dataset_type\n",
    "        self.ins_label_pairs = self.instance_label_prep(self.classes, self.pvc, self.dataset_type)\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.ins_label_pairs)\n",
    "    \n",
    "    def image_load(self, image_path):\n",
    "        # Open image and load\n",
    "        img = (Image.open(image_path))\n",
    "        img.load()\n",
    "        \n",
    "        img = np.array(img)\n",
    "        if len(img.shape) == 2:\n",
    "            img = np.expand_dims(img, 2)\n",
    "            img = np.repeat(img, 3, 2)\n",
    "            \n",
    "        return Image.fromarray(img)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # Path to the image\n",
    "        image_path = self.img_root + self.ins_label_pairs[index][0] + '.jpg'\n",
    "        \n",
    "        # Open the image\n",
    "        image = self.image_load(image_path)\n",
    "        label = torch.from_numpy((self.ins_label_pairs[index][1]).astype(float))\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return [image, label]\n",
    "    \n",
    "    \n",
    "    def instance_label_prep(self, classes, pvc, dataset_type):\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        classes: a list containing the classes used\n",
    "        pvc: pascalVOC object\n",
    "        dataset_type: train, trainval or val\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Get a dataframe from within the pascalVOC dataset. It will be in a one hot encoding fashion\n",
    "        final_df = None\n",
    "\n",
    "        # Loop through each different class to get each image's classes\n",
    "        for index, x in enumerate(classes):\n",
    "            cat_name = x # category name\n",
    "\n",
    "            df = pvc.imgs_from_category_as_list(cat_name, dataset_type)\n",
    "            df[x] = df[x].replace(-1, 0)\n",
    "\n",
    "            # For the first category, we use its dataframe as the base\n",
    "            if index == 0:\n",
    "                final_df = df\n",
    "            # And merge with the rest of the following categories\n",
    "            else:        \n",
    "                final_df = final_df.merge(df, on='filename', how='inner')\n",
    "\n",
    "        # Here we get each image name and their respective labels (one hot encoding format) and store in a list\n",
    "        df_np = final_df.to_numpy()\n",
    "\n",
    "        ins_labels = []\n",
    "        for x in df_np:\n",
    "            ins_labels.append([x[0], x[1:]])\n",
    "\n",
    "        return ins_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable',\n",
    "            'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "pvc = PascalVOC('VOC2012')\n",
    "imgpath = 'VOC2012/JPEGImages/'\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')    \n",
    "tr = transforms.Compose([transforms.RandomResizedCrop(300),\n",
    "                             transforms.ToTensor(),\n",
    "                             transforms.Normalize([0.4589, 0.4355, 0.4032],[0.2239, 0.2186, 0.2206])])\n",
    "\n",
    "# Create datasets and respective dataloaders\n",
    "\n",
    "train_dataset = HandsomeBinderNet(imgpath, class_list, pvc, 'train', transform=tr)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "val_dataset = HandsomeBinderNet(imgpath, class_list, pvc, 'trainval', transform=tr)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "test_dataset = HandsomeBinderNet(imgpath, class_list, pvc, 'val', transform=tr)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(512, 20)\n",
    "model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
    "loss_fun = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, device, train_loader, optimizer, num_epochs, val_loader, loss_fun):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss = train(model, device, train_loader, optimizer, epoch, loss_fun)\n",
    "        val_loss, predictions, targets = validate(model, device, val_loader, epoch, loss_fun)\n",
    "\n",
    "#         if (len(val_losses) > 0) and (val_loss < min(val_losses)):\n",
    "#             torch.save(model.state_dict(), \"best_model_B.pt\")\n",
    "#             print(\"Saving model (epoch {}) with lowest validation loss: {}\"\n",
    "#                   .format(epoch, val_loss))\n",
    "\n",
    "#         train_losses.append(train_loss)\n",
    "#         val_losses.append(val_loss)\n",
    "#         val_accuracies.append(val_accuracy)\n",
    "\n",
    "    print(\"Training and validation complete.\")\n",
    "    return train_losses, val_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, loss_fun):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for idx, batch in enumerate(train_loader):\n",
    "        data = batch[0].to(device)\n",
    "        target = batch[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "#         print(target, torch.sigmoid(output))\n",
    "        loss = loss_fun(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "        if idx % 5 == 0:\n",
    "            print('Epoch: {}, Training_Samples: {}/{}, Loss: {}'.format(epoch, idx, len(train_loader), loss.item()))\n",
    "    train_loss = torch.mean(torch.tensor(train_losses))\n",
    "    print('\\nEpoch: {}'.format(epoch))\n",
    "    print('Training set: Average loss: {:.4f}'.format(train_loss))\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, device, val_loader, epoch, loss_fun):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(val_loader):\n",
    "            data = batch[0].to(device)\n",
    "            target = batch[1].to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            # compute the batch loss\n",
    "            batch_loss = loss_fun(output, target).item()\n",
    "            val_loss += batch_loss\n",
    "            pred = torch.sigmoid(output)\n",
    "            \n",
    "            if idx == 0:\n",
    "                predictions = pred\n",
    "                targets = target\n",
    "            else:\n",
    "                predictions = torch.cat((predictions, pred))\n",
    "                targets = torch.cat((targets, target))\n",
    "            if idx % 5 == 0:\n",
    "                print('Epoch: {}, Validation_Samples: {}/{}, Loss: {}'.format(epoch, idx, len(val_loader), batch_loss))\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    print('\\nEpoch: {}'.format(epoch))\n",
    "    print('Validation set: Average loss: {:.4f}, AP: {:.4f})'.format(val_loss, \n",
    "                                                                     average_precision_score(targets.reshape(-1, 20).cpu(), \n",
    "                                                                                             predictions.reshape(-1, 20).cpu())))\n",
    "    \n",
    "    return val_loss, predictions, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training_Samples: 0/358, Loss: 0.7229492115366154\n",
      "Epoch: 1, Training_Samples: 5/358, Loss: 0.6747655701672183\n",
      "Epoch: 1, Training_Samples: 10/358, Loss: 0.5930754545335258\n",
      "Epoch: 1, Training_Samples: 15/358, Loss: 0.4891532903899928\n",
      "Epoch: 1, Training_Samples: 20/358, Loss: 0.42267312589708705\n",
      "Epoch: 1, Training_Samples: 25/358, Loss: 0.3623271746768008\n",
      "Epoch: 1, Training_Samples: 30/358, Loss: 0.3160185871937287\n",
      "Epoch: 1, Training_Samples: 35/358, Loss: 0.2976356498079098\n",
      "Epoch: 1, Training_Samples: 40/358, Loss: 0.26556564472760097\n",
      "Epoch: 1, Training_Samples: 45/358, Loss: 0.3075610725113443\n",
      "Epoch: 1, Training_Samples: 50/358, Loss: 0.2542842552122176\n",
      "Epoch: 1, Training_Samples: 55/358, Loss: 0.2960028991089634\n",
      "Epoch: 1, Training_Samples: 60/358, Loss: 0.24070930992727996\n",
      "Epoch: 1, Training_Samples: 65/358, Loss: 0.26117820494468436\n",
      "Epoch: 1, Training_Samples: 70/358, Loss: 0.267733180827909\n",
      "Epoch: 1, Training_Samples: 75/358, Loss: 0.2572748116312054\n",
      "Epoch: 1, Training_Samples: 80/358, Loss: 0.25327170692835677\n",
      "Epoch: 1, Training_Samples: 85/358, Loss: 0.24901540436828173\n",
      "Epoch: 1, Training_Samples: 90/358, Loss: 0.22368621207795045\n",
      "Epoch: 1, Training_Samples: 95/358, Loss: 0.2639678135558357\n",
      "Epoch: 1, Training_Samples: 100/358, Loss: 0.2199146634490551\n",
      "Epoch: 1, Training_Samples: 105/358, Loss: 0.23860840534231106\n",
      "Epoch: 1, Training_Samples: 110/358, Loss: 0.23463782611461836\n",
      "Epoch: 1, Training_Samples: 115/358, Loss: 0.27481694647303884\n",
      "Epoch: 1, Training_Samples: 120/358, Loss: 0.199761507598389\n",
      "Epoch: 1, Training_Samples: 125/358, Loss: 0.24444382829985226\n",
      "Epoch: 1, Training_Samples: 130/358, Loss: 0.2288722215011534\n",
      "Epoch: 1, Training_Samples: 135/358, Loss: 0.2533009287811022\n",
      "Epoch: 1, Training_Samples: 140/358, Loss: 0.23635802700054215\n",
      "Epoch: 1, Training_Samples: 145/358, Loss: 0.21287079962173733\n",
      "Epoch: 1, Training_Samples: 150/358, Loss: 0.21883241907467008\n",
      "Epoch: 1, Training_Samples: 155/358, Loss: 0.23634539768707594\n",
      "Epoch: 1, Training_Samples: 160/358, Loss: 0.2429222117520453\n",
      "Epoch: 1, Training_Samples: 165/358, Loss: 0.24102765215520502\n",
      "Epoch: 1, Training_Samples: 170/358, Loss: 0.22177021834493935\n",
      "Epoch: 1, Training_Samples: 175/358, Loss: 0.2192957006738113\n",
      "Epoch: 1, Training_Samples: 180/358, Loss: 0.23440895392901098\n",
      "Epoch: 1, Training_Samples: 185/358, Loss: 0.2313433616115886\n",
      "Epoch: 1, Training_Samples: 190/358, Loss: 0.2625119017904535\n",
      "Epoch: 1, Training_Samples: 195/358, Loss: 0.2174067604009836\n",
      "Epoch: 1, Training_Samples: 200/358, Loss: 0.2070802896465497\n",
      "Epoch: 1, Training_Samples: 205/358, Loss: 0.2538139406054029\n",
      "Epoch: 1, Training_Samples: 210/358, Loss: 0.22608837575701898\n",
      "Epoch: 1, Training_Samples: 215/358, Loss: 0.22622062411755783\n",
      "Epoch: 1, Training_Samples: 220/358, Loss: 0.23619740586533067\n",
      "Epoch: 1, Training_Samples: 225/358, Loss: 0.22563333423238555\n",
      "Epoch: 1, Training_Samples: 230/358, Loss: 0.22140777386552593\n",
      "Epoch: 1, Training_Samples: 235/358, Loss: 0.2433559885189829\n",
      "Epoch: 1, Training_Samples: 240/358, Loss: 0.200021407357736\n",
      "Epoch: 1, Training_Samples: 245/358, Loss: 0.21535151196760047\n",
      "Epoch: 1, Training_Samples: 250/358, Loss: 0.20324884768527143\n",
      "Epoch: 1, Training_Samples: 255/358, Loss: 0.21824205484415668\n",
      "Epoch: 1, Training_Samples: 260/358, Loss: 0.25488574598425473\n",
      "Epoch: 1, Training_Samples: 265/358, Loss: 0.22185359297695798\n",
      "Epoch: 1, Training_Samples: 270/358, Loss: 0.23954757618334718\n",
      "Epoch: 1, Training_Samples: 275/358, Loss: 0.20316197752600218\n",
      "Epoch: 1, Training_Samples: 280/358, Loss: 0.1860188892268829\n",
      "Epoch: 1, Training_Samples: 285/358, Loss: 0.21357728267762482\n",
      "Epoch: 1, Training_Samples: 290/358, Loss: 0.20974795357297846\n",
      "Epoch: 1, Training_Samples: 295/358, Loss: 0.2149583486711686\n",
      "Epoch: 1, Training_Samples: 300/358, Loss: 0.2240587147714704\n",
      "Epoch: 1, Training_Samples: 305/358, Loss: 0.21005915514689072\n",
      "Epoch: 1, Training_Samples: 310/358, Loss: 0.21767951542720868\n",
      "Epoch: 1, Training_Samples: 315/358, Loss: 0.20548621415244822\n",
      "Epoch: 1, Training_Samples: 320/358, Loss: 0.24007825650827916\n",
      "Epoch: 1, Training_Samples: 325/358, Loss: 0.20342796377532404\n",
      "Epoch: 1, Training_Samples: 330/358, Loss: 0.20802307985745763\n",
      "Epoch: 1, Training_Samples: 335/358, Loss: 0.21151984107267802\n",
      "Epoch: 1, Training_Samples: 340/358, Loss: 0.21118052917952967\n",
      "Epoch: 1, Training_Samples: 345/358, Loss: 0.27958550131145676\n",
      "Epoch: 1, Training_Samples: 350/358, Loss: 0.26751384867143024\n",
      "Epoch: 1, Training_Samples: 355/358, Loss: 0.24346292333220523\n",
      "\n",
      "Epoch: 1\n",
      "Training set: Average loss: 0.2560\n",
      "Epoch: 1, Validation_Samples: 0/722, Loss: 0.19191770563955254\n",
      "Epoch: 1, Validation_Samples: 5/722, Loss: 0.19791381124034146\n",
      "Epoch: 1, Validation_Samples: 10/722, Loss: 0.18984937397334953\n",
      "Epoch: 1, Validation_Samples: 15/722, Loss: 0.2223113444320452\n",
      "Epoch: 1, Validation_Samples: 20/722, Loss: 0.18587841715546524\n",
      "Epoch: 1, Validation_Samples: 25/722, Loss: 0.18616369319689138\n",
      "Epoch: 1, Validation_Samples: 30/722, Loss: 0.19194275220433155\n",
      "Epoch: 1, Validation_Samples: 35/722, Loss: 0.15464622059455327\n",
      "Epoch: 1, Validation_Samples: 40/722, Loss: 0.19836550666115765\n",
      "Epoch: 1, Validation_Samples: 45/722, Loss: 0.18810299657368837\n",
      "Epoch: 1, Validation_Samples: 50/722, Loss: 0.22872124147849604\n",
      "Epoch: 1, Validation_Samples: 55/722, Loss: 0.19595093538888256\n",
      "Epoch: 1, Validation_Samples: 60/722, Loss: 0.19886350286013074\n",
      "Epoch: 1, Validation_Samples: 65/722, Loss: 0.1908796712212029\n",
      "Epoch: 1, Validation_Samples: 70/722, Loss: 0.20023747409931342\n",
      "Epoch: 1, Validation_Samples: 75/722, Loss: 0.21261816902145805\n",
      "Epoch: 1, Validation_Samples: 80/722, Loss: 0.24183230908582162\n",
      "Epoch: 1, Validation_Samples: 85/722, Loss: 0.2459990809075397\n",
      "Epoch: 1, Validation_Samples: 90/722, Loss: 0.22550212215158055\n",
      "Epoch: 1, Validation_Samples: 95/722, Loss: 0.20178274703540272\n",
      "Epoch: 1, Validation_Samples: 100/722, Loss: 0.21901089883274336\n",
      "Epoch: 1, Validation_Samples: 105/722, Loss: 0.21230631629298535\n",
      "Epoch: 1, Validation_Samples: 110/722, Loss: 0.22087723311529092\n",
      "Epoch: 1, Validation_Samples: 115/722, Loss: 0.17847610181720702\n",
      "Epoch: 1, Validation_Samples: 120/722, Loss: 0.18251778702685567\n",
      "Epoch: 1, Validation_Samples: 125/722, Loss: 0.23062032768146618\n",
      "Epoch: 1, Validation_Samples: 130/722, Loss: 0.22741151646579078\n",
      "Epoch: 1, Validation_Samples: 135/722, Loss: 0.21104355952278422\n",
      "Epoch: 1, Validation_Samples: 140/722, Loss: 0.2009945670363731\n",
      "Epoch: 1, Validation_Samples: 145/722, Loss: 0.2067753887740836\n",
      "Epoch: 1, Validation_Samples: 150/722, Loss: 0.2815071203260346\n",
      "Epoch: 1, Validation_Samples: 155/722, Loss: 0.19801624544734125\n",
      "Epoch: 1, Validation_Samples: 160/722, Loss: 0.19101504498102298\n",
      "Epoch: 1, Validation_Samples: 165/722, Loss: 0.22756450442868006\n",
      "Epoch: 1, Validation_Samples: 170/722, Loss: 0.21276698880499162\n",
      "Epoch: 1, Validation_Samples: 175/722, Loss: 0.18894421275587042\n",
      "Epoch: 1, Validation_Samples: 180/722, Loss: 0.19908473232444904\n",
      "Epoch: 1, Validation_Samples: 185/722, Loss: 0.20158347845458016\n",
      "Epoch: 1, Validation_Samples: 190/722, Loss: 0.22270541536054722\n",
      "Epoch: 1, Validation_Samples: 195/722, Loss: 0.16613147481284435\n",
      "Epoch: 1, Validation_Samples: 200/722, Loss: 0.197736943200036\n",
      "Epoch: 1, Validation_Samples: 205/722, Loss: 0.2277466540299439\n",
      "Epoch: 1, Validation_Samples: 210/722, Loss: 0.1871055491297168\n",
      "Epoch: 1, Validation_Samples: 215/722, Loss: 0.2482867598307441\n",
      "Epoch: 1, Validation_Samples: 220/722, Loss: 0.18587311701171083\n",
      "Epoch: 1, Validation_Samples: 225/722, Loss: 0.22369542904873546\n",
      "Epoch: 1, Validation_Samples: 230/722, Loss: 0.24019200886478376\n",
      "Epoch: 1, Validation_Samples: 235/722, Loss: 0.20323250415836927\n",
      "Epoch: 1, Validation_Samples: 240/722, Loss: 0.18808640307980348\n",
      "Epoch: 1, Validation_Samples: 245/722, Loss: 0.2251844272947179\n",
      "Epoch: 1, Validation_Samples: 250/722, Loss: 0.18377136035970573\n",
      "Epoch: 1, Validation_Samples: 255/722, Loss: 0.18189717902660354\n",
      "Epoch: 1, Validation_Samples: 260/722, Loss: 0.22341981536566\n",
      "Epoch: 1, Validation_Samples: 265/722, Loss: 0.2116263669319654\n",
      "Epoch: 1, Validation_Samples: 270/722, Loss: 0.17697835667678496\n",
      "Epoch: 1, Validation_Samples: 275/722, Loss: 0.18632522393595757\n",
      "Epoch: 1, Validation_Samples: 280/722, Loss: 0.18937687006141513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Validation_Samples: 285/722, Loss: 0.18661186908270685\n",
      "Epoch: 1, Validation_Samples: 290/722, Loss: 0.20691410533734655\n",
      "Epoch: 1, Validation_Samples: 295/722, Loss: 0.2098352401629568\n",
      "Epoch: 1, Validation_Samples: 300/722, Loss: 0.201668132060268\n",
      "Epoch: 1, Validation_Samples: 305/722, Loss: 0.20972208233659925\n",
      "Epoch: 1, Validation_Samples: 310/722, Loss: 0.1934266249179034\n",
      "Epoch: 1, Validation_Samples: 315/722, Loss: 0.24117051340230103\n",
      "Epoch: 1, Validation_Samples: 320/722, Loss: 0.19556814304395484\n",
      "Epoch: 1, Validation_Samples: 325/722, Loss: 0.1837887542438647\n",
      "Epoch: 1, Validation_Samples: 330/722, Loss: 0.20917265750166258\n",
      "Epoch: 1, Validation_Samples: 335/722, Loss: 0.21354119667763272\n",
      "Epoch: 1, Validation_Samples: 340/722, Loss: 0.19687959844893638\n",
      "Epoch: 1, Validation_Samples: 345/722, Loss: 0.20994072589934948\n",
      "Epoch: 1, Validation_Samples: 350/722, Loss: 0.17459812836297323\n",
      "Epoch: 1, Validation_Samples: 355/722, Loss: 0.2014592717677339\n",
      "Epoch: 1, Validation_Samples: 360/722, Loss: 0.19979785891326907\n",
      "Epoch: 1, Validation_Samples: 365/722, Loss: 0.24143924930298508\n",
      "Epoch: 1, Validation_Samples: 370/722, Loss: 0.16778993769573416\n",
      "Epoch: 1, Validation_Samples: 375/722, Loss: 0.19075156362130072\n",
      "Epoch: 1, Validation_Samples: 380/722, Loss: 0.18597315775167242\n",
      "Epoch: 1, Validation_Samples: 385/722, Loss: 0.21486236082010224\n",
      "Epoch: 1, Validation_Samples: 390/722, Loss: 0.20975545714303132\n",
      "Epoch: 1, Validation_Samples: 395/722, Loss: 0.2003475323196598\n",
      "Epoch: 1, Validation_Samples: 400/722, Loss: 0.2160850142153657\n",
      "Epoch: 1, Validation_Samples: 405/722, Loss: 0.23841579455238782\n",
      "Epoch: 1, Validation_Samples: 410/722, Loss: 0.1974665283488244\n",
      "Epoch: 1, Validation_Samples: 415/722, Loss: 0.17023633372478075\n",
      "Epoch: 1, Validation_Samples: 420/722, Loss: 0.2305227477213381\n",
      "Epoch: 1, Validation_Samples: 425/722, Loss: 0.18000353639834238\n",
      "Epoch: 1, Validation_Samples: 430/722, Loss: 0.19303743192679143\n",
      "Epoch: 1, Validation_Samples: 435/722, Loss: 0.20016518053626556\n",
      "Epoch: 1, Validation_Samples: 440/722, Loss: 0.18465131695095546\n",
      "Epoch: 1, Validation_Samples: 445/722, Loss: 0.23119657567215166\n",
      "Epoch: 1, Validation_Samples: 450/722, Loss: 0.23305472041026268\n",
      "Epoch: 1, Validation_Samples: 455/722, Loss: 0.18174759077824318\n",
      "Epoch: 1, Validation_Samples: 460/722, Loss: 0.2025745610100617\n",
      "Epoch: 1, Validation_Samples: 465/722, Loss: 0.21265303669288851\n",
      "Epoch: 1, Validation_Samples: 470/722, Loss: 0.21231118936567006\n",
      "Epoch: 1, Validation_Samples: 475/722, Loss: 0.1757949916444205\n",
      "Epoch: 1, Validation_Samples: 480/722, Loss: 0.199858072389247\n",
      "Epoch: 1, Validation_Samples: 485/722, Loss: 0.2028209787631739\n",
      "Epoch: 1, Validation_Samples: 490/722, Loss: 0.20751825019395162\n",
      "Epoch: 1, Validation_Samples: 495/722, Loss: 0.1865908943868864\n",
      "Epoch: 1, Validation_Samples: 500/722, Loss: 0.1631143327049951\n",
      "Epoch: 1, Validation_Samples: 505/722, Loss: 0.19519838556419045\n",
      "Epoch: 1, Validation_Samples: 510/722, Loss: 0.18242023251366213\n",
      "Epoch: 1, Validation_Samples: 515/722, Loss: 0.19552034798271536\n",
      "Epoch: 1, Validation_Samples: 520/722, Loss: 0.19097227391547647\n",
      "Epoch: 1, Validation_Samples: 525/722, Loss: 0.212158339247255\n",
      "Epoch: 1, Validation_Samples: 530/722, Loss: 0.2124946575611033\n",
      "Epoch: 1, Validation_Samples: 535/722, Loss: 0.19997870091724598\n",
      "Epoch: 1, Validation_Samples: 540/722, Loss: 0.21466487958120464\n",
      "Epoch: 1, Validation_Samples: 545/722, Loss: 0.18604340476170828\n",
      "Epoch: 1, Validation_Samples: 550/722, Loss: 0.19021085307141636\n",
      "Epoch: 1, Validation_Samples: 555/722, Loss: 0.20997805441755227\n",
      "Epoch: 1, Validation_Samples: 560/722, Loss: 0.18667784924848987\n",
      "Epoch: 1, Validation_Samples: 565/722, Loss: 0.1826003227205762\n",
      "Epoch: 1, Validation_Samples: 570/722, Loss: 0.2393786112723129\n",
      "Epoch: 1, Validation_Samples: 575/722, Loss: 0.22440992343320626\n",
      "Epoch: 1, Validation_Samples: 580/722, Loss: 0.1829087216465054\n",
      "Epoch: 1, Validation_Samples: 585/722, Loss: 0.21473659103198248\n",
      "Epoch: 1, Validation_Samples: 590/722, Loss: 0.16846166289913148\n",
      "Epoch: 1, Validation_Samples: 595/722, Loss: 0.19817802419906794\n",
      "Epoch: 1, Validation_Samples: 600/722, Loss: 0.2310715261616459\n",
      "Epoch: 1, Validation_Samples: 605/722, Loss: 0.20416185526790995\n",
      "Epoch: 1, Validation_Samples: 610/722, Loss: 0.1844867268099101\n",
      "Epoch: 1, Validation_Samples: 615/722, Loss: 0.22066064111068398\n",
      "Epoch: 1, Validation_Samples: 620/722, Loss: 0.25011505196915546\n",
      "Epoch: 1, Validation_Samples: 625/722, Loss: 0.20976755550366905\n",
      "Epoch: 1, Validation_Samples: 630/722, Loss: 0.21205300338540506\n",
      "Epoch: 1, Validation_Samples: 635/722, Loss: 0.21983757510190005\n",
      "Epoch: 1, Validation_Samples: 640/722, Loss: 0.17348903547030597\n",
      "Epoch: 1, Validation_Samples: 645/722, Loss: 0.22948975305185745\n",
      "Epoch: 1, Validation_Samples: 650/722, Loss: 0.22019036118108382\n",
      "Epoch: 1, Validation_Samples: 655/722, Loss: 0.21318446767110277\n",
      "Epoch: 1, Validation_Samples: 660/722, Loss: 0.22954582919854039\n",
      "Epoch: 1, Validation_Samples: 665/722, Loss: 0.22813731803344287\n",
      "Epoch: 1, Validation_Samples: 670/722, Loss: 0.20758563161314936\n",
      "Epoch: 1, Validation_Samples: 675/722, Loss: 0.20473608864485507\n",
      "Epoch: 1, Validation_Samples: 680/722, Loss: 0.1896415937807322\n",
      "Epoch: 1, Validation_Samples: 685/722, Loss: 0.18931818496293007\n",
      "Epoch: 1, Validation_Samples: 690/722, Loss: 0.22826845969170825\n",
      "Epoch: 1, Validation_Samples: 695/722, Loss: 0.22715619408420665\n",
      "Epoch: 1, Validation_Samples: 700/722, Loss: 0.24014656571831552\n",
      "Epoch: 1, Validation_Samples: 705/722, Loss: 0.2016391602836447\n",
      "Epoch: 1, Validation_Samples: 710/722, Loss: 0.21819558123144484\n",
      "Epoch: 1, Validation_Samples: 715/722, Loss: 0.2055232996129177\n",
      "Epoch: 1, Validation_Samples: 720/722, Loss: 0.21852221125397397\n",
      "\n",
      "Epoch: 1\n",
      "Validation set: Average loss: 0.2059, AP: 0.2578)\n",
      "Epoch: 2, Training_Samples: 0/358, Loss: 0.19395596458650696\n",
      "Epoch: 2, Training_Samples: 5/358, Loss: 0.19819013566225033\n",
      "Epoch: 2, Training_Samples: 10/358, Loss: 0.1949540261373174\n",
      "Epoch: 2, Training_Samples: 15/358, Loss: 0.21299792997611625\n",
      "Epoch: 2, Training_Samples: 20/358, Loss: 0.18159498185491624\n",
      "Epoch: 2, Training_Samples: 25/358, Loss: 0.20749202044785234\n",
      "Epoch: 2, Training_Samples: 30/358, Loss: 0.21855505870481104\n",
      "Epoch: 2, Training_Samples: 35/358, Loss: 0.1887266767248528\n",
      "Epoch: 2, Training_Samples: 40/358, Loss: 0.1867419242280263\n",
      "Epoch: 2, Training_Samples: 45/358, Loss: 0.21710604853748505\n",
      "Epoch: 2, Training_Samples: 50/358, Loss: 0.2019698345832455\n",
      "Epoch: 2, Training_Samples: 55/358, Loss: 0.18396149375732881\n",
      "Epoch: 2, Training_Samples: 60/358, Loss: 0.2453551063917057\n",
      "Epoch: 2, Training_Samples: 65/358, Loss: 0.2187901650415897\n",
      "Epoch: 2, Training_Samples: 70/358, Loss: 0.20565580918470436\n",
      "Epoch: 2, Training_Samples: 75/358, Loss: 0.2158910435489441\n",
      "Epoch: 2, Training_Samples: 80/358, Loss: 0.17845936815636218\n",
      "Epoch: 2, Training_Samples: 85/358, Loss: 0.2555646199951031\n",
      "Epoch: 2, Training_Samples: 90/358, Loss: 0.1850587538458081\n",
      "Epoch: 2, Training_Samples: 95/358, Loss: 0.18831093888483008\n",
      "Epoch: 2, Training_Samples: 100/358, Loss: 0.20117208639713083\n",
      "Epoch: 2, Training_Samples: 105/358, Loss: 0.22741039083584091\n",
      "Epoch: 2, Training_Samples: 110/358, Loss: 0.22119427064030503\n",
      "Epoch: 2, Training_Samples: 115/358, Loss: 0.16844475658417546\n",
      "Epoch: 2, Training_Samples: 120/358, Loss: 0.18915625310176984\n",
      "Epoch: 2, Training_Samples: 125/358, Loss: 0.20013109820188024\n",
      "Epoch: 2, Training_Samples: 130/358, Loss: 0.1907400240178363\n",
      "Epoch: 2, Training_Samples: 135/358, Loss: 0.1879489626132961\n",
      "Epoch: 2, Training_Samples: 140/358, Loss: 0.16618899398858086\n",
      "Epoch: 2, Training_Samples: 145/358, Loss: 0.19362249302167664\n",
      "Epoch: 2, Training_Samples: 150/358, Loss: 0.20720116860573753\n",
      "Epoch: 2, Training_Samples: 155/358, Loss: 0.1743522856389862\n",
      "Epoch: 2, Training_Samples: 160/358, Loss: 0.24050116440009425\n",
      "Epoch: 2, Training_Samples: 165/358, Loss: 0.21752516379559186\n",
      "Epoch: 2, Training_Samples: 170/358, Loss: 0.21095069604072356\n",
      "Epoch: 2, Training_Samples: 175/358, Loss: 0.22244040249758062\n",
      "Epoch: 2, Training_Samples: 180/358, Loss: 0.19997076910032868\n",
      "Epoch: 2, Training_Samples: 185/358, Loss: 0.18035226092151005\n",
      "Epoch: 2, Training_Samples: 190/358, Loss: 0.1777590027533765\n",
      "Epoch: 2, Training_Samples: 195/358, Loss: 0.24634857068974716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Training_Samples: 200/358, Loss: 0.16659539684469468\n",
      "Epoch: 2, Training_Samples: 205/358, Loss: 0.20472568515890596\n",
      "Epoch: 2, Training_Samples: 210/358, Loss: 0.17821258489405858\n",
      "Epoch: 2, Training_Samples: 215/358, Loss: 0.16226249241818427\n",
      "Epoch: 2, Training_Samples: 220/358, Loss: 0.21060007719867974\n",
      "Epoch: 2, Training_Samples: 225/358, Loss: 0.19452035861160905\n",
      "Epoch: 2, Training_Samples: 230/358, Loss: 0.178955823553417\n",
      "Epoch: 2, Training_Samples: 235/358, Loss: 0.15845822076023927\n",
      "Epoch: 2, Training_Samples: 240/358, Loss: 0.1862985527051164\n",
      "Epoch: 2, Training_Samples: 245/358, Loss: 0.1874656212976667\n",
      "Epoch: 2, Training_Samples: 250/358, Loss: 0.22121463238761907\n",
      "Epoch: 2, Training_Samples: 255/358, Loss: 0.17023919758030295\n",
      "Epoch: 2, Training_Samples: 260/358, Loss: 0.1830780484811391\n",
      "Epoch: 2, Training_Samples: 265/358, Loss: 0.17556456932766182\n",
      "Epoch: 2, Training_Samples: 270/358, Loss: 0.19986410415819902\n",
      "Epoch: 2, Training_Samples: 275/358, Loss: 0.21515709082626355\n",
      "Epoch: 2, Training_Samples: 280/358, Loss: 0.1601128137736744\n",
      "Epoch: 2, Training_Samples: 285/358, Loss: 0.21210822890278103\n",
      "Epoch: 2, Training_Samples: 290/358, Loss: 0.1675610066097938\n",
      "Epoch: 2, Training_Samples: 295/358, Loss: 0.17845700480887855\n",
      "Epoch: 2, Training_Samples: 300/358, Loss: 0.16227561527659748\n",
      "Epoch: 2, Training_Samples: 305/358, Loss: 0.1968790047511589\n",
      "Epoch: 2, Training_Samples: 310/358, Loss: 0.1717033789409362\n",
      "Epoch: 2, Training_Samples: 315/358, Loss: 0.16215765432642998\n",
      "Epoch: 2, Training_Samples: 320/358, Loss: 0.18217427772537423\n",
      "Epoch: 2, Training_Samples: 325/358, Loss: 0.2106252273585448\n",
      "Epoch: 2, Training_Samples: 330/358, Loss: 0.21667596937297187\n",
      "Epoch: 2, Training_Samples: 335/358, Loss: 0.22492262537155716\n",
      "Epoch: 2, Training_Samples: 340/358, Loss: 0.1772077703187934\n",
      "Epoch: 2, Training_Samples: 345/358, Loss: 0.17133457607191818\n",
      "Epoch: 2, Training_Samples: 350/358, Loss: 0.18466191052566563\n",
      "Epoch: 2, Training_Samples: 355/358, Loss: 0.20433741159710198\n",
      "\n",
      "Epoch: 2\n",
      "Training set: Average loss: 0.1978\n",
      "Epoch: 2, Validation_Samples: 0/722, Loss: 0.18226171821932072\n",
      "Epoch: 2, Validation_Samples: 5/722, Loss: 0.1738225780732219\n",
      "Epoch: 2, Validation_Samples: 10/722, Loss: 0.1645548945642689\n",
      "Epoch: 2, Validation_Samples: 15/722, Loss: 0.17410650174766568\n",
      "Epoch: 2, Validation_Samples: 20/722, Loss: 0.17094899894221122\n",
      "Epoch: 2, Validation_Samples: 25/722, Loss: 0.15282656636110042\n",
      "Epoch: 2, Validation_Samples: 30/722, Loss: 0.1723775603796038\n",
      "Epoch: 2, Validation_Samples: 35/722, Loss: 0.1840948047081922\n",
      "Epoch: 2, Validation_Samples: 40/722, Loss: 0.18007384444347718\n",
      "Epoch: 2, Validation_Samples: 45/722, Loss: 0.17530031069629354\n",
      "Epoch: 2, Validation_Samples: 50/722, Loss: 0.19933616062510157\n",
      "Epoch: 2, Validation_Samples: 55/722, Loss: 0.2044807507160045\n",
      "Epoch: 2, Validation_Samples: 60/722, Loss: 0.19330710467979184\n",
      "Epoch: 2, Validation_Samples: 65/722, Loss: 0.17520181339360213\n",
      "Epoch: 2, Validation_Samples: 70/722, Loss: 0.16739242916388095\n",
      "Epoch: 2, Validation_Samples: 75/722, Loss: 0.18262564465270636\n",
      "Epoch: 2, Validation_Samples: 80/722, Loss: 0.1421313879275482\n",
      "Epoch: 2, Validation_Samples: 85/722, Loss: 0.18973261879998898\n",
      "Epoch: 2, Validation_Samples: 90/722, Loss: 0.17802464804549872\n",
      "Epoch: 2, Validation_Samples: 95/722, Loss: 0.19809491194681594\n",
      "Epoch: 2, Validation_Samples: 100/722, Loss: 0.21804231258975523\n",
      "Epoch: 2, Validation_Samples: 105/722, Loss: 0.20001466721099884\n",
      "Epoch: 2, Validation_Samples: 110/722, Loss: 0.15837532803381812\n",
      "Epoch: 2, Validation_Samples: 115/722, Loss: 0.19721817737229008\n",
      "Epoch: 2, Validation_Samples: 120/722, Loss: 0.1890609213019835\n",
      "Epoch: 2, Validation_Samples: 125/722, Loss: 0.19462807625603668\n",
      "Epoch: 2, Validation_Samples: 130/722, Loss: 0.15469267776360066\n",
      "Epoch: 2, Validation_Samples: 135/722, Loss: 0.16828524816990964\n",
      "Epoch: 2, Validation_Samples: 140/722, Loss: 0.1435863305506413\n",
      "Epoch: 2, Validation_Samples: 145/722, Loss: 0.1465979117771532\n",
      "Epoch: 2, Validation_Samples: 150/722, Loss: 0.23949133718035773\n",
      "Epoch: 2, Validation_Samples: 155/722, Loss: 0.18524494112266718\n",
      "Epoch: 2, Validation_Samples: 160/722, Loss: 0.1508884311946131\n",
      "Epoch: 2, Validation_Samples: 165/722, Loss: 0.15360376936500336\n",
      "Epoch: 2, Validation_Samples: 170/722, Loss: 0.17142656144920032\n",
      "Epoch: 2, Validation_Samples: 175/722, Loss: 0.14162470417684664\n",
      "Epoch: 2, Validation_Samples: 180/722, Loss: 0.1718274392631617\n",
      "Epoch: 2, Validation_Samples: 185/722, Loss: 0.15647546732988668\n",
      "Epoch: 2, Validation_Samples: 190/722, Loss: 0.1952591335960511\n",
      "Epoch: 2, Validation_Samples: 195/722, Loss: 0.17664079055073914\n",
      "Epoch: 2, Validation_Samples: 200/722, Loss: 0.16094744296657415\n",
      "Epoch: 2, Validation_Samples: 205/722, Loss: 0.21296651904380579\n",
      "Epoch: 2, Validation_Samples: 210/722, Loss: 0.17355984850983489\n",
      "Epoch: 2, Validation_Samples: 215/722, Loss: 0.1731109119568365\n",
      "Epoch: 2, Validation_Samples: 220/722, Loss: 0.19943785555405136\n",
      "Epoch: 2, Validation_Samples: 225/722, Loss: 0.2098330374118672\n",
      "Epoch: 2, Validation_Samples: 230/722, Loss: 0.19287514129543185\n",
      "Epoch: 2, Validation_Samples: 235/722, Loss: 0.18755255392394338\n",
      "Epoch: 2, Validation_Samples: 240/722, Loss: 0.13856617461121293\n",
      "Epoch: 2, Validation_Samples: 245/722, Loss: 0.16277543562438285\n",
      "Epoch: 2, Validation_Samples: 250/722, Loss: 0.1949837451984546\n",
      "Epoch: 2, Validation_Samples: 255/722, Loss: 0.18397529347407832\n",
      "Epoch: 2, Validation_Samples: 260/722, Loss: 0.1478634000779438\n",
      "Epoch: 2, Validation_Samples: 265/722, Loss: 0.1661885706035114\n",
      "Epoch: 2, Validation_Samples: 270/722, Loss: 0.15824518164507848\n",
      "Epoch: 2, Validation_Samples: 275/722, Loss: 0.1714238865466622\n",
      "Epoch: 2, Validation_Samples: 280/722, Loss: 0.1947250718789069\n",
      "Epoch: 2, Validation_Samples: 285/722, Loss: 0.15611858259603362\n",
      "Epoch: 2, Validation_Samples: 290/722, Loss: 0.1386033306324652\n",
      "Epoch: 2, Validation_Samples: 295/722, Loss: 0.19102718526427392\n",
      "Epoch: 2, Validation_Samples: 300/722, Loss: 0.1607424082132671\n",
      "Epoch: 2, Validation_Samples: 305/722, Loss: 0.2078936243107174\n",
      "Epoch: 2, Validation_Samples: 310/722, Loss: 0.19376159624388486\n",
      "Epoch: 2, Validation_Samples: 315/722, Loss: 0.15765525644512643\n",
      "Epoch: 2, Validation_Samples: 320/722, Loss: 0.17526511522987093\n",
      "Epoch: 2, Validation_Samples: 325/722, Loss: 0.18931326391403533\n",
      "Epoch: 2, Validation_Samples: 330/722, Loss: 0.15443725989380258\n",
      "Epoch: 2, Validation_Samples: 335/722, Loss: 0.18176413986259252\n",
      "Epoch: 2, Validation_Samples: 340/722, Loss: 0.15339645385506398\n",
      "Epoch: 2, Validation_Samples: 345/722, Loss: 0.16718595106065057\n",
      "Epoch: 2, Validation_Samples: 350/722, Loss: 0.144214702727562\n",
      "Epoch: 2, Validation_Samples: 355/722, Loss: 0.17562546891917705\n",
      "Epoch: 2, Validation_Samples: 360/722, Loss: 0.14037845766648444\n",
      "Epoch: 2, Validation_Samples: 365/722, Loss: 0.2253550571165917\n",
      "Epoch: 2, Validation_Samples: 370/722, Loss: 0.18004210519667121\n",
      "Epoch: 2, Validation_Samples: 375/722, Loss: 0.1772858410744913\n",
      "Epoch: 2, Validation_Samples: 380/722, Loss: 0.1652788172220681\n",
      "Epoch: 2, Validation_Samples: 385/722, Loss: 0.1613943382205296\n",
      "Epoch: 2, Validation_Samples: 390/722, Loss: 0.18613147388530527\n",
      "Epoch: 2, Validation_Samples: 395/722, Loss: 0.14779865359954156\n",
      "Epoch: 2, Validation_Samples: 400/722, Loss: 0.19962257132012035\n",
      "Epoch: 2, Validation_Samples: 405/722, Loss: 0.20115923787506554\n",
      "Epoch: 2, Validation_Samples: 410/722, Loss: 0.15189805011677673\n",
      "Epoch: 2, Validation_Samples: 415/722, Loss: 0.16796752692023795\n",
      "Epoch: 2, Validation_Samples: 420/722, Loss: 0.20223867847805965\n",
      "Epoch: 2, Validation_Samples: 425/722, Loss: 0.16440083780248033\n",
      "Epoch: 2, Validation_Samples: 430/722, Loss: 0.17941152363953583\n",
      "Epoch: 2, Validation_Samples: 435/722, Loss: 0.1651674211335403\n",
      "Epoch: 2, Validation_Samples: 440/722, Loss: 0.17402351405180636\n",
      "Epoch: 2, Validation_Samples: 445/722, Loss: 0.17930569839895227\n",
      "Epoch: 2, Validation_Samples: 450/722, Loss: 0.17594471231157344\n",
      "Epoch: 2, Validation_Samples: 455/722, Loss: 0.1797627724296337\n",
      "Epoch: 2, Validation_Samples: 460/722, Loss: 0.19955380783711874\n",
      "Epoch: 2, Validation_Samples: 465/722, Loss: 0.15752787201066587\n",
      "Epoch: 2, Validation_Samples: 470/722, Loss: 0.21421309950389275\n",
      "Epoch: 2, Validation_Samples: 475/722, Loss: 0.1969128476956212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Validation_Samples: 480/722, Loss: 0.17149692052062665\n",
      "Epoch: 2, Validation_Samples: 485/722, Loss: 0.1845117703842705\n",
      "Epoch: 2, Validation_Samples: 490/722, Loss: 0.170906524076538\n",
      "Epoch: 2, Validation_Samples: 495/722, Loss: 0.1847519953965972\n",
      "Epoch: 2, Validation_Samples: 500/722, Loss: 0.20122948566799445\n",
      "Epoch: 2, Validation_Samples: 505/722, Loss: 0.1491341297487575\n",
      "Epoch: 2, Validation_Samples: 510/722, Loss: 0.18853215394275208\n",
      "Epoch: 2, Validation_Samples: 515/722, Loss: 0.222953190925241\n",
      "Epoch: 2, Validation_Samples: 520/722, Loss: 0.1928520366022783\n",
      "Epoch: 2, Validation_Samples: 525/722, Loss: 0.17119025360514667\n",
      "Epoch: 2, Validation_Samples: 530/722, Loss: 0.15474483251686189\n",
      "Epoch: 2, Validation_Samples: 535/722, Loss: 0.19992377336780107\n",
      "Epoch: 2, Validation_Samples: 540/722, Loss: 0.16447895467465345\n",
      "Epoch: 2, Validation_Samples: 545/722, Loss: 0.1838015970106474\n",
      "Epoch: 2, Validation_Samples: 550/722, Loss: 0.1985700160255611\n",
      "Epoch: 2, Validation_Samples: 555/722, Loss: 0.21962511510349744\n",
      "Epoch: 2, Validation_Samples: 560/722, Loss: 0.19388661517208516\n",
      "Epoch: 2, Validation_Samples: 565/722, Loss: 0.1655458939511881\n",
      "Epoch: 2, Validation_Samples: 570/722, Loss: 0.16448205177919034\n",
      "Epoch: 2, Validation_Samples: 575/722, Loss: 0.19818401189754403\n",
      "Epoch: 2, Validation_Samples: 580/722, Loss: 0.15554407219427416\n",
      "Epoch: 2, Validation_Samples: 585/722, Loss: 0.17959729979058658\n",
      "Epoch: 2, Validation_Samples: 590/722, Loss: 0.1508437989783713\n",
      "Epoch: 2, Validation_Samples: 595/722, Loss: 0.1892672035313388\n",
      "Epoch: 2, Validation_Samples: 600/722, Loss: 0.16713785372775106\n",
      "Epoch: 2, Validation_Samples: 605/722, Loss: 0.15900040545335523\n",
      "Epoch: 2, Validation_Samples: 610/722, Loss: 0.2234663798361663\n",
      "Epoch: 2, Validation_Samples: 615/722, Loss: 0.17089689868150776\n",
      "Epoch: 2, Validation_Samples: 620/722, Loss: 0.1632869348702053\n",
      "Epoch: 2, Validation_Samples: 625/722, Loss: 0.15711344322603202\n",
      "Epoch: 2, Validation_Samples: 630/722, Loss: 0.18691547808559622\n",
      "Epoch: 2, Validation_Samples: 635/722, Loss: 0.1789659630195986\n",
      "Epoch: 2, Validation_Samples: 640/722, Loss: 0.18753655046948442\n",
      "Epoch: 2, Validation_Samples: 645/722, Loss: 0.1737949974859086\n",
      "Epoch: 2, Validation_Samples: 650/722, Loss: 0.1871342416478068\n",
      "Epoch: 2, Validation_Samples: 655/722, Loss: 0.18608662674600351\n",
      "Epoch: 2, Validation_Samples: 660/722, Loss: 0.1920147128741237\n",
      "Epoch: 2, Validation_Samples: 665/722, Loss: 0.17976668108430863\n",
      "Epoch: 2, Validation_Samples: 670/722, Loss: 0.17632171944501807\n",
      "Epoch: 2, Validation_Samples: 675/722, Loss: 0.16448127670342838\n",
      "Epoch: 2, Validation_Samples: 680/722, Loss: 0.19151823753366876\n",
      "Epoch: 2, Validation_Samples: 685/722, Loss: 0.19227762727084755\n",
      "Epoch: 2, Validation_Samples: 690/722, Loss: 0.21484501242814133\n",
      "Epoch: 2, Validation_Samples: 695/722, Loss: 0.18838019095275832\n",
      "Epoch: 2, Validation_Samples: 700/722, Loss: 0.17016488015577247\n",
      "Epoch: 2, Validation_Samples: 705/722, Loss: 0.18626150389364596\n",
      "Epoch: 2, Validation_Samples: 710/722, Loss: 0.17657393205826089\n",
      "Epoch: 2, Validation_Samples: 715/722, Loss: 0.17991574599049232\n",
      "Epoch: 2, Validation_Samples: 720/722, Loss: 0.18342888679735445\n",
      "\n",
      "Epoch: 2\n",
      "Validation set: Average loss: 0.1778, AP: 0.4246)\n",
      "Epoch: 3, Training_Samples: 0/358, Loss: 0.18403628933524535\n",
      "Epoch: 3, Training_Samples: 5/358, Loss: 0.1771327028863581\n",
      "Epoch: 3, Training_Samples: 10/358, Loss: 0.19228735191139634\n",
      "Epoch: 3, Training_Samples: 15/358, Loss: 0.17779650590038537\n",
      "Epoch: 3, Training_Samples: 20/358, Loss: 0.1693582815863611\n",
      "Epoch: 3, Training_Samples: 25/358, Loss: 0.1655649616941594\n",
      "Epoch: 3, Training_Samples: 30/358, Loss: 0.1611772804178404\n",
      "Epoch: 3, Training_Samples: 35/358, Loss: 0.18450407991232606\n",
      "Epoch: 3, Training_Samples: 40/358, Loss: 0.17556368571352812\n",
      "Epoch: 3, Training_Samples: 45/358, Loss: 0.19247476954324755\n",
      "Epoch: 3, Training_Samples: 50/358, Loss: 0.16208443539762024\n",
      "Epoch: 3, Training_Samples: 55/358, Loss: 0.19644216234820155\n",
      "Epoch: 3, Training_Samples: 60/358, Loss: 0.17616505825270748\n",
      "Epoch: 3, Training_Samples: 65/358, Loss: 0.2287331965304153\n",
      "Epoch: 3, Training_Samples: 70/358, Loss: 0.21612613801135974\n",
      "Epoch: 3, Training_Samples: 75/358, Loss: 0.15249142253671327\n",
      "Epoch: 3, Training_Samples: 80/358, Loss: 0.17088420183842273\n",
      "Epoch: 3, Training_Samples: 85/358, Loss: 0.18042564098222433\n",
      "Epoch: 3, Training_Samples: 90/358, Loss: 0.18847283979188337\n",
      "Epoch: 3, Training_Samples: 95/358, Loss: 0.21213167218699278\n",
      "Epoch: 3, Training_Samples: 100/358, Loss: 0.21220836740542093\n",
      "Epoch: 3, Training_Samples: 105/358, Loss: 0.19474988939508162\n",
      "Epoch: 3, Training_Samples: 110/358, Loss: 0.18792394613605745\n",
      "Epoch: 3, Training_Samples: 115/358, Loss: 0.1791363062604152\n",
      "Epoch: 3, Training_Samples: 120/358, Loss: 0.20441682232809869\n",
      "Epoch: 3, Training_Samples: 125/358, Loss: 0.15592826669410778\n",
      "Epoch: 3, Training_Samples: 130/358, Loss: 0.1589142800429286\n",
      "Epoch: 3, Training_Samples: 135/358, Loss: 0.17285481735748662\n",
      "Epoch: 3, Training_Samples: 140/358, Loss: 0.18101246898086923\n",
      "Epoch: 3, Training_Samples: 145/358, Loss: 0.18452249940529927\n",
      "Epoch: 3, Training_Samples: 150/358, Loss: 0.20138488765395773\n",
      "Epoch: 3, Training_Samples: 155/358, Loss: 0.15827317357138568\n",
      "Epoch: 3, Training_Samples: 160/358, Loss: 0.1714556390575391\n",
      "Epoch: 3, Training_Samples: 165/358, Loss: 0.16513348055736687\n",
      "Epoch: 3, Training_Samples: 170/358, Loss: 0.18564677297985024\n",
      "Epoch: 3, Training_Samples: 175/358, Loss: 0.1471250964307706\n",
      "Epoch: 3, Training_Samples: 180/358, Loss: 0.16557833908230848\n",
      "Epoch: 3, Training_Samples: 185/358, Loss: 0.1493337552269479\n",
      "Epoch: 3, Training_Samples: 190/358, Loss: 0.1888095489592666\n",
      "Epoch: 3, Training_Samples: 195/358, Loss: 0.15077076597065406\n",
      "Epoch: 3, Training_Samples: 200/358, Loss: 0.16604479696586888\n",
      "Epoch: 3, Training_Samples: 205/358, Loss: 0.15364483565692075\n",
      "Epoch: 3, Training_Samples: 210/358, Loss: 0.18979479676563452\n",
      "Epoch: 3, Training_Samples: 215/358, Loss: 0.17884103636800455\n",
      "Epoch: 3, Training_Samples: 220/358, Loss: 0.16620072692006277\n",
      "Epoch: 3, Training_Samples: 225/358, Loss: 0.18565561663288607\n",
      "Epoch: 3, Training_Samples: 230/358, Loss: 0.1701545749636466\n",
      "Epoch: 3, Training_Samples: 235/358, Loss: 0.19435422758860987\n",
      "Epoch: 3, Training_Samples: 240/358, Loss: 0.15486754654534693\n",
      "Epoch: 3, Training_Samples: 245/358, Loss: 0.15448930774287217\n",
      "Epoch: 3, Training_Samples: 250/358, Loss: 0.16395896481690547\n",
      "Epoch: 3, Training_Samples: 255/358, Loss: 0.15600513689495357\n",
      "Epoch: 3, Training_Samples: 260/358, Loss: 0.16292252477335079\n",
      "Epoch: 3, Training_Samples: 265/358, Loss: 0.1700336917334716\n",
      "Epoch: 3, Training_Samples: 270/358, Loss: 0.17322669481777314\n",
      "Epoch: 3, Training_Samples: 275/358, Loss: 0.147807111227368\n",
      "Epoch: 3, Training_Samples: 280/358, Loss: 0.17965753801064152\n",
      "Epoch: 3, Training_Samples: 285/358, Loss: 0.14002362387159067\n",
      "Epoch: 3, Training_Samples: 290/358, Loss: 0.16418022323516993\n",
      "Epoch: 3, Training_Samples: 295/358, Loss: 0.18257504845397265\n",
      "Epoch: 3, Training_Samples: 300/358, Loss: 0.1788983036355328\n",
      "Epoch: 3, Training_Samples: 305/358, Loss: 0.17007578635177345\n",
      "Epoch: 3, Training_Samples: 310/358, Loss: 0.17156995977984676\n",
      "Epoch: 3, Training_Samples: 315/358, Loss: 0.18239881800365965\n",
      "Epoch: 3, Training_Samples: 320/358, Loss: 0.16545329702602138\n",
      "Epoch: 3, Training_Samples: 325/358, Loss: 0.15785665054201975\n",
      "Epoch: 3, Training_Samples: 330/358, Loss: 0.1837917555873392\n",
      "Epoch: 3, Training_Samples: 335/358, Loss: 0.13891764088841826\n",
      "Epoch: 3, Training_Samples: 340/358, Loss: 0.12963377498446765\n",
      "Epoch: 3, Training_Samples: 345/358, Loss: 0.1503463028385102\n",
      "Epoch: 3, Training_Samples: 350/358, Loss: 0.1871571374220207\n",
      "Epoch: 3, Training_Samples: 355/358, Loss: 0.1657306954302218\n",
      "\n",
      "Epoch: 3\n",
      "Training set: Average loss: 0.1768\n",
      "Epoch: 3, Validation_Samples: 0/722, Loss: 0.15521049636933523\n",
      "Epoch: 3, Validation_Samples: 5/722, Loss: 0.17677230266439198\n",
      "Epoch: 3, Validation_Samples: 10/722, Loss: 0.16751964703275177\n",
      "Epoch: 3, Validation_Samples: 15/722, Loss: 0.1496005308041777\n",
      "Epoch: 3, Validation_Samples: 20/722, Loss: 0.18346394848001482\n",
      "Epoch: 3, Validation_Samples: 25/722, Loss: 0.13693079395586583\n",
      "Epoch: 3, Validation_Samples: 30/722, Loss: 0.13919594355737563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Validation_Samples: 35/722, Loss: 0.15718971384357813\n",
      "Epoch: 3, Validation_Samples: 40/722, Loss: 0.18239670470028393\n",
      "Epoch: 3, Validation_Samples: 45/722, Loss: 0.15793171594591804\n",
      "Epoch: 3, Validation_Samples: 50/722, Loss: 0.15914326646325502\n",
      "Epoch: 3, Validation_Samples: 55/722, Loss: 0.14196164227714644\n",
      "Epoch: 3, Validation_Samples: 60/722, Loss: 0.15594709510390856\n",
      "Epoch: 3, Validation_Samples: 65/722, Loss: 0.19708902417069704\n",
      "Epoch: 3, Validation_Samples: 70/722, Loss: 0.1593219334804694\n",
      "Epoch: 3, Validation_Samples: 75/722, Loss: 0.15768320343730152\n",
      "Epoch: 3, Validation_Samples: 80/722, Loss: 0.15122188009483511\n",
      "Epoch: 3, Validation_Samples: 85/722, Loss: 0.16297436934525833\n",
      "Epoch: 3, Validation_Samples: 90/722, Loss: 0.13658085871806247\n",
      "Epoch: 3, Validation_Samples: 95/722, Loss: 0.16783999763237306\n",
      "Epoch: 3, Validation_Samples: 100/722, Loss: 0.1429687899079005\n",
      "Epoch: 3, Validation_Samples: 105/722, Loss: 0.18211846307661186\n",
      "Epoch: 3, Validation_Samples: 110/722, Loss: 0.17084526570609232\n",
      "Epoch: 3, Validation_Samples: 115/722, Loss: 0.1734895928304954\n",
      "Epoch: 3, Validation_Samples: 120/722, Loss: 0.15175932941203865\n",
      "Epoch: 3, Validation_Samples: 125/722, Loss: 0.14844445034260736\n",
      "Epoch: 3, Validation_Samples: 130/722, Loss: 0.14247586278936478\n",
      "Epoch: 3, Validation_Samples: 135/722, Loss: 0.13161120238830146\n",
      "Epoch: 3, Validation_Samples: 140/722, Loss: 0.16146086134556273\n",
      "Epoch: 3, Validation_Samples: 145/722, Loss: 0.14259848011891652\n",
      "Epoch: 3, Validation_Samples: 150/722, Loss: 0.15303401930405866\n",
      "Epoch: 3, Validation_Samples: 155/722, Loss: 0.1339408161206723\n",
      "Epoch: 3, Validation_Samples: 160/722, Loss: 0.183332923750028\n",
      "Epoch: 3, Validation_Samples: 165/722, Loss: 0.13694825375183442\n",
      "Epoch: 3, Validation_Samples: 170/722, Loss: 0.1639354732741765\n",
      "Epoch: 3, Validation_Samples: 175/722, Loss: 0.16921729860010254\n",
      "Epoch: 3, Validation_Samples: 180/722, Loss: 0.1802156806623804\n",
      "Epoch: 3, Validation_Samples: 185/722, Loss: 0.15821013935793862\n",
      "Epoch: 3, Validation_Samples: 190/722, Loss: 0.16497914746270753\n",
      "Epoch: 3, Validation_Samples: 195/722, Loss: 0.16243802183651906\n",
      "Epoch: 3, Validation_Samples: 200/722, Loss: 0.15051506424973812\n",
      "Epoch: 3, Validation_Samples: 205/722, Loss: 0.17450056364597658\n",
      "Epoch: 3, Validation_Samples: 210/722, Loss: 0.1349610299512292\n",
      "Epoch: 3, Validation_Samples: 215/722, Loss: 0.14437569202405148\n",
      "Epoch: 3, Validation_Samples: 220/722, Loss: 0.13629940872008728\n",
      "Epoch: 3, Validation_Samples: 225/722, Loss: 0.12489027043393632\n",
      "Epoch: 3, Validation_Samples: 230/722, Loss: 0.15012614168851238\n",
      "Epoch: 3, Validation_Samples: 235/722, Loss: 0.16225425522422818\n",
      "Epoch: 3, Validation_Samples: 240/722, Loss: 0.12152711698863664\n",
      "Epoch: 3, Validation_Samples: 245/722, Loss: 0.14705674386111936\n",
      "Epoch: 3, Validation_Samples: 250/722, Loss: 0.16615526661252064\n",
      "Epoch: 3, Validation_Samples: 255/722, Loss: 0.1908506466240369\n",
      "Epoch: 3, Validation_Samples: 260/722, Loss: 0.22541720449338337\n",
      "Epoch: 3, Validation_Samples: 265/722, Loss: 0.17790856795441318\n",
      "Epoch: 3, Validation_Samples: 270/722, Loss: 0.14165865355547372\n",
      "Epoch: 3, Validation_Samples: 275/722, Loss: 0.17431277772624573\n",
      "Epoch: 3, Validation_Samples: 280/722, Loss: 0.15597092978698826\n",
      "Epoch: 3, Validation_Samples: 285/722, Loss: 0.1501318136708138\n",
      "Epoch: 3, Validation_Samples: 290/722, Loss: 0.1351300353151332\n",
      "Epoch: 3, Validation_Samples: 295/722, Loss: 0.13133283756520284\n",
      "Epoch: 3, Validation_Samples: 300/722, Loss: 0.1971333299190814\n",
      "Epoch: 3, Validation_Samples: 305/722, Loss: 0.13468884861025987\n",
      "Epoch: 3, Validation_Samples: 310/722, Loss: 0.1750125475608052\n",
      "Epoch: 3, Validation_Samples: 315/722, Loss: 0.1699175892106084\n",
      "Epoch: 3, Validation_Samples: 320/722, Loss: 0.16491984552526148\n",
      "Epoch: 3, Validation_Samples: 325/722, Loss: 0.15332064071845283\n",
      "Epoch: 3, Validation_Samples: 330/722, Loss: 0.15164101600720312\n",
      "Epoch: 3, Validation_Samples: 335/722, Loss: 0.14799117485298427\n",
      "Epoch: 3, Validation_Samples: 340/722, Loss: 0.13149923521057957\n",
      "Epoch: 3, Validation_Samples: 345/722, Loss: 0.14835199495082546\n",
      "Epoch: 3, Validation_Samples: 350/722, Loss: 0.1675600447776594\n",
      "Epoch: 3, Validation_Samples: 355/722, Loss: 0.13635411266407185\n",
      "Epoch: 3, Validation_Samples: 360/722, Loss: 0.16302035055171052\n",
      "Epoch: 3, Validation_Samples: 365/722, Loss: 0.13078690929870634\n",
      "Epoch: 3, Validation_Samples: 370/722, Loss: 0.16720908595484946\n",
      "Epoch: 3, Validation_Samples: 375/722, Loss: 0.1791388196352367\n",
      "Epoch: 3, Validation_Samples: 380/722, Loss: 0.13536779377124358\n",
      "Epoch: 3, Validation_Samples: 385/722, Loss: 0.16111843177619845\n",
      "Epoch: 3, Validation_Samples: 390/722, Loss: 0.1431322185336087\n",
      "Epoch: 3, Validation_Samples: 395/722, Loss: 0.16445383465689845\n",
      "Epoch: 3, Validation_Samples: 400/722, Loss: 0.16223914007180248\n",
      "Epoch: 3, Validation_Samples: 405/722, Loss: 0.16850993295817415\n",
      "Epoch: 3, Validation_Samples: 410/722, Loss: 0.13705101251893553\n",
      "Epoch: 3, Validation_Samples: 415/722, Loss: 0.1418516739367058\n",
      "Epoch: 3, Validation_Samples: 420/722, Loss: 0.1615334146890413\n",
      "Epoch: 3, Validation_Samples: 425/722, Loss: 0.1613851129333249\n",
      "Epoch: 3, Validation_Samples: 430/722, Loss: 0.1619778443202858\n",
      "Epoch: 3, Validation_Samples: 435/722, Loss: 0.15452800173769604\n",
      "Epoch: 3, Validation_Samples: 440/722, Loss: 0.13562454896643664\n",
      "Epoch: 3, Validation_Samples: 445/722, Loss: 0.19369939094974215\n",
      "Epoch: 3, Validation_Samples: 450/722, Loss: 0.14771186007647982\n",
      "Epoch: 3, Validation_Samples: 455/722, Loss: 0.13236567669216967\n",
      "Epoch: 3, Validation_Samples: 460/722, Loss: 0.16425272113548683\n",
      "Epoch: 3, Validation_Samples: 465/722, Loss: 0.2017980971554243\n",
      "Epoch: 3, Validation_Samples: 470/722, Loss: 0.16021555436688834\n",
      "Epoch: 3, Validation_Samples: 475/722, Loss: 0.1517416809537605\n",
      "Epoch: 3, Validation_Samples: 480/722, Loss: 0.1481980448036454\n",
      "Epoch: 3, Validation_Samples: 485/722, Loss: 0.1545228021762355\n",
      "Epoch: 3, Validation_Samples: 490/722, Loss: 0.1517724388448547\n",
      "Epoch: 3, Validation_Samples: 495/722, Loss: 0.1943671920821653\n",
      "Epoch: 3, Validation_Samples: 500/722, Loss: 0.15876287742282416\n",
      "Epoch: 3, Validation_Samples: 505/722, Loss: 0.14646485964301995\n",
      "Epoch: 3, Validation_Samples: 510/722, Loss: 0.15152887547105734\n",
      "Epoch: 3, Validation_Samples: 515/722, Loss: 0.16748431951206208\n",
      "Epoch: 3, Validation_Samples: 520/722, Loss: 0.14692414546807883\n",
      "Epoch: 3, Validation_Samples: 525/722, Loss: 0.17273953402378947\n",
      "Epoch: 3, Validation_Samples: 530/722, Loss: 0.15322694266985326\n",
      "Epoch: 3, Validation_Samples: 535/722, Loss: 0.1952235541056713\n",
      "Epoch: 3, Validation_Samples: 540/722, Loss: 0.18419749579797257\n",
      "Epoch: 3, Validation_Samples: 545/722, Loss: 0.20794244443725707\n",
      "Epoch: 3, Validation_Samples: 550/722, Loss: 0.12187819469113703\n",
      "Epoch: 3, Validation_Samples: 555/722, Loss: 0.15371436383871342\n",
      "Epoch: 3, Validation_Samples: 560/722, Loss: 0.17312140129908676\n",
      "Epoch: 3, Validation_Samples: 565/722, Loss: 0.14138800657938289\n",
      "Epoch: 3, Validation_Samples: 570/722, Loss: 0.1603525334670993\n",
      "Epoch: 3, Validation_Samples: 575/722, Loss: 0.17272256552522455\n",
      "Epoch: 3, Validation_Samples: 580/722, Loss: 0.16822982851542972\n",
      "Epoch: 3, Validation_Samples: 585/722, Loss: 0.1660742944551759\n",
      "Epoch: 3, Validation_Samples: 590/722, Loss: 0.1907634082802066\n",
      "Epoch: 3, Validation_Samples: 595/722, Loss: 0.17284883046664182\n",
      "Epoch: 3, Validation_Samples: 600/722, Loss: 0.14223281409571645\n",
      "Epoch: 3, Validation_Samples: 605/722, Loss: 0.15231532252322194\n",
      "Epoch: 3, Validation_Samples: 610/722, Loss: 0.13383382016393924\n",
      "Epoch: 3, Validation_Samples: 615/722, Loss: 0.1475999967012088\n",
      "Epoch: 3, Validation_Samples: 620/722, Loss: 0.16222964271652965\n",
      "Epoch: 3, Validation_Samples: 625/722, Loss: 0.1726357547796071\n",
      "Epoch: 3, Validation_Samples: 630/722, Loss: 0.16545066839348122\n",
      "Epoch: 3, Validation_Samples: 635/722, Loss: 0.15454646216029613\n",
      "Epoch: 3, Validation_Samples: 640/722, Loss: 0.2052088032015863\n",
      "Epoch: 3, Validation_Samples: 645/722, Loss: 0.15918645443463067\n",
      "Epoch: 3, Validation_Samples: 650/722, Loss: 0.17276375239322195\n",
      "Epoch: 3, Validation_Samples: 655/722, Loss: 0.1488691431017942\n",
      "Epoch: 3, Validation_Samples: 660/722, Loss: 0.1281514882848878\n",
      "Epoch: 3, Validation_Samples: 665/722, Loss: 0.15447900991474314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Validation_Samples: 670/722, Loss: 0.14854797247117854\n",
      "Epoch: 3, Validation_Samples: 675/722, Loss: 0.16181426066319982\n",
      "Epoch: 3, Validation_Samples: 680/722, Loss: 0.18186851647017988\n",
      "Epoch: 3, Validation_Samples: 685/722, Loss: 0.16407877623011394\n",
      "Epoch: 3, Validation_Samples: 690/722, Loss: 0.13611598005056674\n",
      "Epoch: 3, Validation_Samples: 695/722, Loss: 0.15029716682335562\n",
      "Epoch: 3, Validation_Samples: 700/722, Loss: 0.14458534042140508\n",
      "Epoch: 3, Validation_Samples: 705/722, Loss: 0.1796463198546237\n",
      "Epoch: 3, Validation_Samples: 710/722, Loss: 0.14986053804106178\n",
      "Epoch: 3, Validation_Samples: 715/722, Loss: 0.148832358972931\n",
      "Epoch: 3, Validation_Samples: 720/722, Loss: 0.17172527764700762\n",
      "\n",
      "Epoch: 3\n",
      "Validation set: Average loss: 0.1602, AP: 0.5077)\n",
      "Epoch: 4, Training_Samples: 0/358, Loss: 0.16856883734383862\n",
      "Epoch: 4, Training_Samples: 5/358, Loss: 0.15625710204050514\n",
      "Epoch: 4, Training_Samples: 10/358, Loss: 0.13722715495489834\n",
      "Epoch: 4, Training_Samples: 15/358, Loss: 0.13506380762563402\n",
      "Epoch: 4, Training_Samples: 20/358, Loss: 0.1434060137769521\n",
      "Epoch: 4, Training_Samples: 25/358, Loss: 0.1557802060636303\n",
      "Epoch: 4, Training_Samples: 30/358, Loss: 0.2229988440733114\n",
      "Epoch: 4, Training_Samples: 35/358, Loss: 0.1562395898936569\n",
      "Epoch: 4, Training_Samples: 40/358, Loss: 0.14827767989389165\n",
      "Epoch: 4, Training_Samples: 45/358, Loss: 0.213330735920327\n",
      "Epoch: 4, Training_Samples: 50/358, Loss: 0.13339904691384613\n",
      "Epoch: 4, Training_Samples: 55/358, Loss: 0.1617282870932797\n",
      "Epoch: 4, Training_Samples: 60/358, Loss: 0.1630589285541259\n",
      "Epoch: 4, Training_Samples: 65/358, Loss: 0.1829921575326293\n",
      "Epoch: 4, Training_Samples: 70/358, Loss: 0.17097570778102267\n",
      "Epoch: 4, Training_Samples: 75/358, Loss: 0.16826745049992847\n",
      "Epoch: 4, Training_Samples: 80/358, Loss: 0.1370580985494233\n",
      "Epoch: 4, Training_Samples: 85/358, Loss: 0.13960746618188632\n",
      "Epoch: 4, Training_Samples: 90/358, Loss: 0.15760473957615978\n",
      "Epoch: 4, Training_Samples: 95/358, Loss: 0.15007856444325368\n",
      "Epoch: 4, Training_Samples: 100/358, Loss: 0.16012742130363006\n",
      "Epoch: 4, Training_Samples: 105/358, Loss: 0.18060200683447258\n",
      "Epoch: 4, Training_Samples: 110/358, Loss: 0.1460206143052362\n",
      "Epoch: 4, Training_Samples: 115/358, Loss: 0.13512911032044514\n",
      "Epoch: 4, Training_Samples: 120/358, Loss: 0.1175575585654433\n",
      "Epoch: 4, Training_Samples: 125/358, Loss: 0.14758160139060866\n",
      "Epoch: 4, Training_Samples: 130/358, Loss: 0.2116135566552443\n",
      "Epoch: 4, Training_Samples: 135/358, Loss: 0.17554240927792014\n",
      "Epoch: 4, Training_Samples: 140/358, Loss: 0.19088342669732267\n",
      "Epoch: 4, Training_Samples: 145/358, Loss: 0.15037582020282333\n",
      "Epoch: 4, Training_Samples: 150/358, Loss: 0.16605120683869512\n",
      "Epoch: 4, Training_Samples: 155/358, Loss: 0.1732255614913152\n",
      "Epoch: 4, Training_Samples: 160/358, Loss: 0.14566726426947973\n",
      "Epoch: 4, Training_Samples: 165/358, Loss: 0.15713305208634473\n",
      "Epoch: 4, Training_Samples: 170/358, Loss: 0.16463912260137234\n",
      "Epoch: 4, Training_Samples: 175/358, Loss: 0.13441136343153243\n",
      "Epoch: 4, Training_Samples: 180/358, Loss: 0.17737927632022732\n",
      "Epoch: 4, Training_Samples: 185/358, Loss: 0.1604518867662079\n",
      "Epoch: 4, Training_Samples: 190/358, Loss: 0.18523055747120215\n",
      "Epoch: 4, Training_Samples: 195/358, Loss: 0.18305046303566883\n",
      "Epoch: 4, Training_Samples: 200/358, Loss: 0.18353722124545474\n",
      "Epoch: 4, Training_Samples: 205/358, Loss: 0.1562819760268429\n",
      "Epoch: 4, Training_Samples: 210/358, Loss: 0.14768611083972175\n",
      "Epoch: 4, Training_Samples: 215/358, Loss: 0.16961752599801322\n",
      "Epoch: 4, Training_Samples: 220/358, Loss: 0.14235672435058636\n",
      "Epoch: 4, Training_Samples: 225/358, Loss: 0.15206481607768174\n",
      "Epoch: 4, Training_Samples: 230/358, Loss: 0.1550174928443144\n",
      "Epoch: 4, Training_Samples: 235/358, Loss: 0.14890740937380448\n",
      "Epoch: 4, Training_Samples: 240/358, Loss: 0.15548861622585305\n",
      "Epoch: 4, Training_Samples: 245/358, Loss: 0.152551346677684\n",
      "Epoch: 4, Training_Samples: 250/358, Loss: 0.13655440809353184\n",
      "Epoch: 4, Training_Samples: 255/358, Loss: 0.18749382177038454\n",
      "Epoch: 4, Training_Samples: 260/358, Loss: 0.16532188981676318\n",
      "Epoch: 4, Training_Samples: 265/358, Loss: 0.1592752362539299\n",
      "Epoch: 4, Training_Samples: 270/358, Loss: 0.20415756716767422\n",
      "Epoch: 4, Training_Samples: 275/358, Loss: 0.1681170138356075\n",
      "Epoch: 4, Training_Samples: 280/358, Loss: 0.18756516953823638\n",
      "Epoch: 4, Training_Samples: 285/358, Loss: 0.17369379287720135\n",
      "Epoch: 4, Training_Samples: 290/358, Loss: 0.19127096155151174\n",
      "Epoch: 4, Training_Samples: 295/358, Loss: 0.12075985421409262\n",
      "Epoch: 4, Training_Samples: 300/358, Loss: 0.12411842824872683\n",
      "Epoch: 4, Training_Samples: 305/358, Loss: 0.1737925489238633\n",
      "Epoch: 4, Training_Samples: 310/358, Loss: 0.16926589175605145\n",
      "Epoch: 4, Training_Samples: 315/358, Loss: 0.20193563025469605\n",
      "Epoch: 4, Training_Samples: 320/358, Loss: 0.17621512187607416\n",
      "Epoch: 4, Training_Samples: 325/358, Loss: 0.16814696666235238\n",
      "Epoch: 4, Training_Samples: 330/358, Loss: 0.16918701628670535\n",
      "Epoch: 4, Training_Samples: 335/358, Loss: 0.15174374690665857\n",
      "Epoch: 4, Training_Samples: 340/358, Loss: 0.1831058277974133\n",
      "Epoch: 4, Training_Samples: 345/358, Loss: 0.15039305714602944\n",
      "Epoch: 4, Training_Samples: 350/358, Loss: 0.15425110874789436\n",
      "Epoch: 4, Training_Samples: 355/358, Loss: 0.13742709872640768\n",
      "\n",
      "Epoch: 4\n",
      "Training set: Average loss: 0.1628\n",
      "Epoch: 4, Validation_Samples: 0/722, Loss: 0.18122028812714522\n",
      "Epoch: 4, Validation_Samples: 5/722, Loss: 0.14530616495021256\n",
      "Epoch: 4, Validation_Samples: 10/722, Loss: 0.12606185634958586\n",
      "Epoch: 4, Validation_Samples: 15/722, Loss: 0.1331998303903183\n",
      "Epoch: 4, Validation_Samples: 20/722, Loss: 0.15687488619790937\n",
      "Epoch: 4, Validation_Samples: 25/722, Loss: 0.16414618333053207\n",
      "Epoch: 4, Validation_Samples: 30/722, Loss: 0.14858623432013413\n",
      "Epoch: 4, Validation_Samples: 35/722, Loss: 0.12167006008952944\n",
      "Epoch: 4, Validation_Samples: 40/722, Loss: 0.12823465337878273\n",
      "Epoch: 4, Validation_Samples: 45/722, Loss: 0.16059645026981542\n",
      "Epoch: 4, Validation_Samples: 50/722, Loss: 0.16620022257832207\n",
      "Epoch: 4, Validation_Samples: 55/722, Loss: 0.15964089782024204\n",
      "Epoch: 4, Validation_Samples: 60/722, Loss: 0.15953606028437095\n",
      "Epoch: 4, Validation_Samples: 65/722, Loss: 0.1899320305389177\n",
      "Epoch: 4, Validation_Samples: 70/722, Loss: 0.16477660653736156\n",
      "Epoch: 4, Validation_Samples: 75/722, Loss: 0.12344849544404507\n",
      "Epoch: 4, Validation_Samples: 80/722, Loss: 0.18350755108493802\n",
      "Epoch: 4, Validation_Samples: 85/722, Loss: 0.14703068683243212\n",
      "Epoch: 4, Validation_Samples: 90/722, Loss: 0.1298663488877812\n",
      "Epoch: 4, Validation_Samples: 95/722, Loss: 0.15160845362547923\n",
      "Epoch: 4, Validation_Samples: 100/722, Loss: 0.13601012047692146\n",
      "Epoch: 4, Validation_Samples: 105/722, Loss: 0.14898747249772962\n",
      "Epoch: 4, Validation_Samples: 110/722, Loss: 0.1252362744634148\n",
      "Epoch: 4, Validation_Samples: 115/722, Loss: 0.15300912348439072\n",
      "Epoch: 4, Validation_Samples: 120/722, Loss: 0.12398305002219627\n",
      "Epoch: 4, Validation_Samples: 125/722, Loss: 0.15700570000515776\n",
      "Epoch: 4, Validation_Samples: 130/722, Loss: 0.17396924956111628\n",
      "Epoch: 4, Validation_Samples: 135/722, Loss: 0.1360758801433505\n",
      "Epoch: 4, Validation_Samples: 140/722, Loss: 0.15829812197767423\n",
      "Epoch: 4, Validation_Samples: 145/722, Loss: 0.16392938819282704\n",
      "Epoch: 4, Validation_Samples: 150/722, Loss: 0.18577692915911864\n",
      "Epoch: 4, Validation_Samples: 155/722, Loss: 0.11601354568298657\n",
      "Epoch: 4, Validation_Samples: 160/722, Loss: 0.12207069865763177\n",
      "Epoch: 4, Validation_Samples: 165/722, Loss: 0.1132342941331723\n",
      "Epoch: 4, Validation_Samples: 170/722, Loss: 0.12738678011947283\n",
      "Epoch: 4, Validation_Samples: 175/722, Loss: 0.1459775121115813\n",
      "Epoch: 4, Validation_Samples: 180/722, Loss: 0.15426896876301066\n",
      "Epoch: 4, Validation_Samples: 185/722, Loss: 0.13513286262715773\n",
      "Epoch: 4, Validation_Samples: 190/722, Loss: 0.16070370407484866\n",
      "Epoch: 4, Validation_Samples: 195/722, Loss: 0.1360740841888744\n",
      "Epoch: 4, Validation_Samples: 200/722, Loss: 0.11627407889339746\n",
      "Epoch: 4, Validation_Samples: 205/722, Loss: 0.12495716508828825\n",
      "Epoch: 4, Validation_Samples: 210/722, Loss: 0.14595989129830453\n",
      "Epoch: 4, Validation_Samples: 215/722, Loss: 0.1224496700631929\n",
      "Epoch: 4, Validation_Samples: 220/722, Loss: 0.17903067096671155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Validation_Samples: 225/722, Loss: 0.1306515862290285\n",
      "Epoch: 4, Validation_Samples: 230/722, Loss: 0.13756667705992404\n",
      "Epoch: 4, Validation_Samples: 235/722, Loss: 0.13083126484301774\n",
      "Epoch: 4, Validation_Samples: 240/722, Loss: 0.12181852957444313\n",
      "Epoch: 4, Validation_Samples: 245/722, Loss: 0.12093756671442049\n",
      "Epoch: 4, Validation_Samples: 250/722, Loss: 0.1566024976980546\n",
      "Epoch: 4, Validation_Samples: 255/722, Loss: 0.16080267990418276\n",
      "Epoch: 4, Validation_Samples: 260/722, Loss: 0.11727399060711563\n",
      "Epoch: 4, Validation_Samples: 265/722, Loss: 0.14063808135707795\n",
      "Epoch: 4, Validation_Samples: 270/722, Loss: 0.13232845591998685\n",
      "Epoch: 4, Validation_Samples: 275/722, Loss: 0.1470919756527609\n",
      "Epoch: 4, Validation_Samples: 280/722, Loss: 0.15754890677897607\n",
      "Epoch: 4, Validation_Samples: 285/722, Loss: 0.1598132734888901\n",
      "Epoch: 4, Validation_Samples: 290/722, Loss: 0.13848821228984057\n",
      "Epoch: 4, Validation_Samples: 295/722, Loss: 0.15669233838711738\n",
      "Epoch: 4, Validation_Samples: 300/722, Loss: 0.14439834201022894\n",
      "Epoch: 4, Validation_Samples: 305/722, Loss: 0.13991816871932247\n",
      "Epoch: 4, Validation_Samples: 310/722, Loss: 0.181833149294793\n",
      "Epoch: 4, Validation_Samples: 315/722, Loss: 0.15845570006725954\n",
      "Epoch: 4, Validation_Samples: 320/722, Loss: 0.17280458550961184\n",
      "Epoch: 4, Validation_Samples: 325/722, Loss: 0.16063491747976735\n",
      "Epoch: 4, Validation_Samples: 330/722, Loss: 0.13237933755636097\n",
      "Epoch: 4, Validation_Samples: 335/722, Loss: 0.14241031126189274\n",
      "Epoch: 4, Validation_Samples: 340/722, Loss: 0.1512492881029796\n",
      "Epoch: 4, Validation_Samples: 345/722, Loss: 0.13257368447456175\n",
      "Epoch: 4, Validation_Samples: 350/722, Loss: 0.15764636310093735\n",
      "Epoch: 4, Validation_Samples: 355/722, Loss: 0.14365887377508166\n",
      "Epoch: 4, Validation_Samples: 360/722, Loss: 0.16674384134960843\n",
      "Epoch: 4, Validation_Samples: 365/722, Loss: 0.1409187421479261\n",
      "Epoch: 4, Validation_Samples: 370/722, Loss: 0.15651922704092702\n",
      "Epoch: 4, Validation_Samples: 375/722, Loss: 0.13272860237723344\n",
      "Epoch: 4, Validation_Samples: 380/722, Loss: 0.1999210879391349\n",
      "Epoch: 4, Validation_Samples: 385/722, Loss: 0.13274674711403592\n",
      "Epoch: 4, Validation_Samples: 390/722, Loss: 0.14159890620281335\n",
      "Epoch: 4, Validation_Samples: 395/722, Loss: 0.1265262518954897\n",
      "Epoch: 4, Validation_Samples: 400/722, Loss: 0.1332215135817944\n",
      "Epoch: 4, Validation_Samples: 405/722, Loss: 0.15550085643819875\n",
      "Epoch: 4, Validation_Samples: 410/722, Loss: 0.14311394200556496\n",
      "Epoch: 4, Validation_Samples: 415/722, Loss: 0.12533688649229546\n",
      "Epoch: 4, Validation_Samples: 420/722, Loss: 0.12676563783836917\n",
      "Epoch: 4, Validation_Samples: 425/722, Loss: 0.16154682755512403\n",
      "Epoch: 4, Validation_Samples: 430/722, Loss: 0.1294946095666452\n",
      "Epoch: 4, Validation_Samples: 435/722, Loss: 0.1385075210176248\n",
      "Epoch: 4, Validation_Samples: 440/722, Loss: 0.15100448933631697\n",
      "Epoch: 4, Validation_Samples: 445/722, Loss: 0.14316013098572108\n",
      "Epoch: 4, Validation_Samples: 450/722, Loss: 0.14931549557730708\n",
      "Epoch: 4, Validation_Samples: 455/722, Loss: 0.14595444764137722\n",
      "Epoch: 4, Validation_Samples: 460/722, Loss: 0.1377084177040294\n",
      "Epoch: 4, Validation_Samples: 465/722, Loss: 0.17208933182292782\n",
      "Epoch: 4, Validation_Samples: 470/722, Loss: 0.13385168898660235\n",
      "Epoch: 4, Validation_Samples: 475/722, Loss: 0.18289943936526867\n",
      "Epoch: 4, Validation_Samples: 480/722, Loss: 0.13481143703534193\n",
      "Epoch: 4, Validation_Samples: 485/722, Loss: 0.1476102183096789\n",
      "Epoch: 4, Validation_Samples: 490/722, Loss: 0.1387920890668916\n",
      "Epoch: 4, Validation_Samples: 495/722, Loss: 0.16809141416998472\n",
      "Epoch: 4, Validation_Samples: 500/722, Loss: 0.15451717841716292\n",
      "Epoch: 4, Validation_Samples: 505/722, Loss: 0.12687073345427968\n",
      "Epoch: 4, Validation_Samples: 510/722, Loss: 0.16254006731601878\n",
      "Epoch: 4, Validation_Samples: 515/722, Loss: 0.18200543201635533\n",
      "Epoch: 4, Validation_Samples: 520/722, Loss: 0.14559110981332624\n",
      "Epoch: 4, Validation_Samples: 525/722, Loss: 0.16528975530100734\n",
      "Epoch: 4, Validation_Samples: 530/722, Loss: 0.13220922248848715\n",
      "Epoch: 4, Validation_Samples: 535/722, Loss: 0.1787436275376745\n",
      "Epoch: 4, Validation_Samples: 540/722, Loss: 0.17097900087948792\n",
      "Epoch: 4, Validation_Samples: 545/722, Loss: 0.1198554202773368\n",
      "Epoch: 4, Validation_Samples: 550/722, Loss: 0.14235847063355428\n",
      "Epoch: 4, Validation_Samples: 555/722, Loss: 0.1331420096959834\n",
      "Epoch: 4, Validation_Samples: 560/722, Loss: 0.167548733578877\n",
      "Epoch: 4, Validation_Samples: 565/722, Loss: 0.14705324807266187\n",
      "Epoch: 4, Validation_Samples: 570/722, Loss: 0.11615279486345331\n",
      "Epoch: 4, Validation_Samples: 575/722, Loss: 0.14975023350117025\n",
      "Epoch: 4, Validation_Samples: 580/722, Loss: 0.1324268375458644\n",
      "Epoch: 4, Validation_Samples: 585/722, Loss: 0.10871786634346199\n",
      "Epoch: 4, Validation_Samples: 590/722, Loss: 0.14060254053332027\n",
      "Epoch: 4, Validation_Samples: 595/722, Loss: 0.1264386385100539\n",
      "Epoch: 4, Validation_Samples: 600/722, Loss: 0.16060015106565773\n",
      "Epoch: 4, Validation_Samples: 605/722, Loss: 0.15690591819688646\n",
      "Epoch: 4, Validation_Samples: 610/722, Loss: 0.13817986523712433\n",
      "Epoch: 4, Validation_Samples: 615/722, Loss: 0.14167685329415103\n",
      "Epoch: 4, Validation_Samples: 620/722, Loss: 0.15153587061682963\n",
      "Epoch: 4, Validation_Samples: 625/722, Loss: 0.1575482055494556\n",
      "Epoch: 4, Validation_Samples: 630/722, Loss: 0.1423623512859783\n",
      "Epoch: 4, Validation_Samples: 635/722, Loss: 0.1518540685203125\n",
      "Epoch: 4, Validation_Samples: 640/722, Loss: 0.14765824109202422\n",
      "Epoch: 4, Validation_Samples: 645/722, Loss: 0.16974834538737638\n",
      "Epoch: 4, Validation_Samples: 650/722, Loss: 0.1382251580797683\n",
      "Epoch: 4, Validation_Samples: 655/722, Loss: 0.14175372729450195\n",
      "Epoch: 4, Validation_Samples: 660/722, Loss: 0.1663779589739865\n",
      "Epoch: 4, Validation_Samples: 665/722, Loss: 0.1469742161105619\n",
      "Epoch: 4, Validation_Samples: 670/722, Loss: 0.1390473132135877\n",
      "Epoch: 4, Validation_Samples: 675/722, Loss: 0.13499860183130027\n",
      "Epoch: 4, Validation_Samples: 680/722, Loss: 0.1539508850313098\n",
      "Epoch: 4, Validation_Samples: 685/722, Loss: 0.15389980854915342\n",
      "Epoch: 4, Validation_Samples: 690/722, Loss: 0.1255912727313329\n",
      "Epoch: 4, Validation_Samples: 695/722, Loss: 0.14647124050733035\n",
      "Epoch: 4, Validation_Samples: 700/722, Loss: 0.15728326053152059\n",
      "Epoch: 4, Validation_Samples: 705/722, Loss: 0.15843091773907156\n",
      "Epoch: 4, Validation_Samples: 710/722, Loss: 0.14541669675973673\n",
      "Epoch: 4, Validation_Samples: 715/722, Loss: 0.12965487396637893\n",
      "Epoch: 4, Validation_Samples: 720/722, Loss: 0.15832876769532822\n",
      "\n",
      "Epoch: 4\n",
      "Validation set: Average loss: 0.1478, AP: 0.5585)\n",
      "Epoch: 5, Training_Samples: 0/358, Loss: 0.16333814931070464\n",
      "Epoch: 5, Training_Samples: 5/358, Loss: 0.15870143724547625\n",
      "Epoch: 5, Training_Samples: 10/358, Loss: 0.19913578600339013\n",
      "Epoch: 5, Training_Samples: 15/358, Loss: 0.1681476210736315\n",
      "Epoch: 5, Training_Samples: 20/358, Loss: 0.15627685594339707\n",
      "Epoch: 5, Training_Samples: 25/358, Loss: 0.15198297678042677\n",
      "Epoch: 5, Training_Samples: 30/358, Loss: 0.1444766984625914\n",
      "Epoch: 5, Training_Samples: 35/358, Loss: 0.16884157019148938\n",
      "Epoch: 5, Training_Samples: 40/358, Loss: 0.134448725303453\n",
      "Epoch: 5, Training_Samples: 45/358, Loss: 0.14681206855254358\n",
      "Epoch: 5, Training_Samples: 50/358, Loss: 0.15117594420013722\n",
      "Epoch: 5, Training_Samples: 55/358, Loss: 0.15523014737381408\n",
      "Epoch: 5, Training_Samples: 60/358, Loss: 0.1982842187840002\n",
      "Epoch: 5, Training_Samples: 65/358, Loss: 0.15659559618330804\n",
      "Epoch: 5, Training_Samples: 70/358, Loss: 0.13274222797740426\n",
      "Epoch: 5, Training_Samples: 75/358, Loss: 0.1813735152591322\n",
      "Epoch: 5, Training_Samples: 80/358, Loss: 0.14282551800247642\n",
      "Epoch: 5, Training_Samples: 85/358, Loss: 0.15256188227610787\n",
      "Epoch: 5, Training_Samples: 90/358, Loss: 0.14808504686645882\n",
      "Epoch: 5, Training_Samples: 95/358, Loss: 0.133714974604287\n",
      "Epoch: 5, Training_Samples: 100/358, Loss: 0.17344586262309983\n",
      "Epoch: 5, Training_Samples: 105/358, Loss: 0.19493092090683437\n",
      "Epoch: 5, Training_Samples: 110/358, Loss: 0.18159278256354455\n",
      "Epoch: 5, Training_Samples: 115/358, Loss: 0.14812423863192406\n",
      "Epoch: 5, Training_Samples: 120/358, Loss: 0.1229856711457589\n",
      "Epoch: 5, Training_Samples: 125/358, Loss: 0.17217331109085307\n",
      "Epoch: 5, Training_Samples: 130/358, Loss: 0.13615974338139605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Training_Samples: 135/358, Loss: 0.13316917902906772\n",
      "Epoch: 5, Training_Samples: 140/358, Loss: 0.1537652782201715\n",
      "Epoch: 5, Training_Samples: 145/358, Loss: 0.14655203142711656\n",
      "Epoch: 5, Training_Samples: 150/358, Loss: 0.13244316080995186\n",
      "Epoch: 5, Training_Samples: 155/358, Loss: 0.1268142816007868\n",
      "Epoch: 5, Training_Samples: 160/358, Loss: 0.15281222660603405\n",
      "Epoch: 5, Training_Samples: 165/358, Loss: 0.14834953982077315\n",
      "Epoch: 5, Training_Samples: 170/358, Loss: 0.13741646216424785\n",
      "Epoch: 5, Training_Samples: 175/358, Loss: 0.13645851423328736\n",
      "Epoch: 5, Training_Samples: 180/358, Loss: 0.1466793410218036\n",
      "Epoch: 5, Training_Samples: 185/358, Loss: 0.1354693043114176\n",
      "Epoch: 5, Training_Samples: 190/358, Loss: 0.15903909734451785\n",
      "Epoch: 5, Training_Samples: 195/358, Loss: 0.13097617083577784\n",
      "Epoch: 5, Training_Samples: 200/358, Loss: 0.12112890520345532\n",
      "Epoch: 5, Training_Samples: 205/358, Loss: 0.16919905451228012\n",
      "Epoch: 5, Training_Samples: 210/358, Loss: 0.19601751273380694\n",
      "Epoch: 5, Training_Samples: 215/358, Loss: 0.15153875364013483\n",
      "Epoch: 5, Training_Samples: 220/358, Loss: 0.1909737521514343\n",
      "Epoch: 5, Training_Samples: 225/358, Loss: 0.18229156759722628\n",
      "Epoch: 5, Training_Samples: 230/358, Loss: 0.16942781957359818\n",
      "Epoch: 5, Training_Samples: 235/358, Loss: 0.16118354499088233\n",
      "Epoch: 5, Training_Samples: 240/358, Loss: 0.1600273012935643\n",
      "Epoch: 5, Training_Samples: 245/358, Loss: 0.13992634998044495\n",
      "Epoch: 5, Training_Samples: 250/358, Loss: 0.13648556349597077\n",
      "Epoch: 5, Training_Samples: 255/358, Loss: 0.10929911056696856\n",
      "Epoch: 5, Training_Samples: 260/358, Loss: 0.15083411472375347\n",
      "Epoch: 5, Training_Samples: 265/358, Loss: 0.13964967728536093\n",
      "Epoch: 5, Training_Samples: 270/358, Loss: 0.14806596276858972\n",
      "Epoch: 5, Training_Samples: 275/358, Loss: 0.1341775968052077\n",
      "Epoch: 5, Training_Samples: 280/358, Loss: 0.1501927765071363\n",
      "Epoch: 5, Training_Samples: 285/358, Loss: 0.1478645636840274\n",
      "Epoch: 5, Training_Samples: 290/358, Loss: 0.18592162485996583\n",
      "Epoch: 5, Training_Samples: 295/358, Loss: 0.13672430762752905\n",
      "Epoch: 5, Training_Samples: 300/358, Loss: 0.1660935745375146\n",
      "Epoch: 5, Training_Samples: 305/358, Loss: 0.14893427192522637\n",
      "Epoch: 5, Training_Samples: 310/358, Loss: 0.12361218521588127\n",
      "Epoch: 5, Training_Samples: 315/358, Loss: 0.15137927189298167\n",
      "Epoch: 5, Training_Samples: 320/358, Loss: 0.16678826588455095\n",
      "Epoch: 5, Training_Samples: 325/358, Loss: 0.154339928911127\n",
      "Epoch: 5, Training_Samples: 330/358, Loss: 0.17153965625521386\n",
      "Epoch: 5, Training_Samples: 335/358, Loss: 0.16185756683396388\n",
      "Epoch: 5, Training_Samples: 340/358, Loss: 0.1605576657075078\n",
      "Epoch: 5, Training_Samples: 345/358, Loss: 0.1497216949025098\n",
      "Epoch: 5, Training_Samples: 350/358, Loss: 0.15256477676195687\n",
      "Epoch: 5, Training_Samples: 355/358, Loss: 0.13617764659823892\n",
      "\n",
      "Epoch: 5\n",
      "Training set: Average loss: 0.1527\n",
      "Epoch: 5, Validation_Samples: 0/722, Loss: 0.15431657494620843\n",
      "Epoch: 5, Validation_Samples: 5/722, Loss: 0.09816340985736068\n",
      "Epoch: 5, Validation_Samples: 10/722, Loss: 0.11234957598020212\n",
      "Epoch: 5, Validation_Samples: 15/722, Loss: 0.1333873582880355\n",
      "Epoch: 5, Validation_Samples: 20/722, Loss: 0.13245600895803292\n",
      "Epoch: 5, Validation_Samples: 25/722, Loss: 0.14924179121842596\n",
      "Epoch: 5, Validation_Samples: 30/722, Loss: 0.12317937833629085\n",
      "Epoch: 5, Validation_Samples: 35/722, Loss: 0.13972059987643867\n",
      "Epoch: 5, Validation_Samples: 40/722, Loss: 0.1537551407654284\n",
      "Epoch: 5, Validation_Samples: 45/722, Loss: 0.14027566294996763\n",
      "Epoch: 5, Validation_Samples: 50/722, Loss: 0.18739733305330253\n",
      "Epoch: 5, Validation_Samples: 55/722, Loss: 0.12173530506744211\n",
      "Epoch: 5, Validation_Samples: 60/722, Loss: 0.12897053579750103\n",
      "Epoch: 5, Validation_Samples: 65/722, Loss: 0.1436971133610618\n",
      "Epoch: 5, Validation_Samples: 70/722, Loss: 0.12689249363011784\n",
      "Epoch: 5, Validation_Samples: 75/722, Loss: 0.1544561917648118\n",
      "Epoch: 5, Validation_Samples: 80/722, Loss: 0.14337480007766562\n",
      "Epoch: 5, Validation_Samples: 85/722, Loss: 0.1371955878739868\n",
      "Epoch: 5, Validation_Samples: 90/722, Loss: 0.15753908259022892\n",
      "Epoch: 5, Validation_Samples: 95/722, Loss: 0.16061990398920575\n",
      "Epoch: 5, Validation_Samples: 100/722, Loss: 0.14080349711196\n",
      "Epoch: 5, Validation_Samples: 105/722, Loss: 0.08242166498712007\n",
      "Epoch: 5, Validation_Samples: 110/722, Loss: 0.13247977509322353\n",
      "Epoch: 5, Validation_Samples: 115/722, Loss: 0.1624463127528728\n",
      "Epoch: 5, Validation_Samples: 120/722, Loss: 0.12044730655453226\n",
      "Epoch: 5, Validation_Samples: 125/722, Loss: 0.1341301142576301\n",
      "Epoch: 5, Validation_Samples: 130/722, Loss: 0.15915923140934393\n",
      "Epoch: 5, Validation_Samples: 135/722, Loss: 0.11863766356906076\n",
      "Epoch: 5, Validation_Samples: 140/722, Loss: 0.16384105472859284\n",
      "Epoch: 5, Validation_Samples: 145/722, Loss: 0.14717613534333737\n",
      "Epoch: 5, Validation_Samples: 150/722, Loss: 0.12694420393586717\n",
      "Epoch: 5, Validation_Samples: 155/722, Loss: 0.13200232607225743\n",
      "Epoch: 5, Validation_Samples: 160/722, Loss: 0.13245329374377865\n",
      "Epoch: 5, Validation_Samples: 165/722, Loss: 0.13979310892534183\n",
      "Epoch: 5, Validation_Samples: 170/722, Loss: 0.13996815162248655\n",
      "Epoch: 5, Validation_Samples: 175/722, Loss: 0.13421554734158006\n",
      "Epoch: 5, Validation_Samples: 180/722, Loss: 0.1384680209309045\n",
      "Epoch: 5, Validation_Samples: 185/722, Loss: 0.13278682644284284\n",
      "Epoch: 5, Validation_Samples: 190/722, Loss: 0.13636582051787408\n",
      "Epoch: 5, Validation_Samples: 195/722, Loss: 0.15582786671864934\n",
      "Epoch: 5, Validation_Samples: 200/722, Loss: 0.16702482694975945\n",
      "Epoch: 5, Validation_Samples: 205/722, Loss: 0.10590940758613188\n",
      "Epoch: 5, Validation_Samples: 210/722, Loss: 0.1302057371810322\n",
      "Epoch: 5, Validation_Samples: 215/722, Loss: 0.11528268954133779\n",
      "Epoch: 5, Validation_Samples: 220/722, Loss: 0.11925971139530801\n",
      "Epoch: 5, Validation_Samples: 225/722, Loss: 0.14034163908214156\n",
      "Epoch: 5, Validation_Samples: 230/722, Loss: 0.15086154216016026\n",
      "Epoch: 5, Validation_Samples: 235/722, Loss: 0.16011124976508898\n",
      "Epoch: 5, Validation_Samples: 240/722, Loss: 0.15547007092502246\n",
      "Epoch: 5, Validation_Samples: 245/722, Loss: 0.1352984540742271\n",
      "Epoch: 5, Validation_Samples: 250/722, Loss: 0.14091821285765396\n",
      "Epoch: 5, Validation_Samples: 255/722, Loss: 0.16390136886453546\n",
      "Epoch: 5, Validation_Samples: 260/722, Loss: 0.12159442374632182\n",
      "Epoch: 5, Validation_Samples: 265/722, Loss: 0.14304477200898463\n",
      "Epoch: 5, Validation_Samples: 270/722, Loss: 0.1268649296368994\n",
      "Epoch: 5, Validation_Samples: 275/722, Loss: 0.1272434163248873\n",
      "Epoch: 5, Validation_Samples: 280/722, Loss: 0.14856409877472665\n",
      "Epoch: 5, Validation_Samples: 285/722, Loss: 0.11627132122029188\n",
      "Epoch: 5, Validation_Samples: 290/722, Loss: 0.12483148243722006\n",
      "Epoch: 5, Validation_Samples: 295/722, Loss: 0.14627233600888387\n",
      "Epoch: 5, Validation_Samples: 300/722, Loss: 0.13180823791221533\n",
      "Epoch: 5, Validation_Samples: 305/722, Loss: 0.12014594405852323\n",
      "Epoch: 5, Validation_Samples: 310/722, Loss: 0.12928609651555542\n",
      "Epoch: 5, Validation_Samples: 315/722, Loss: 0.14945255071273145\n",
      "Epoch: 5, Validation_Samples: 320/722, Loss: 0.13615037867338084\n",
      "Epoch: 5, Validation_Samples: 325/722, Loss: 0.18048964866024322\n",
      "Epoch: 5, Validation_Samples: 330/722, Loss: 0.14877893796910402\n",
      "Epoch: 5, Validation_Samples: 335/722, Loss: 0.12625013716722808\n",
      "Epoch: 5, Validation_Samples: 340/722, Loss: 0.11128900775853169\n",
      "Epoch: 5, Validation_Samples: 345/722, Loss: 0.13420352478350697\n",
      "Epoch: 5, Validation_Samples: 350/722, Loss: 0.13210718972590635\n",
      "Epoch: 5, Validation_Samples: 355/722, Loss: 0.11242385361870437\n",
      "Epoch: 5, Validation_Samples: 360/722, Loss: 0.12028836701502275\n",
      "Epoch: 5, Validation_Samples: 365/722, Loss: 0.1637655209574716\n",
      "Epoch: 5, Validation_Samples: 370/722, Loss: 0.10949330503420995\n",
      "Epoch: 5, Validation_Samples: 375/722, Loss: 0.1634253923744487\n",
      "Epoch: 5, Validation_Samples: 380/722, Loss: 0.11252954321469952\n",
      "Epoch: 5, Validation_Samples: 385/722, Loss: 0.11667906933932486\n",
      "Epoch: 5, Validation_Samples: 390/722, Loss: 0.14215878887328431\n",
      "Epoch: 5, Validation_Samples: 395/722, Loss: 0.17115075060113108\n",
      "Epoch: 5, Validation_Samples: 400/722, Loss: 0.10826718671619306\n",
      "Epoch: 5, Validation_Samples: 405/722, Loss: 0.12192930813042926\n",
      "Epoch: 5, Validation_Samples: 410/722, Loss: 0.12615329633308245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Validation_Samples: 415/722, Loss: 0.13478730497914074\n",
      "Epoch: 5, Validation_Samples: 420/722, Loss: 0.13334180690933148\n",
      "Epoch: 5, Validation_Samples: 425/722, Loss: 0.13365543482196754\n",
      "Epoch: 5, Validation_Samples: 430/722, Loss: 0.151534078844574\n",
      "Epoch: 5, Validation_Samples: 435/722, Loss: 0.12765473928038337\n",
      "Epoch: 5, Validation_Samples: 440/722, Loss: 0.16375247962070769\n",
      "Epoch: 5, Validation_Samples: 445/722, Loss: 0.10729198106498351\n",
      "Epoch: 5, Validation_Samples: 450/722, Loss: 0.11459392624447615\n",
      "Epoch: 5, Validation_Samples: 455/722, Loss: 0.1266331312126178\n",
      "Epoch: 5, Validation_Samples: 460/722, Loss: 0.13094810333482537\n",
      "Epoch: 5, Validation_Samples: 465/722, Loss: 0.129154532562159\n",
      "Epoch: 5, Validation_Samples: 470/722, Loss: 0.14898495345402757\n",
      "Epoch: 5, Validation_Samples: 475/722, Loss: 0.1019312020526202\n",
      "Epoch: 5, Validation_Samples: 480/722, Loss: 0.14934374469635064\n",
      "Epoch: 5, Validation_Samples: 485/722, Loss: 0.14660921178187464\n",
      "Epoch: 5, Validation_Samples: 490/722, Loss: 0.129613489585597\n",
      "Epoch: 5, Validation_Samples: 495/722, Loss: 0.1413156448362456\n",
      "Epoch: 5, Validation_Samples: 500/722, Loss: 0.11722159006399897\n",
      "Epoch: 5, Validation_Samples: 505/722, Loss: 0.16173652293681803\n",
      "Epoch: 5, Validation_Samples: 510/722, Loss: 0.14980014964887742\n",
      "Epoch: 5, Validation_Samples: 515/722, Loss: 0.14174352755283137\n",
      "Epoch: 5, Validation_Samples: 520/722, Loss: 0.15256396030891473\n",
      "Epoch: 5, Validation_Samples: 525/722, Loss: 0.11771768063216445\n",
      "Epoch: 5, Validation_Samples: 530/722, Loss: 0.15811340344819652\n",
      "Epoch: 5, Validation_Samples: 535/722, Loss: 0.1102169426703716\n",
      "Epoch: 5, Validation_Samples: 540/722, Loss: 0.11902885083852076\n",
      "Epoch: 5, Validation_Samples: 545/722, Loss: 0.1491981742018314\n",
      "Epoch: 5, Validation_Samples: 550/722, Loss: 0.1435481495201137\n",
      "Epoch: 5, Validation_Samples: 555/722, Loss: 0.10929201822313225\n",
      "Epoch: 5, Validation_Samples: 560/722, Loss: 0.1057308525511819\n",
      "Epoch: 5, Validation_Samples: 565/722, Loss: 0.12932057279612147\n",
      "Epoch: 5, Validation_Samples: 570/722, Loss: 0.12980016464411698\n",
      "Epoch: 5, Validation_Samples: 575/722, Loss: 0.14356704855036012\n",
      "Epoch: 5, Validation_Samples: 580/722, Loss: 0.1068154870271109\n",
      "Epoch: 5, Validation_Samples: 585/722, Loss: 0.13810635991643228\n",
      "Epoch: 5, Validation_Samples: 590/722, Loss: 0.1437518837563683\n",
      "Epoch: 5, Validation_Samples: 595/722, Loss: 0.12898752387603196\n",
      "Epoch: 5, Validation_Samples: 600/722, Loss: 0.1536011275986319\n",
      "Epoch: 5, Validation_Samples: 605/722, Loss: 0.169369674992188\n",
      "Epoch: 5, Validation_Samples: 610/722, Loss: 0.1335212937914665\n",
      "Epoch: 5, Validation_Samples: 615/722, Loss: 0.12037979003426012\n",
      "Epoch: 5, Validation_Samples: 620/722, Loss: 0.13482502890017098\n",
      "Epoch: 5, Validation_Samples: 625/722, Loss: 0.14588114433255817\n",
      "Epoch: 5, Validation_Samples: 630/722, Loss: 0.12605115602311534\n",
      "Epoch: 5, Validation_Samples: 635/722, Loss: 0.13688384885054342\n",
      "Epoch: 5, Validation_Samples: 640/722, Loss: 0.15650070951242703\n",
      "Epoch: 5, Validation_Samples: 645/722, Loss: 0.11687961319763013\n",
      "Epoch: 5, Validation_Samples: 650/722, Loss: 0.12174157741921042\n",
      "Epoch: 5, Validation_Samples: 655/722, Loss: 0.1516667540731833\n",
      "Epoch: 5, Validation_Samples: 660/722, Loss: 0.1412549747217067\n",
      "Epoch: 5, Validation_Samples: 665/722, Loss: 0.1266489883555705\n",
      "Epoch: 5, Validation_Samples: 670/722, Loss: 0.10405911540265562\n",
      "Epoch: 5, Validation_Samples: 675/722, Loss: 0.10958153101981569\n",
      "Epoch: 5, Validation_Samples: 680/722, Loss: 0.15906747962959483\n",
      "Epoch: 5, Validation_Samples: 685/722, Loss: 0.13733010744146346\n",
      "Epoch: 5, Validation_Samples: 690/722, Loss: 0.13284962636699515\n",
      "Epoch: 5, Validation_Samples: 695/722, Loss: 0.10800682987608877\n",
      "Epoch: 5, Validation_Samples: 700/722, Loss: 0.1546417445523278\n",
      "Epoch: 5, Validation_Samples: 705/722, Loss: 0.17036597387930313\n",
      "Epoch: 5, Validation_Samples: 710/722, Loss: 0.1618761056091699\n",
      "Epoch: 5, Validation_Samples: 715/722, Loss: 0.12674496759845125\n",
      "Epoch: 5, Validation_Samples: 720/722, Loss: 0.1449855703615354\n",
      "\n",
      "Epoch: 5\n",
      "Validation set: Average loss: 0.1379, AP: 0.5929)\n",
      "Epoch: 6, Training_Samples: 0/358, Loss: 0.11539295395395868\n",
      "Epoch: 6, Training_Samples: 5/358, Loss: 0.15301943920191702\n",
      "Epoch: 6, Training_Samples: 10/358, Loss: 0.15157351605974367\n",
      "Epoch: 6, Training_Samples: 15/358, Loss: 0.15119218016801156\n",
      "Epoch: 6, Training_Samples: 20/358, Loss: 0.16212328412314295\n",
      "Epoch: 6, Training_Samples: 25/358, Loss: 0.13314393628991658\n",
      "Epoch: 6, Training_Samples: 30/358, Loss: 0.12550343684438148\n",
      "Epoch: 6, Training_Samples: 35/358, Loss: 0.12162132616235229\n",
      "Epoch: 6, Training_Samples: 40/358, Loss: 0.13218876606095428\n",
      "Epoch: 6, Training_Samples: 45/358, Loss: 0.12675994573331528\n",
      "Epoch: 6, Training_Samples: 50/358, Loss: 0.16691281511475564\n",
      "Epoch: 6, Training_Samples: 55/358, Loss: 0.12555333050828787\n",
      "Epoch: 6, Training_Samples: 60/358, Loss: 0.1300247391845235\n",
      "Epoch: 6, Training_Samples: 65/358, Loss: 0.12377531159648668\n",
      "Epoch: 6, Training_Samples: 70/358, Loss: 0.1387851517518865\n",
      "Epoch: 6, Training_Samples: 75/358, Loss: 0.1483548596107048\n",
      "Epoch: 6, Training_Samples: 80/358, Loss: 0.14800011712835284\n",
      "Epoch: 6, Training_Samples: 85/358, Loss: 0.17252719251053847\n",
      "Epoch: 6, Training_Samples: 90/358, Loss: 0.17126152018640706\n",
      "Epoch: 6, Training_Samples: 95/358, Loss: 0.11713320221307218\n",
      "Epoch: 6, Training_Samples: 100/358, Loss: 0.15075908914990294\n",
      "Epoch: 6, Training_Samples: 105/358, Loss: 0.13914670662395984\n",
      "Epoch: 6, Training_Samples: 110/358, Loss: 0.16521626636686348\n",
      "Epoch: 6, Training_Samples: 115/358, Loss: 0.11838776112823785\n",
      "Epoch: 6, Training_Samples: 120/358, Loss: 0.1372432256184702\n",
      "Epoch: 6, Training_Samples: 125/358, Loss: 0.11765828206963604\n",
      "Epoch: 6, Training_Samples: 130/358, Loss: 0.12638127483244788\n",
      "Epoch: 6, Training_Samples: 135/358, Loss: 0.14574085310288692\n",
      "Epoch: 6, Training_Samples: 140/358, Loss: 0.15646587463373804\n",
      "Epoch: 6, Training_Samples: 145/358, Loss: 0.149547398845411\n",
      "Epoch: 6, Training_Samples: 150/358, Loss: 0.12097167771262315\n",
      "Epoch: 6, Training_Samples: 155/358, Loss: 0.12354550550096022\n",
      "Epoch: 6, Training_Samples: 160/358, Loss: 0.14538385972006757\n",
      "Epoch: 6, Training_Samples: 165/358, Loss: 0.16411092563684485\n",
      "Epoch: 6, Training_Samples: 170/358, Loss: 0.1318431284687156\n",
      "Epoch: 6, Training_Samples: 175/358, Loss: 0.12798531320232664\n",
      "Epoch: 6, Training_Samples: 180/358, Loss: 0.13183766066897823\n",
      "Epoch: 6, Training_Samples: 185/358, Loss: 0.1464316291064604\n",
      "Epoch: 6, Training_Samples: 190/358, Loss: 0.12599224251776547\n",
      "Epoch: 6, Training_Samples: 195/358, Loss: 0.13498176990137042\n",
      "Epoch: 6, Training_Samples: 200/358, Loss: 0.13662585799181945\n",
      "Epoch: 6, Training_Samples: 205/358, Loss: 0.15918329982201535\n",
      "Epoch: 6, Training_Samples: 210/358, Loss: 0.11851329301254897\n",
      "Epoch: 6, Training_Samples: 215/358, Loss: 0.13746908197417124\n",
      "Epoch: 6, Training_Samples: 220/358, Loss: 0.14428425380570223\n",
      "Epoch: 6, Training_Samples: 225/358, Loss: 0.14838806332480997\n",
      "Epoch: 6, Training_Samples: 230/358, Loss: 0.1279731444678982\n",
      "Epoch: 6, Training_Samples: 235/358, Loss: 0.13806608011207083\n",
      "Epoch: 6, Training_Samples: 240/358, Loss: 0.16320777126929542\n",
      "Epoch: 6, Training_Samples: 245/358, Loss: 0.11964144225803953\n",
      "Epoch: 6, Training_Samples: 250/358, Loss: 0.1362101929732196\n",
      "Epoch: 6, Training_Samples: 255/358, Loss: 0.1371978255735022\n",
      "Epoch: 6, Training_Samples: 260/358, Loss: 0.1126982446563925\n",
      "Epoch: 6, Training_Samples: 265/358, Loss: 0.18044793725717587\n",
      "Epoch: 6, Training_Samples: 270/358, Loss: 0.1415860669168488\n",
      "Epoch: 6, Training_Samples: 275/358, Loss: 0.14213410521472283\n",
      "Epoch: 6, Training_Samples: 280/358, Loss: 0.11073340903954536\n",
      "Epoch: 6, Training_Samples: 285/358, Loss: 0.14485635624835277\n",
      "Epoch: 6, Training_Samples: 290/358, Loss: 0.13098796476743407\n",
      "Epoch: 6, Training_Samples: 295/358, Loss: 0.1580800584106179\n",
      "Epoch: 6, Training_Samples: 300/358, Loss: 0.14291222255221675\n",
      "Epoch: 6, Training_Samples: 305/358, Loss: 0.1266781112571099\n",
      "Epoch: 6, Training_Samples: 310/358, Loss: 0.11265870598635976\n",
      "Epoch: 6, Training_Samples: 315/358, Loss: 0.12877207950150635\n",
      "Epoch: 6, Training_Samples: 320/358, Loss: 0.1450900475505071\n",
      "Epoch: 6, Training_Samples: 325/358, Loss: 0.11667232798059503\n",
      "Epoch: 6, Training_Samples: 330/358, Loss: 0.14493981476998113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Training_Samples: 335/358, Loss: 0.1450433066391174\n",
      "Epoch: 6, Training_Samples: 340/358, Loss: 0.11406508639924354\n",
      "Epoch: 6, Training_Samples: 345/358, Loss: 0.1223164662497156\n",
      "Epoch: 6, Training_Samples: 350/358, Loss: 0.1302411818173564\n",
      "Epoch: 6, Training_Samples: 355/358, Loss: 0.16209449511894142\n",
      "\n",
      "Epoch: 6\n",
      "Training set: Average loss: 0.1441\n",
      "Epoch: 6, Validation_Samples: 0/722, Loss: 0.13101564271797567\n",
      "Epoch: 6, Validation_Samples: 5/722, Loss: 0.09839177733379152\n",
      "Epoch: 6, Validation_Samples: 10/722, Loss: 0.1311360902023204\n",
      "Epoch: 6, Validation_Samples: 15/722, Loss: 0.11287403347262456\n",
      "Epoch: 6, Validation_Samples: 20/722, Loss: 0.12028803253560827\n",
      "Epoch: 6, Validation_Samples: 25/722, Loss: 0.1833016631531922\n",
      "Epoch: 6, Validation_Samples: 30/722, Loss: 0.13691723994366115\n",
      "Epoch: 6, Validation_Samples: 35/722, Loss: 0.14089243214874075\n",
      "Epoch: 6, Validation_Samples: 40/722, Loss: 0.12725387116254513\n",
      "Epoch: 6, Validation_Samples: 45/722, Loss: 0.14607692111069284\n",
      "Epoch: 6, Validation_Samples: 50/722, Loss: 0.1420883499465849\n",
      "Epoch: 6, Validation_Samples: 55/722, Loss: 0.11508229472847988\n",
      "Epoch: 6, Validation_Samples: 60/722, Loss: 0.1497342436069137\n",
      "Epoch: 6, Validation_Samples: 65/722, Loss: 0.13643127626573004\n",
      "Epoch: 6, Validation_Samples: 70/722, Loss: 0.12114665179584946\n",
      "Epoch: 6, Validation_Samples: 75/722, Loss: 0.15226670299738326\n",
      "Epoch: 6, Validation_Samples: 80/722, Loss: 0.1258318320975638\n",
      "Epoch: 6, Validation_Samples: 85/722, Loss: 0.11397109328545627\n",
      "Epoch: 6, Validation_Samples: 90/722, Loss: 0.12292382766143779\n",
      "Epoch: 6, Validation_Samples: 95/722, Loss: 0.11896247493230581\n",
      "Epoch: 6, Validation_Samples: 100/722, Loss: 0.14666885464741652\n",
      "Epoch: 6, Validation_Samples: 105/722, Loss: 0.13427520259644088\n",
      "Epoch: 6, Validation_Samples: 110/722, Loss: 0.14131782089402908\n",
      "Epoch: 6, Validation_Samples: 115/722, Loss: 0.14121783374076854\n",
      "Epoch: 6, Validation_Samples: 120/722, Loss: 0.11848351008851186\n",
      "Epoch: 6, Validation_Samples: 125/722, Loss: 0.13472800035468346\n",
      "Epoch: 6, Validation_Samples: 130/722, Loss: 0.16100340232685967\n",
      "Epoch: 6, Validation_Samples: 135/722, Loss: 0.11132792891566784\n",
      "Epoch: 6, Validation_Samples: 140/722, Loss: 0.15095699400815588\n",
      "Epoch: 6, Validation_Samples: 145/722, Loss: 0.13467849639671153\n",
      "Epoch: 6, Validation_Samples: 150/722, Loss: 0.1358968810914434\n",
      "Epoch: 6, Validation_Samples: 155/722, Loss: 0.13494265653798762\n",
      "Epoch: 6, Validation_Samples: 160/722, Loss: 0.10390257114589958\n",
      "Epoch: 6, Validation_Samples: 165/722, Loss: 0.12917778501782667\n",
      "Epoch: 6, Validation_Samples: 170/722, Loss: 0.1250699010728069\n",
      "Epoch: 6, Validation_Samples: 175/722, Loss: 0.13502868003753052\n",
      "Epoch: 6, Validation_Samples: 180/722, Loss: 0.10316940170335097\n",
      "Epoch: 6, Validation_Samples: 185/722, Loss: 0.12227795352755672\n",
      "Epoch: 6, Validation_Samples: 190/722, Loss: 0.14288124006685957\n",
      "Epoch: 6, Validation_Samples: 195/722, Loss: 0.17363131973359078\n",
      "Epoch: 6, Validation_Samples: 200/722, Loss: 0.10475940473513952\n",
      "Epoch: 6, Validation_Samples: 205/722, Loss: 0.1379958377698347\n",
      "Epoch: 6, Validation_Samples: 210/722, Loss: 0.12570637439819002\n",
      "Epoch: 6, Validation_Samples: 215/722, Loss: 0.12631445850923778\n",
      "Epoch: 6, Validation_Samples: 220/722, Loss: 0.18883590618087276\n",
      "Epoch: 6, Validation_Samples: 225/722, Loss: 0.14102798618642054\n",
      "Epoch: 6, Validation_Samples: 230/722, Loss: 0.13099200666335764\n",
      "Epoch: 6, Validation_Samples: 235/722, Loss: 0.14066901057041925\n",
      "Epoch: 6, Validation_Samples: 240/722, Loss: 0.11192454852914287\n",
      "Epoch: 6, Validation_Samples: 245/722, Loss: 0.1362443130499985\n",
      "Epoch: 6, Validation_Samples: 250/722, Loss: 0.11751837516332765\n",
      "Epoch: 6, Validation_Samples: 255/722, Loss: 0.12709293673405286\n",
      "Epoch: 6, Validation_Samples: 260/722, Loss: 0.11393829457589617\n",
      "Epoch: 6, Validation_Samples: 265/722, Loss: 0.10898104676538918\n",
      "Epoch: 6, Validation_Samples: 270/722, Loss: 0.13388606585830465\n",
      "Epoch: 6, Validation_Samples: 275/722, Loss: 0.11420855347459374\n",
      "Epoch: 6, Validation_Samples: 280/722, Loss: 0.14712474476772675\n",
      "Epoch: 6, Validation_Samples: 285/722, Loss: 0.14088832828762346\n",
      "Epoch: 6, Validation_Samples: 290/722, Loss: 0.1389081773074136\n",
      "Epoch: 6, Validation_Samples: 295/722, Loss: 0.1677128609362694\n",
      "Epoch: 6, Validation_Samples: 300/722, Loss: 0.19190862508297038\n",
      "Epoch: 6, Validation_Samples: 305/722, Loss: 0.13111657685668793\n",
      "Epoch: 6, Validation_Samples: 310/722, Loss: 0.10246456133825572\n",
      "Epoch: 6, Validation_Samples: 315/722, Loss: 0.11492844939983814\n",
      "Epoch: 6, Validation_Samples: 320/722, Loss: 0.1210298399095817\n",
      "Epoch: 6, Validation_Samples: 325/722, Loss: 0.14649501025503397\n",
      "Epoch: 6, Validation_Samples: 330/722, Loss: 0.16011297982921954\n",
      "Epoch: 6, Validation_Samples: 335/722, Loss: 0.13338670509056805\n",
      "Epoch: 6, Validation_Samples: 340/722, Loss: 0.14397450477816007\n",
      "Epoch: 6, Validation_Samples: 345/722, Loss: 0.1401954316830251\n",
      "Epoch: 6, Validation_Samples: 350/722, Loss: 0.14494337848132297\n",
      "Epoch: 6, Validation_Samples: 355/722, Loss: 0.15914644436548342\n",
      "Epoch: 6, Validation_Samples: 360/722, Loss: 0.1538412044124327\n",
      "Epoch: 6, Validation_Samples: 365/722, Loss: 0.09458404483927095\n",
      "Epoch: 6, Validation_Samples: 370/722, Loss: 0.11244588764922209\n",
      "Epoch: 6, Validation_Samples: 375/722, Loss: 0.1687152520573642\n",
      "Epoch: 6, Validation_Samples: 380/722, Loss: 0.11121831309874398\n",
      "Epoch: 6, Validation_Samples: 385/722, Loss: 0.12126213637489747\n",
      "Epoch: 6, Validation_Samples: 390/722, Loss: 0.16323713383760802\n",
      "Epoch: 6, Validation_Samples: 395/722, Loss: 0.11160718058651765\n",
      "Epoch: 6, Validation_Samples: 400/722, Loss: 0.14043048245567932\n",
      "Epoch: 6, Validation_Samples: 405/722, Loss: 0.11144744188891752\n",
      "Epoch: 6, Validation_Samples: 410/722, Loss: 0.1939761427032\n",
      "Epoch: 6, Validation_Samples: 415/722, Loss: 0.11617516941042955\n",
      "Epoch: 6, Validation_Samples: 420/722, Loss: 0.15026786978704762\n",
      "Epoch: 6, Validation_Samples: 425/722, Loss: 0.14456072160254083\n",
      "Epoch: 6, Validation_Samples: 430/722, Loss: 0.10789821215876534\n",
      "Epoch: 6, Validation_Samples: 435/722, Loss: 0.12638644371865254\n",
      "Epoch: 6, Validation_Samples: 440/722, Loss: 0.13032138630622792\n",
      "Epoch: 6, Validation_Samples: 445/722, Loss: 0.11961729944178824\n",
      "Epoch: 6, Validation_Samples: 450/722, Loss: 0.11657889251057763\n",
      "Epoch: 6, Validation_Samples: 455/722, Loss: 0.13145601630583345\n",
      "Epoch: 6, Validation_Samples: 460/722, Loss: 0.1410879402326689\n",
      "Epoch: 6, Validation_Samples: 465/722, Loss: 0.133231465354824\n",
      "Epoch: 6, Validation_Samples: 470/722, Loss: 0.12323616873500337\n",
      "Epoch: 6, Validation_Samples: 475/722, Loss: 0.16251378585823278\n",
      "Epoch: 6, Validation_Samples: 480/722, Loss: 0.11993005663119585\n",
      "Epoch: 6, Validation_Samples: 485/722, Loss: 0.1009327031865554\n",
      "Epoch: 6, Validation_Samples: 490/722, Loss: 0.15662928587322691\n",
      "Epoch: 6, Validation_Samples: 495/722, Loss: 0.1410211377225917\n",
      "Epoch: 6, Validation_Samples: 500/722, Loss: 0.13128283079835262\n",
      "Epoch: 6, Validation_Samples: 505/722, Loss: 0.10401377955328074\n",
      "Epoch: 6, Validation_Samples: 510/722, Loss: 0.14040656333820253\n",
      "Epoch: 6, Validation_Samples: 515/722, Loss: 0.14296002240903996\n",
      "Epoch: 6, Validation_Samples: 520/722, Loss: 0.12725021461798633\n",
      "Epoch: 6, Validation_Samples: 525/722, Loss: 0.10653631218437196\n",
      "Epoch: 6, Validation_Samples: 530/722, Loss: 0.12276617580555557\n",
      "Epoch: 6, Validation_Samples: 535/722, Loss: 0.10578635200618333\n",
      "Epoch: 6, Validation_Samples: 540/722, Loss: 0.12254237340269739\n",
      "Epoch: 6, Validation_Samples: 545/722, Loss: 0.1667390623503277\n",
      "Epoch: 6, Validation_Samples: 550/722, Loss: 0.13592441182971518\n",
      "Epoch: 6, Validation_Samples: 555/722, Loss: 0.12279446073067848\n",
      "Epoch: 6, Validation_Samples: 560/722, Loss: 0.15660439218900712\n",
      "Epoch: 6, Validation_Samples: 565/722, Loss: 0.16899800408015223\n",
      "Epoch: 6, Validation_Samples: 570/722, Loss: 0.16127880820057905\n",
      "Epoch: 6, Validation_Samples: 575/722, Loss: 0.1358730635861723\n",
      "Epoch: 6, Validation_Samples: 580/722, Loss: 0.11117001998000849\n",
      "Epoch: 6, Validation_Samples: 585/722, Loss: 0.1667070679869799\n",
      "Epoch: 6, Validation_Samples: 590/722, Loss: 0.10514811360512491\n",
      "Epoch: 6, Validation_Samples: 595/722, Loss: 0.14900950911994346\n",
      "Epoch: 6, Validation_Samples: 600/722, Loss: 0.15182131626555967\n",
      "Epoch: 6, Validation_Samples: 605/722, Loss: 0.1418456105572645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Validation_Samples: 610/722, Loss: 0.1380354005646695\n",
      "Epoch: 6, Validation_Samples: 615/722, Loss: 0.11106724961603122\n",
      "Epoch: 6, Validation_Samples: 620/722, Loss: 0.09576434927203362\n",
      "Epoch: 6, Validation_Samples: 625/722, Loss: 0.1273489265878059\n",
      "Epoch: 6, Validation_Samples: 630/722, Loss: 0.12685811658633916\n",
      "Epoch: 6, Validation_Samples: 635/722, Loss: 0.13506454139232793\n",
      "Epoch: 6, Validation_Samples: 640/722, Loss: 0.1341939832238806\n",
      "Epoch: 6, Validation_Samples: 645/722, Loss: 0.12594650762758425\n",
      "Epoch: 6, Validation_Samples: 650/722, Loss: 0.12924210928368002\n",
      "Epoch: 6, Validation_Samples: 655/722, Loss: 0.13038756527300377\n",
      "Epoch: 6, Validation_Samples: 660/722, Loss: 0.11324417945196966\n",
      "Epoch: 6, Validation_Samples: 665/722, Loss: 0.1572182522088622\n",
      "Epoch: 6, Validation_Samples: 670/722, Loss: 0.13555330431982412\n",
      "Epoch: 6, Validation_Samples: 675/722, Loss: 0.09132521421695154\n",
      "Epoch: 6, Validation_Samples: 680/722, Loss: 0.1607300837933523\n",
      "Epoch: 6, Validation_Samples: 685/722, Loss: 0.12987689011670495\n",
      "Epoch: 6, Validation_Samples: 690/722, Loss: 0.13428131737424798\n",
      "Epoch: 6, Validation_Samples: 695/722, Loss: 0.13222013659823886\n",
      "Epoch: 6, Validation_Samples: 700/722, Loss: 0.15181722323484187\n",
      "Epoch: 6, Validation_Samples: 705/722, Loss: 0.14455830927949437\n",
      "Epoch: 6, Validation_Samples: 710/722, Loss: 0.12222806121370425\n",
      "Epoch: 6, Validation_Samples: 715/722, Loss: 0.14271148265832825\n",
      "Epoch: 6, Validation_Samples: 720/722, Loss: 0.1505608976754863\n",
      "\n",
      "Epoch: 6\n",
      "Validation set: Average loss: 0.1318, AP: 0.6147)\n",
      "Epoch: 7, Training_Samples: 0/358, Loss: 0.1417152151022147\n",
      "Epoch: 7, Training_Samples: 5/358, Loss: 0.12922094436067338\n",
      "Epoch: 7, Training_Samples: 10/358, Loss: 0.14050371131435238\n",
      "Epoch: 7, Training_Samples: 15/358, Loss: 0.12671576385047142\n",
      "Epoch: 7, Training_Samples: 20/358, Loss: 0.1513530622976473\n",
      "Epoch: 7, Training_Samples: 25/358, Loss: 0.14624546476505718\n",
      "Epoch: 7, Training_Samples: 30/358, Loss: 0.14457318971971025\n",
      "Epoch: 7, Training_Samples: 35/358, Loss: 0.11994428716022155\n",
      "Epoch: 7, Training_Samples: 40/358, Loss: 0.14906725006650756\n",
      "Epoch: 7, Training_Samples: 45/358, Loss: 0.11851538852948224\n",
      "Epoch: 7, Training_Samples: 50/358, Loss: 0.18860635778594453\n",
      "Epoch: 7, Training_Samples: 55/358, Loss: 0.12404436262799463\n",
      "Epoch: 7, Training_Samples: 60/358, Loss: 0.1602706873417218\n",
      "Epoch: 7, Training_Samples: 65/358, Loss: 0.1354593868707221\n",
      "Epoch: 7, Training_Samples: 70/358, Loss: 0.13999038818674533\n",
      "Epoch: 7, Training_Samples: 75/358, Loss: 0.11035090557851546\n",
      "Epoch: 7, Training_Samples: 80/358, Loss: 0.12661251827705153\n",
      "Epoch: 7, Training_Samples: 85/358, Loss: 0.19887093909301384\n",
      "Epoch: 7, Training_Samples: 90/358, Loss: 0.11121549911018037\n",
      "Epoch: 7, Training_Samples: 95/358, Loss: 0.14736016447345618\n",
      "Epoch: 7, Training_Samples: 100/358, Loss: 0.129947850312115\n",
      "Epoch: 7, Training_Samples: 105/358, Loss: 0.10934143134786607\n",
      "Epoch: 7, Training_Samples: 110/358, Loss: 0.13577151119068767\n",
      "Epoch: 7, Training_Samples: 115/358, Loss: 0.17350542291452511\n",
      "Epoch: 7, Training_Samples: 120/358, Loss: 0.18102018219982222\n",
      "Epoch: 7, Training_Samples: 125/358, Loss: 0.14170316441892702\n",
      "Epoch: 7, Training_Samples: 130/358, Loss: 0.13820754073275776\n",
      "Epoch: 7, Training_Samples: 135/358, Loss: 0.13373374321335507\n",
      "Epoch: 7, Training_Samples: 140/358, Loss: 0.14393342483654598\n",
      "Epoch: 7, Training_Samples: 145/358, Loss: 0.15791722565419675\n",
      "Epoch: 7, Training_Samples: 150/358, Loss: 0.11113549807309389\n",
      "Epoch: 7, Training_Samples: 155/358, Loss: 0.14610144848077297\n",
      "Epoch: 7, Training_Samples: 160/358, Loss: 0.1645422330841574\n",
      "Epoch: 7, Training_Samples: 165/358, Loss: 0.1256170040747829\n",
      "Epoch: 7, Training_Samples: 170/358, Loss: 0.10177245695571392\n",
      "Epoch: 7, Training_Samples: 175/358, Loss: 0.16553251075391437\n",
      "Epoch: 7, Training_Samples: 180/358, Loss: 0.135304304617626\n",
      "Epoch: 7, Training_Samples: 185/358, Loss: 0.12813496059567403\n",
      "Epoch: 7, Training_Samples: 190/358, Loss: 0.11286100347816924\n",
      "Epoch: 7, Training_Samples: 195/358, Loss: 0.15047145470391504\n",
      "Epoch: 7, Training_Samples: 200/358, Loss: 0.11609830946741083\n",
      "Epoch: 7, Training_Samples: 205/358, Loss: 0.16408542097376586\n",
      "Epoch: 7, Training_Samples: 210/358, Loss: 0.12146327338491959\n",
      "Epoch: 7, Training_Samples: 215/358, Loss: 0.11141378615266462\n",
      "Epoch: 7, Training_Samples: 220/358, Loss: 0.15768621564887408\n",
      "Epoch: 7, Training_Samples: 225/358, Loss: 0.14693096827933635\n",
      "Epoch: 7, Training_Samples: 230/358, Loss: 0.12584371902669178\n",
      "Epoch: 7, Training_Samples: 235/358, Loss: 0.14151243961654453\n",
      "Epoch: 7, Training_Samples: 240/358, Loss: 0.12202494681292292\n",
      "Epoch: 7, Training_Samples: 245/358, Loss: 0.12493921995356154\n",
      "Epoch: 7, Training_Samples: 250/358, Loss: 0.1147131673393783\n",
      "Epoch: 7, Training_Samples: 255/358, Loss: 0.12508460147345074\n",
      "Epoch: 7, Training_Samples: 260/358, Loss: 0.1308487238708271\n",
      "Epoch: 7, Training_Samples: 265/358, Loss: 0.12551507109905186\n",
      "Epoch: 7, Training_Samples: 270/358, Loss: 0.16680643389132144\n",
      "Epoch: 7, Training_Samples: 275/358, Loss: 0.14863326402265317\n",
      "Epoch: 7, Training_Samples: 280/358, Loss: 0.13929200257785865\n",
      "Epoch: 7, Training_Samples: 285/358, Loss: 0.15964092380814404\n",
      "Epoch: 7, Training_Samples: 290/358, Loss: 0.13747785477302127\n",
      "Epoch: 7, Training_Samples: 295/358, Loss: 0.163365095629864\n",
      "Epoch: 7, Training_Samples: 300/358, Loss: 0.10787534336980534\n",
      "Epoch: 7, Training_Samples: 305/358, Loss: 0.13774649246009948\n",
      "Epoch: 7, Training_Samples: 310/358, Loss: 0.1328307158427364\n",
      "Epoch: 7, Training_Samples: 315/358, Loss: 0.10797807323816662\n",
      "Epoch: 7, Training_Samples: 320/358, Loss: 0.1270124021707681\n",
      "Epoch: 7, Training_Samples: 325/358, Loss: 0.13569118392475896\n",
      "Epoch: 7, Training_Samples: 330/358, Loss: 0.1308476526295707\n",
      "Epoch: 7, Training_Samples: 335/358, Loss: 0.13363828710892417\n",
      "Epoch: 7, Training_Samples: 340/358, Loss: 0.11401556870153495\n",
      "Epoch: 7, Training_Samples: 345/358, Loss: 0.15748108173954278\n",
      "Epoch: 7, Training_Samples: 350/358, Loss: 0.17827260839641745\n",
      "Epoch: 7, Training_Samples: 355/358, Loss: 0.1085464593479857\n",
      "\n",
      "Epoch: 7\n",
      "Training set: Average loss: 0.1377\n",
      "Epoch: 7, Validation_Samples: 0/722, Loss: 0.11601629223260798\n",
      "Epoch: 7, Validation_Samples: 5/722, Loss: 0.11719989211524354\n",
      "Epoch: 7, Validation_Samples: 10/722, Loss: 0.14545454288629772\n",
      "Epoch: 7, Validation_Samples: 15/722, Loss: 0.16172843259406236\n",
      "Epoch: 7, Validation_Samples: 20/722, Loss: 0.1276111701968888\n",
      "Epoch: 7, Validation_Samples: 25/722, Loss: 0.10262826894091771\n",
      "Epoch: 7, Validation_Samples: 30/722, Loss: 0.1419660829407551\n",
      "Epoch: 7, Validation_Samples: 35/722, Loss: 0.1761517601710424\n",
      "Epoch: 7, Validation_Samples: 40/722, Loss: 0.14432555833830513\n",
      "Epoch: 7, Validation_Samples: 45/722, Loss: 0.1376926647107726\n",
      "Epoch: 7, Validation_Samples: 50/722, Loss: 0.12114055574053677\n",
      "Epoch: 7, Validation_Samples: 55/722, Loss: 0.12682377663002692\n",
      "Epoch: 7, Validation_Samples: 60/722, Loss: 0.15545744918219026\n",
      "Epoch: 7, Validation_Samples: 65/722, Loss: 0.12980277001423796\n",
      "Epoch: 7, Validation_Samples: 70/722, Loss: 0.15221689419770115\n",
      "Epoch: 7, Validation_Samples: 75/722, Loss: 0.1315489411977049\n",
      "Epoch: 7, Validation_Samples: 80/722, Loss: 0.12110165950119113\n",
      "Epoch: 7, Validation_Samples: 85/722, Loss: 0.11473445190768801\n",
      "Epoch: 7, Validation_Samples: 90/722, Loss: 0.09368319735549947\n",
      "Epoch: 7, Validation_Samples: 95/722, Loss: 0.1303688382845967\n",
      "Epoch: 7, Validation_Samples: 100/722, Loss: 0.10632267885520445\n",
      "Epoch: 7, Validation_Samples: 105/722, Loss: 0.10181638062400412\n",
      "Epoch: 7, Validation_Samples: 110/722, Loss: 0.1319676697175585\n",
      "Epoch: 7, Validation_Samples: 115/722, Loss: 0.1060021980390411\n",
      "Epoch: 7, Validation_Samples: 120/722, Loss: 0.1095745394039743\n",
      "Epoch: 7, Validation_Samples: 125/722, Loss: 0.12162942816955959\n",
      "Epoch: 7, Validation_Samples: 130/722, Loss: 0.10307499023399998\n",
      "Epoch: 7, Validation_Samples: 135/722, Loss: 0.14813501651028135\n",
      "Epoch: 7, Validation_Samples: 140/722, Loss: 0.12711288330812517\n",
      "Epoch: 7, Validation_Samples: 145/722, Loss: 0.11844326366315218\n",
      "Epoch: 7, Validation_Samples: 150/722, Loss: 0.14065336351346985\n",
      "Epoch: 7, Validation_Samples: 155/722, Loss: 0.1179138858261477\n",
      "Epoch: 7, Validation_Samples: 160/722, Loss: 0.12384422643105042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Validation_Samples: 165/722, Loss: 0.099349406485581\n",
      "Epoch: 7, Validation_Samples: 170/722, Loss: 0.12508504424876568\n",
      "Epoch: 7, Validation_Samples: 175/722, Loss: 0.1436564220792814\n",
      "Epoch: 7, Validation_Samples: 180/722, Loss: 0.17210612454635948\n",
      "Epoch: 7, Validation_Samples: 185/722, Loss: 0.13361015131037557\n",
      "Epoch: 7, Validation_Samples: 190/722, Loss: 0.11261044491139682\n",
      "Epoch: 7, Validation_Samples: 195/722, Loss: 0.13098214502243666\n",
      "Epoch: 7, Validation_Samples: 200/722, Loss: 0.13184125750566375\n",
      "Epoch: 7, Validation_Samples: 205/722, Loss: 0.1329229092489267\n",
      "Epoch: 7, Validation_Samples: 210/722, Loss: 0.14495593555853523\n",
      "Epoch: 7, Validation_Samples: 215/722, Loss: 0.10263220399713283\n",
      "Epoch: 7, Validation_Samples: 220/722, Loss: 0.11218562325561764\n",
      "Epoch: 7, Validation_Samples: 225/722, Loss: 0.1460584380500417\n",
      "Epoch: 7, Validation_Samples: 230/722, Loss: 0.15761622118332902\n",
      "Epoch: 7, Validation_Samples: 235/722, Loss: 0.11719947356504794\n",
      "Epoch: 7, Validation_Samples: 240/722, Loss: 0.1445687555815443\n",
      "Epoch: 7, Validation_Samples: 245/722, Loss: 0.13634336024138027\n",
      "Epoch: 7, Validation_Samples: 250/722, Loss: 0.13981426564161384\n",
      "Epoch: 7, Validation_Samples: 255/722, Loss: 0.12112196041749682\n",
      "Epoch: 7, Validation_Samples: 260/722, Loss: 0.15508627736356495\n",
      "Epoch: 7, Validation_Samples: 265/722, Loss: 0.12420005573302995\n",
      "Epoch: 7, Validation_Samples: 270/722, Loss: 0.1654006977975996\n",
      "Epoch: 7, Validation_Samples: 275/722, Loss: 0.16895339328687656\n",
      "Epoch: 7, Validation_Samples: 280/722, Loss: 0.11412055615624118\n",
      "Epoch: 7, Validation_Samples: 285/722, Loss: 0.11612821582788879\n",
      "Epoch: 7, Validation_Samples: 290/722, Loss: 0.12969329411980188\n",
      "Epoch: 7, Validation_Samples: 295/722, Loss: 0.12696447046890702\n",
      "Epoch: 7, Validation_Samples: 300/722, Loss: 0.09995548049489168\n",
      "Epoch: 7, Validation_Samples: 305/722, Loss: 0.13538872879581404\n",
      "Epoch: 7, Validation_Samples: 310/722, Loss: 0.169309086731264\n",
      "Epoch: 7, Validation_Samples: 315/722, Loss: 0.1181703246785242\n",
      "Epoch: 7, Validation_Samples: 320/722, Loss: 0.12120908871155706\n",
      "Epoch: 7, Validation_Samples: 325/722, Loss: 0.1141469453695968\n",
      "Epoch: 7, Validation_Samples: 330/722, Loss: 0.09731149923823212\n",
      "Epoch: 7, Validation_Samples: 335/722, Loss: 0.11482152705033138\n",
      "Epoch: 7, Validation_Samples: 340/722, Loss: 0.097761185749295\n",
      "Epoch: 7, Validation_Samples: 345/722, Loss: 0.15076998690402926\n",
      "Epoch: 7, Validation_Samples: 350/722, Loss: 0.13328948457984996\n",
      "Epoch: 7, Validation_Samples: 355/722, Loss: 0.1326566137728568\n",
      "Epoch: 7, Validation_Samples: 360/722, Loss: 0.1347032739045775\n",
      "Epoch: 7, Validation_Samples: 365/722, Loss: 0.1130094287560009\n",
      "Epoch: 7, Validation_Samples: 370/722, Loss: 0.13693986436084987\n",
      "Epoch: 7, Validation_Samples: 375/722, Loss: 0.17317592702940088\n",
      "Epoch: 7, Validation_Samples: 380/722, Loss: 0.0997079718614399\n",
      "Epoch: 7, Validation_Samples: 385/722, Loss: 0.10902907041866662\n",
      "Epoch: 7, Validation_Samples: 390/722, Loss: 0.14146481400963193\n",
      "Epoch: 7, Validation_Samples: 395/722, Loss: 0.13927623322497473\n",
      "Epoch: 7, Validation_Samples: 400/722, Loss: 0.10416440832362209\n",
      "Epoch: 7, Validation_Samples: 405/722, Loss: 0.17841748269092203\n",
      "Epoch: 7, Validation_Samples: 410/722, Loss: 0.15481403910514308\n",
      "Epoch: 7, Validation_Samples: 415/722, Loss: 0.12990211609896163\n",
      "Epoch: 7, Validation_Samples: 420/722, Loss: 0.11065613669651622\n",
      "Epoch: 7, Validation_Samples: 425/722, Loss: 0.13545726363602786\n",
      "Epoch: 7, Validation_Samples: 430/722, Loss: 0.14413637312202837\n",
      "Epoch: 7, Validation_Samples: 435/722, Loss: 0.12098041380463025\n",
      "Epoch: 7, Validation_Samples: 440/722, Loss: 0.16319858741139398\n",
      "Epoch: 7, Validation_Samples: 445/722, Loss: 0.13841497957163573\n",
      "Epoch: 7, Validation_Samples: 450/722, Loss: 0.13988657105155794\n",
      "Epoch: 7, Validation_Samples: 455/722, Loss: 0.13517592741220358\n",
      "Epoch: 7, Validation_Samples: 460/722, Loss: 0.16958913674948087\n",
      "Epoch: 7, Validation_Samples: 465/722, Loss: 0.14009104266665565\n",
      "Epoch: 7, Validation_Samples: 470/722, Loss: 0.17212582529401468\n",
      "Epoch: 7, Validation_Samples: 475/722, Loss: 0.1419633341555957\n",
      "Epoch: 7, Validation_Samples: 480/722, Loss: 0.1519245697450352\n",
      "Epoch: 7, Validation_Samples: 485/722, Loss: 0.12043075776485922\n",
      "Epoch: 7, Validation_Samples: 490/722, Loss: 0.10187497931849032\n",
      "Epoch: 7, Validation_Samples: 495/722, Loss: 0.11609771421912676\n",
      "Epoch: 7, Validation_Samples: 500/722, Loss: 0.11119244441922727\n",
      "Epoch: 7, Validation_Samples: 505/722, Loss: 0.12615802646230176\n",
      "Epoch: 7, Validation_Samples: 510/722, Loss: 0.15040882254042856\n",
      "Epoch: 7, Validation_Samples: 515/722, Loss: 0.1509696604933987\n",
      "Epoch: 7, Validation_Samples: 520/722, Loss: 0.16590507852978478\n",
      "Epoch: 7, Validation_Samples: 525/722, Loss: 0.14818090841053705\n",
      "Epoch: 7, Validation_Samples: 530/722, Loss: 0.11563838235053411\n",
      "Epoch: 7, Validation_Samples: 535/722, Loss: 0.09269267566767374\n",
      "Epoch: 7, Validation_Samples: 540/722, Loss: 0.15558833427017746\n",
      "Epoch: 7, Validation_Samples: 545/722, Loss: 0.15401095652279354\n",
      "Epoch: 7, Validation_Samples: 550/722, Loss: 0.1008730599772245\n",
      "Epoch: 7, Validation_Samples: 555/722, Loss: 0.11328306881244296\n",
      "Epoch: 7, Validation_Samples: 560/722, Loss: 0.10328024995100676\n",
      "Epoch: 7, Validation_Samples: 565/722, Loss: 0.11241734707932281\n",
      "Epoch: 7, Validation_Samples: 570/722, Loss: 0.14196937824056136\n",
      "Epoch: 7, Validation_Samples: 575/722, Loss: 0.13076795426686852\n",
      "Epoch: 7, Validation_Samples: 580/722, Loss: 0.1461948740187443\n",
      "Epoch: 7, Validation_Samples: 585/722, Loss: 0.1393185481467254\n",
      "Epoch: 7, Validation_Samples: 590/722, Loss: 0.13133869516009614\n",
      "Epoch: 7, Validation_Samples: 595/722, Loss: 0.16966051359387876\n",
      "Epoch: 7, Validation_Samples: 600/722, Loss: 0.12454397093472688\n",
      "Epoch: 7, Validation_Samples: 605/722, Loss: 0.09994158181893259\n",
      "Epoch: 7, Validation_Samples: 610/722, Loss: 0.10599839842932646\n",
      "Epoch: 7, Validation_Samples: 615/722, Loss: 0.12923836370759212\n",
      "Epoch: 7, Validation_Samples: 620/722, Loss: 0.12633890553328148\n",
      "Epoch: 7, Validation_Samples: 625/722, Loss: 0.1204784601316706\n",
      "Epoch: 7, Validation_Samples: 630/722, Loss: 0.12351248283614813\n",
      "Epoch: 7, Validation_Samples: 635/722, Loss: 0.1273842444125543\n",
      "Epoch: 7, Validation_Samples: 640/722, Loss: 0.1256956266102835\n",
      "Epoch: 7, Validation_Samples: 645/722, Loss: 0.16671463867665134\n",
      "Epoch: 7, Validation_Samples: 650/722, Loss: 0.13585065960367243\n",
      "Epoch: 7, Validation_Samples: 655/722, Loss: 0.12773293874086125\n",
      "Epoch: 7, Validation_Samples: 660/722, Loss: 0.1687485508034808\n",
      "Epoch: 7, Validation_Samples: 665/722, Loss: 0.1271179173624659\n",
      "Epoch: 7, Validation_Samples: 670/722, Loss: 0.1565314454593237\n",
      "Epoch: 7, Validation_Samples: 675/722, Loss: 0.15496325952582812\n",
      "Epoch: 7, Validation_Samples: 680/722, Loss: 0.1159747552069624\n",
      "Epoch: 7, Validation_Samples: 685/722, Loss: 0.12020083458698577\n",
      "Epoch: 7, Validation_Samples: 690/722, Loss: 0.09759283989493367\n",
      "Epoch: 7, Validation_Samples: 695/722, Loss: 0.11534285255491092\n",
      "Epoch: 7, Validation_Samples: 700/722, Loss: 0.13822268054758785\n",
      "Epoch: 7, Validation_Samples: 705/722, Loss: 0.11640571883253076\n",
      "Epoch: 7, Validation_Samples: 710/722, Loss: 0.11400403057545373\n",
      "Epoch: 7, Validation_Samples: 715/722, Loss: 0.11425962897777002\n",
      "Epoch: 7, Validation_Samples: 720/722, Loss: 0.10521343363854327\n",
      "\n",
      "Epoch: 7\n",
      "Validation set: Average loss: 0.1266, AP: 0.6379)\n",
      "Epoch: 8, Training_Samples: 0/358, Loss: 0.13814453179344124\n",
      "Epoch: 8, Training_Samples: 5/358, Loss: 0.1234488689997181\n",
      "Epoch: 8, Training_Samples: 10/358, Loss: 0.11480963119305758\n",
      "Epoch: 8, Training_Samples: 15/358, Loss: 0.10662793731971042\n",
      "Epoch: 8, Training_Samples: 20/358, Loss: 0.13223386963156344\n",
      "Epoch: 8, Training_Samples: 25/358, Loss: 0.12659567215118248\n",
      "Epoch: 8, Training_Samples: 30/358, Loss: 0.13254839230964793\n",
      "Epoch: 8, Training_Samples: 35/358, Loss: 0.15054350043583753\n",
      "Epoch: 8, Training_Samples: 40/358, Loss: 0.14141832214845432\n",
      "Epoch: 8, Training_Samples: 45/358, Loss: 0.13391165868252627\n",
      "Epoch: 8, Training_Samples: 50/358, Loss: 0.12667281867744115\n",
      "Epoch: 8, Training_Samples: 55/358, Loss: 0.12218351814504307\n",
      "Epoch: 8, Training_Samples: 60/358, Loss: 0.14684327805360248\n",
      "Epoch: 8, Training_Samples: 65/358, Loss: 0.13464176184895277\n",
      "Epoch: 8, Training_Samples: 70/358, Loss: 0.1292363388548512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Training_Samples: 75/358, Loss: 0.11433530154869873\n",
      "Epoch: 8, Training_Samples: 80/358, Loss: 0.1431704034658686\n",
      "Epoch: 8, Training_Samples: 85/358, Loss: 0.13369088050057268\n",
      "Epoch: 8, Training_Samples: 90/358, Loss: 0.1284408161348204\n",
      "Epoch: 8, Training_Samples: 95/358, Loss: 0.15391066315521335\n",
      "Epoch: 8, Training_Samples: 100/358, Loss: 0.14344482424166924\n",
      "Epoch: 8, Training_Samples: 105/358, Loss: 0.1414155627966034\n",
      "Epoch: 8, Training_Samples: 110/358, Loss: 0.1255959431569535\n",
      "Epoch: 8, Training_Samples: 115/358, Loss: 0.16735548535975997\n",
      "Epoch: 8, Training_Samples: 120/358, Loss: 0.12990085654755204\n",
      "Epoch: 8, Training_Samples: 125/358, Loss: 0.12027521167564285\n",
      "Epoch: 8, Training_Samples: 130/358, Loss: 0.12690751592495209\n",
      "Epoch: 8, Training_Samples: 135/358, Loss: 0.15535807492286646\n",
      "Epoch: 8, Training_Samples: 140/358, Loss: 0.13608702617243562\n",
      "Epoch: 8, Training_Samples: 145/358, Loss: 0.15514794835157222\n",
      "Epoch: 8, Training_Samples: 150/358, Loss: 0.1460740641002098\n",
      "Epoch: 8, Training_Samples: 155/358, Loss: 0.12331729853070154\n",
      "Epoch: 8, Training_Samples: 160/358, Loss: 0.10650536503743194\n",
      "Epoch: 8, Training_Samples: 165/358, Loss: 0.1309075076278428\n",
      "Epoch: 8, Training_Samples: 170/358, Loss: 0.13277509807465973\n",
      "Epoch: 8, Training_Samples: 175/358, Loss: 0.1313601851210526\n",
      "Epoch: 8, Training_Samples: 180/358, Loss: 0.10907968049538018\n",
      "Epoch: 8, Training_Samples: 185/358, Loss: 0.10883532631074373\n",
      "Epoch: 8, Training_Samples: 190/358, Loss: 0.13742274271329205\n",
      "Epoch: 8, Training_Samples: 195/358, Loss: 0.1414728643531738\n",
      "Epoch: 8, Training_Samples: 200/358, Loss: 0.12200904882847337\n",
      "Epoch: 8, Training_Samples: 205/358, Loss: 0.12863277648022575\n",
      "Epoch: 8, Training_Samples: 210/358, Loss: 0.1301874135581698\n",
      "Epoch: 8, Training_Samples: 215/358, Loss: 0.14194317961700748\n",
      "Epoch: 8, Training_Samples: 220/358, Loss: 0.12169963325097957\n",
      "Epoch: 8, Training_Samples: 225/358, Loss: 0.1287572033632914\n",
      "Epoch: 8, Training_Samples: 230/358, Loss: 0.12182145621756964\n",
      "Epoch: 8, Training_Samples: 235/358, Loss: 0.16317003191086565\n",
      "Epoch: 8, Training_Samples: 240/358, Loss: 0.12796922163965765\n",
      "Epoch: 8, Training_Samples: 245/358, Loss: 0.1257706284925243\n",
      "Epoch: 8, Training_Samples: 250/358, Loss: 0.1689107584501779\n",
      "Epoch: 8, Training_Samples: 255/358, Loss: 0.12007318137082527\n",
      "Epoch: 8, Training_Samples: 260/358, Loss: 0.11873897416036863\n",
      "Epoch: 8, Training_Samples: 265/358, Loss: 0.13792058853404424\n",
      "Epoch: 8, Training_Samples: 270/358, Loss: 0.24325258523699658\n",
      "Epoch: 8, Training_Samples: 275/358, Loss: 0.12534698553762152\n",
      "Epoch: 8, Training_Samples: 280/358, Loss: 0.11230421873714685\n",
      "Epoch: 8, Training_Samples: 285/358, Loss: 0.15098480485188248\n",
      "Epoch: 8, Training_Samples: 290/358, Loss: 0.15002563167419786\n",
      "Epoch: 8, Training_Samples: 295/358, Loss: 0.13566086722955117\n",
      "Epoch: 8, Training_Samples: 300/358, Loss: 0.16317817771879276\n",
      "Epoch: 8, Training_Samples: 305/358, Loss: 0.15064691323632268\n",
      "Epoch: 8, Training_Samples: 310/358, Loss: 0.1503877762839268\n",
      "Epoch: 8, Training_Samples: 315/358, Loss: 0.12663214967973646\n",
      "Epoch: 8, Training_Samples: 320/358, Loss: 0.12744885111416984\n",
      "Epoch: 8, Training_Samples: 325/358, Loss: 0.09564787218468583\n",
      "Epoch: 8, Training_Samples: 330/358, Loss: 0.15209713621348733\n",
      "Epoch: 8, Training_Samples: 335/358, Loss: 0.10044844340131683\n",
      "Epoch: 8, Training_Samples: 340/358, Loss: 0.1350671370682357\n",
      "Epoch: 8, Training_Samples: 345/358, Loss: 0.15051382539024277\n",
      "Epoch: 8, Training_Samples: 350/358, Loss: 0.09219879275241055\n",
      "Epoch: 8, Training_Samples: 355/358, Loss: 0.11520025900248676\n",
      "\n",
      "Epoch: 8\n",
      "Training set: Average loss: 0.1338\n",
      "Epoch: 8, Validation_Samples: 0/722, Loss: 0.11909527362423153\n",
      "Epoch: 8, Validation_Samples: 5/722, Loss: 0.10818478559822278\n",
      "Epoch: 8, Validation_Samples: 10/722, Loss: 0.16138908503034938\n",
      "Epoch: 8, Validation_Samples: 15/722, Loss: 0.13388562512671529\n",
      "Epoch: 8, Validation_Samples: 20/722, Loss: 0.14943838839571846\n",
      "Epoch: 8, Validation_Samples: 25/722, Loss: 0.13789606438830476\n",
      "Epoch: 8, Validation_Samples: 30/722, Loss: 0.11874756234488816\n",
      "Epoch: 8, Validation_Samples: 35/722, Loss: 0.15089594214194138\n",
      "Epoch: 8, Validation_Samples: 40/722, Loss: 0.12203183273456444\n",
      "Epoch: 8, Validation_Samples: 45/722, Loss: 0.12930667726182998\n",
      "Epoch: 8, Validation_Samples: 50/722, Loss: 0.1442720753829723\n",
      "Epoch: 8, Validation_Samples: 55/722, Loss: 0.13796726868700324\n",
      "Epoch: 8, Validation_Samples: 60/722, Loss: 0.12008918122059287\n",
      "Epoch: 8, Validation_Samples: 65/722, Loss: 0.1177978848331809\n",
      "Epoch: 8, Validation_Samples: 70/722, Loss: 0.09344794198564256\n",
      "Epoch: 8, Validation_Samples: 75/722, Loss: 0.13685195450960455\n",
      "Epoch: 8, Validation_Samples: 80/722, Loss: 0.13168684410553144\n",
      "Epoch: 8, Validation_Samples: 85/722, Loss: 0.13295102198669112\n",
      "Epoch: 8, Validation_Samples: 90/722, Loss: 0.1063306859060703\n",
      "Epoch: 8, Validation_Samples: 95/722, Loss: 0.09527824901055175\n",
      "Epoch: 8, Validation_Samples: 100/722, Loss: 0.12905093971891854\n",
      "Epoch: 8, Validation_Samples: 105/722, Loss: 0.2120585179576362\n",
      "Epoch: 8, Validation_Samples: 110/722, Loss: 0.07563131179307983\n",
      "Epoch: 8, Validation_Samples: 115/722, Loss: 0.08871260242273571\n",
      "Epoch: 8, Validation_Samples: 120/722, Loss: 0.1380826868217325\n",
      "Epoch: 8, Validation_Samples: 125/722, Loss: 0.13040849571699506\n",
      "Epoch: 8, Validation_Samples: 130/722, Loss: 0.13348109050016696\n",
      "Epoch: 8, Validation_Samples: 135/722, Loss: 0.10206921248150316\n",
      "Epoch: 8, Validation_Samples: 140/722, Loss: 0.14606274384049536\n",
      "Epoch: 8, Validation_Samples: 145/722, Loss: 0.1499110876643892\n",
      "Epoch: 8, Validation_Samples: 150/722, Loss: 0.10040367355251306\n",
      "Epoch: 8, Validation_Samples: 155/722, Loss: 0.10545861712347138\n",
      "Epoch: 8, Validation_Samples: 160/722, Loss: 0.09403365708189759\n",
      "Epoch: 8, Validation_Samples: 165/722, Loss: 0.10062137708026113\n",
      "Epoch: 8, Validation_Samples: 170/722, Loss: 0.09943486160422321\n",
      "Epoch: 8, Validation_Samples: 175/722, Loss: 0.10787765811880265\n",
      "Epoch: 8, Validation_Samples: 180/722, Loss: 0.13244001987331763\n",
      "Epoch: 8, Validation_Samples: 185/722, Loss: 0.12114560552986366\n",
      "Epoch: 8, Validation_Samples: 190/722, Loss: 0.11850192809391552\n",
      "Epoch: 8, Validation_Samples: 195/722, Loss: 0.1285136104048133\n",
      "Epoch: 8, Validation_Samples: 200/722, Loss: 0.10838273168787295\n",
      "Epoch: 8, Validation_Samples: 205/722, Loss: 0.1717348711000378\n",
      "Epoch: 8, Validation_Samples: 210/722, Loss: 0.12634639200792594\n",
      "Epoch: 8, Validation_Samples: 215/722, Loss: 0.12384950843638791\n",
      "Epoch: 8, Validation_Samples: 220/722, Loss: 0.1081022654917865\n",
      "Epoch: 8, Validation_Samples: 225/722, Loss: 0.10372870566547235\n",
      "Epoch: 8, Validation_Samples: 230/722, Loss: 0.16058040315056069\n",
      "Epoch: 8, Validation_Samples: 235/722, Loss: 0.13502098876750446\n",
      "Epoch: 8, Validation_Samples: 240/722, Loss: 0.13637270256979747\n",
      "Epoch: 8, Validation_Samples: 245/722, Loss: 0.18175464082584586\n",
      "Epoch: 8, Validation_Samples: 250/722, Loss: 0.1422893312127311\n",
      "Epoch: 8, Validation_Samples: 255/722, Loss: 0.12969950728247268\n",
      "Epoch: 8, Validation_Samples: 260/722, Loss: 0.09461252878384735\n",
      "Epoch: 8, Validation_Samples: 265/722, Loss: 0.11422845381586645\n",
      "Epoch: 8, Validation_Samples: 270/722, Loss: 0.1251799600358467\n",
      "Epoch: 8, Validation_Samples: 275/722, Loss: 0.0962043312109124\n",
      "Epoch: 8, Validation_Samples: 280/722, Loss: 0.16947225918869066\n",
      "Epoch: 8, Validation_Samples: 285/722, Loss: 0.13558819396009944\n",
      "Epoch: 8, Validation_Samples: 290/722, Loss: 0.10324506017347361\n",
      "Epoch: 8, Validation_Samples: 295/722, Loss: 0.11428438535625478\n",
      "Epoch: 8, Validation_Samples: 300/722, Loss: 0.13769158001367834\n",
      "Epoch: 8, Validation_Samples: 305/722, Loss: 0.1356886691156643\n",
      "Epoch: 8, Validation_Samples: 310/722, Loss: 0.10556924207162086\n",
      "Epoch: 8, Validation_Samples: 315/722, Loss: 0.13556331303800043\n",
      "Epoch: 8, Validation_Samples: 320/722, Loss: 0.13910543120701127\n",
      "Epoch: 8, Validation_Samples: 325/722, Loss: 0.132451037530225\n",
      "Epoch: 8, Validation_Samples: 330/722, Loss: 0.0916068409712229\n",
      "Epoch: 8, Validation_Samples: 335/722, Loss: 0.1364183373173346\n",
      "Epoch: 8, Validation_Samples: 340/722, Loss: 0.11942721677596227\n",
      "Epoch: 8, Validation_Samples: 345/722, Loss: 0.08079491570710513\n",
      "Epoch: 8, Validation_Samples: 350/722, Loss: 0.1037132705071037\n",
      "Epoch: 8, Validation_Samples: 355/722, Loss: 0.15250627425654126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Validation_Samples: 360/722, Loss: 0.1432307662968859\n",
      "Epoch: 8, Validation_Samples: 365/722, Loss: 0.15383501940962827\n",
      "Epoch: 8, Validation_Samples: 370/722, Loss: 0.1385158079869079\n",
      "Epoch: 8, Validation_Samples: 375/722, Loss: 0.13411082403351585\n",
      "Epoch: 8, Validation_Samples: 380/722, Loss: 0.1589844605261545\n",
      "Epoch: 8, Validation_Samples: 385/722, Loss: 0.12792743587248248\n",
      "Epoch: 8, Validation_Samples: 390/722, Loss: 0.10890168497621305\n",
      "Epoch: 8, Validation_Samples: 395/722, Loss: 0.19246015126597474\n",
      "Epoch: 8, Validation_Samples: 400/722, Loss: 0.12570502111734735\n",
      "Epoch: 8, Validation_Samples: 405/722, Loss: 0.13907394144770244\n",
      "Epoch: 8, Validation_Samples: 410/722, Loss: 0.10773652572202555\n",
      "Epoch: 8, Validation_Samples: 415/722, Loss: 0.12043765905587005\n",
      "Epoch: 8, Validation_Samples: 420/722, Loss: 0.10252823321954797\n",
      "Epoch: 8, Validation_Samples: 425/722, Loss: 0.12458270143052955\n",
      "Epoch: 8, Validation_Samples: 430/722, Loss: 0.1101426989877636\n",
      "Epoch: 8, Validation_Samples: 435/722, Loss: 0.1458490667026045\n",
      "Epoch: 8, Validation_Samples: 440/722, Loss: 0.11958233884901075\n",
      "Epoch: 8, Validation_Samples: 445/722, Loss: 0.11947293451780254\n",
      "Epoch: 8, Validation_Samples: 450/722, Loss: 0.10774395132146025\n",
      "Epoch: 8, Validation_Samples: 455/722, Loss: 0.16665256327927233\n",
      "Epoch: 8, Validation_Samples: 460/722, Loss: 0.10892425655330498\n",
      "Epoch: 8, Validation_Samples: 465/722, Loss: 0.12013842675964766\n",
      "Epoch: 8, Validation_Samples: 470/722, Loss: 0.06347761944118001\n",
      "Epoch: 8, Validation_Samples: 475/722, Loss: 0.09562807601539168\n",
      "Epoch: 8, Validation_Samples: 480/722, Loss: 0.1082245380992852\n",
      "Epoch: 8, Validation_Samples: 485/722, Loss: 0.10649856587722067\n",
      "Epoch: 8, Validation_Samples: 490/722, Loss: 0.14978306590314397\n",
      "Epoch: 8, Validation_Samples: 495/722, Loss: 0.15026775607201387\n",
      "Epoch: 8, Validation_Samples: 500/722, Loss: 0.1320542604254815\n",
      "Epoch: 8, Validation_Samples: 505/722, Loss: 0.12855479547765003\n",
      "Epoch: 8, Validation_Samples: 510/722, Loss: 0.14444706511842076\n",
      "Epoch: 8, Validation_Samples: 515/722, Loss: 0.12414574370914473\n",
      "Epoch: 8, Validation_Samples: 520/722, Loss: 0.10224236182924763\n",
      "Epoch: 8, Validation_Samples: 525/722, Loss: 0.16505443838127748\n",
      "Epoch: 8, Validation_Samples: 530/722, Loss: 0.09996229116512237\n",
      "Epoch: 8, Validation_Samples: 535/722, Loss: 0.12651408471702483\n",
      "Epoch: 8, Validation_Samples: 540/722, Loss: 0.1480162530989203\n",
      "Epoch: 8, Validation_Samples: 545/722, Loss: 0.11855519442434186\n",
      "Epoch: 8, Validation_Samples: 550/722, Loss: 0.13935915359257736\n",
      "Epoch: 8, Validation_Samples: 555/722, Loss: 0.11814200174079681\n",
      "Epoch: 8, Validation_Samples: 560/722, Loss: 0.13873960536248856\n",
      "Epoch: 8, Validation_Samples: 565/722, Loss: 0.13467466355869842\n",
      "Epoch: 8, Validation_Samples: 570/722, Loss: 0.13197570906549116\n",
      "Epoch: 8, Validation_Samples: 575/722, Loss: 0.11327745775755634\n",
      "Epoch: 8, Validation_Samples: 580/722, Loss: 0.12202493744476355\n",
      "Epoch: 8, Validation_Samples: 585/722, Loss: 0.11942919143496314\n",
      "Epoch: 8, Validation_Samples: 590/722, Loss: 0.08468063165674489\n",
      "Epoch: 8, Validation_Samples: 595/722, Loss: 0.1039091956575687\n",
      "Epoch: 8, Validation_Samples: 600/722, Loss: 0.13603826552648654\n",
      "Epoch: 8, Validation_Samples: 605/722, Loss: 0.14171970682376528\n",
      "Epoch: 8, Validation_Samples: 610/722, Loss: 0.13506162963681137\n",
      "Epoch: 8, Validation_Samples: 615/722, Loss: 0.1270900482612372\n",
      "Epoch: 8, Validation_Samples: 620/722, Loss: 0.13490035631894662\n",
      "Epoch: 8, Validation_Samples: 625/722, Loss: 0.1291601500913747\n",
      "Epoch: 8, Validation_Samples: 630/722, Loss: 0.1450331974270956\n",
      "Epoch: 8, Validation_Samples: 635/722, Loss: 0.12629018625933747\n",
      "Epoch: 8, Validation_Samples: 640/722, Loss: 0.11418383539461313\n",
      "Epoch: 8, Validation_Samples: 645/722, Loss: 0.10949982805581854\n",
      "Epoch: 8, Validation_Samples: 650/722, Loss: 0.11261817962143707\n",
      "Epoch: 8, Validation_Samples: 655/722, Loss: 0.12076843821075278\n",
      "Epoch: 8, Validation_Samples: 660/722, Loss: 0.12247070667677692\n",
      "Epoch: 8, Validation_Samples: 665/722, Loss: 0.14669310536248287\n",
      "Epoch: 8, Validation_Samples: 670/722, Loss: 0.11738098984348663\n",
      "Epoch: 8, Validation_Samples: 675/722, Loss: 0.14000992361772893\n",
      "Epoch: 8, Validation_Samples: 680/722, Loss: 0.12302473749190292\n",
      "Epoch: 8, Validation_Samples: 685/722, Loss: 0.11321617813003634\n",
      "Epoch: 8, Validation_Samples: 690/722, Loss: 0.08190122220336853\n",
      "Epoch: 8, Validation_Samples: 695/722, Loss: 0.11099363952409455\n",
      "Epoch: 8, Validation_Samples: 700/722, Loss: 0.1361642475953113\n",
      "Epoch: 8, Validation_Samples: 705/722, Loss: 0.1484154477755407\n",
      "Epoch: 8, Validation_Samples: 710/722, Loss: 0.11387821254391438\n",
      "Epoch: 8, Validation_Samples: 715/722, Loss: 0.17575757259456806\n",
      "Epoch: 8, Validation_Samples: 720/722, Loss: 0.10549530937954398\n",
      "\n",
      "Epoch: 8\n",
      "Validation set: Average loss: 0.1209, AP: 0.6540)\n",
      "Epoch: 9, Training_Samples: 0/358, Loss: 0.13533221307487378\n",
      "Epoch: 9, Training_Samples: 5/358, Loss: 0.16582154057943632\n",
      "Epoch: 9, Training_Samples: 10/358, Loss: 0.11344599090689288\n",
      "Epoch: 9, Training_Samples: 15/358, Loss: 0.1385135337862318\n",
      "Epoch: 9, Training_Samples: 20/358, Loss: 0.08286918214155654\n",
      "Epoch: 9, Training_Samples: 25/358, Loss: 0.18553337366236405\n",
      "Epoch: 9, Training_Samples: 30/358, Loss: 0.10238578542747626\n",
      "Epoch: 9, Training_Samples: 35/358, Loss: 0.1528655674208034\n",
      "Epoch: 9, Training_Samples: 40/358, Loss: 0.16078196412368168\n",
      "Epoch: 9, Training_Samples: 45/358, Loss: 0.14506531360161723\n",
      "Epoch: 9, Training_Samples: 50/358, Loss: 0.13908386815051021\n",
      "Epoch: 9, Training_Samples: 55/358, Loss: 0.1301828494462059\n",
      "Epoch: 9, Training_Samples: 60/358, Loss: 0.14838073688385517\n",
      "Epoch: 9, Training_Samples: 65/358, Loss: 0.15707906398564167\n",
      "Epoch: 9, Training_Samples: 70/358, Loss: 0.10665977469717629\n",
      "Epoch: 9, Training_Samples: 75/358, Loss: 0.13580198793877546\n",
      "Epoch: 9, Training_Samples: 80/358, Loss: 0.12368894769326261\n",
      "Epoch: 9, Training_Samples: 85/358, Loss: 0.14597620170341002\n",
      "Epoch: 9, Training_Samples: 90/358, Loss: 0.12124982670480415\n",
      "Epoch: 9, Training_Samples: 95/358, Loss: 0.09901083669228095\n",
      "Epoch: 9, Training_Samples: 100/358, Loss: 0.13607354779744943\n",
      "Epoch: 9, Training_Samples: 105/358, Loss: 0.15539894292169834\n",
      "Epoch: 9, Training_Samples: 110/358, Loss: 0.13695256782869442\n",
      "Epoch: 9, Training_Samples: 115/358, Loss: 0.09903497227404746\n",
      "Epoch: 9, Training_Samples: 120/358, Loss: 0.10179509231630687\n",
      "Epoch: 9, Training_Samples: 125/358, Loss: 0.11984231932428568\n",
      "Epoch: 9, Training_Samples: 130/358, Loss: 0.10420068818350414\n",
      "Epoch: 9, Training_Samples: 135/358, Loss: 0.17712186561253893\n",
      "Epoch: 9, Training_Samples: 140/358, Loss: 0.1271111159197867\n",
      "Epoch: 9, Training_Samples: 145/358, Loss: 0.11503884547391537\n",
      "Epoch: 9, Training_Samples: 150/358, Loss: 0.13520491414637698\n",
      "Epoch: 9, Training_Samples: 155/358, Loss: 0.15478081065332733\n",
      "Epoch: 9, Training_Samples: 160/358, Loss: 0.12442913072318047\n",
      "Epoch: 9, Training_Samples: 165/358, Loss: 0.1518220667263019\n",
      "Epoch: 9, Training_Samples: 170/358, Loss: 0.12237933088023321\n",
      "Epoch: 9, Training_Samples: 175/358, Loss: 0.14545801929305904\n",
      "Epoch: 9, Training_Samples: 180/358, Loss: 0.10665867667730321\n",
      "Epoch: 9, Training_Samples: 185/358, Loss: 0.11170732075080443\n",
      "Epoch: 9, Training_Samples: 190/358, Loss: 0.10287133579326468\n",
      "Epoch: 9, Training_Samples: 195/358, Loss: 0.1505419206942668\n",
      "Epoch: 9, Training_Samples: 200/358, Loss: 0.11483037279083946\n",
      "Epoch: 9, Training_Samples: 205/358, Loss: 0.17140879813556395\n",
      "Epoch: 9, Training_Samples: 210/358, Loss: 0.14716013109197915\n",
      "Epoch: 9, Training_Samples: 215/358, Loss: 0.17303184784428027\n",
      "Epoch: 9, Training_Samples: 220/358, Loss: 0.12623828619424607\n",
      "Epoch: 9, Training_Samples: 225/358, Loss: 0.1538028466412523\n",
      "Epoch: 9, Training_Samples: 230/358, Loss: 0.098002657965822\n",
      "Epoch: 9, Training_Samples: 235/358, Loss: 0.13281786047745098\n",
      "Epoch: 9, Training_Samples: 240/358, Loss: 0.12910281386486575\n",
      "Epoch: 9, Training_Samples: 245/358, Loss: 0.12491149393422336\n",
      "Epoch: 9, Training_Samples: 250/358, Loss: 0.1303364046167477\n",
      "Epoch: 9, Training_Samples: 255/358, Loss: 0.1357308068506095\n",
      "Epoch: 9, Training_Samples: 260/358, Loss: 0.13413012005002006\n",
      "Epoch: 9, Training_Samples: 265/358, Loss: 0.11238440741408895\n",
      "Epoch: 9, Training_Samples: 270/358, Loss: 0.12549679115885684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Training_Samples: 275/358, Loss: 0.14092114243672038\n",
      "Epoch: 9, Training_Samples: 280/358, Loss: 0.15001486166096897\n",
      "Epoch: 9, Training_Samples: 285/358, Loss: 0.09509599642565517\n",
      "Epoch: 9, Training_Samples: 290/358, Loss: 0.16545285352402017\n",
      "Epoch: 9, Training_Samples: 295/358, Loss: 0.1619679858237609\n",
      "Epoch: 9, Training_Samples: 300/358, Loss: 0.12521511451234293\n",
      "Epoch: 9, Training_Samples: 305/358, Loss: 0.15266232294745302\n",
      "Epoch: 9, Training_Samples: 310/358, Loss: 0.13029702923921513\n",
      "Epoch: 9, Training_Samples: 315/358, Loss: 0.1273994534795862\n",
      "Epoch: 9, Training_Samples: 320/358, Loss: 0.1079528437424409\n",
      "Epoch: 9, Training_Samples: 325/358, Loss: 0.09991797574417077\n",
      "Epoch: 9, Training_Samples: 330/358, Loss: 0.15536628890433463\n",
      "Epoch: 9, Training_Samples: 335/358, Loss: 0.1493296287434683\n",
      "Epoch: 9, Training_Samples: 340/358, Loss: 0.11573596442978488\n",
      "Epoch: 9, Training_Samples: 345/358, Loss: 0.14270182427501518\n",
      "Epoch: 9, Training_Samples: 350/358, Loss: 0.09818028173502691\n",
      "Epoch: 9, Training_Samples: 355/358, Loss: 0.10964828777043978\n",
      "\n",
      "Epoch: 9\n",
      "Training set: Average loss: 0.1294\n",
      "Epoch: 9, Validation_Samples: 0/722, Loss: 0.09488256323980376\n",
      "Epoch: 9, Validation_Samples: 5/722, Loss: 0.11970276103348625\n",
      "Epoch: 9, Validation_Samples: 10/722, Loss: 0.12071489476829157\n",
      "Epoch: 9, Validation_Samples: 15/722, Loss: 0.10972514941553238\n",
      "Epoch: 9, Validation_Samples: 20/722, Loss: 0.0847254426103442\n",
      "Epoch: 9, Validation_Samples: 25/722, Loss: 0.10275583140360278\n",
      "Epoch: 9, Validation_Samples: 30/722, Loss: 0.1156937562979933\n",
      "Epoch: 9, Validation_Samples: 35/722, Loss: 0.11584900460608884\n",
      "Epoch: 9, Validation_Samples: 40/722, Loss: 0.09026907531476218\n",
      "Epoch: 9, Validation_Samples: 45/722, Loss: 0.09483826640255769\n",
      "Epoch: 9, Validation_Samples: 50/722, Loss: 0.10192682546584736\n",
      "Epoch: 9, Validation_Samples: 55/722, Loss: 0.09628100649594488\n",
      "Epoch: 9, Validation_Samples: 60/722, Loss: 0.12350820331335706\n",
      "Epoch: 9, Validation_Samples: 65/722, Loss: 0.1436801011470877\n",
      "Epoch: 9, Validation_Samples: 70/722, Loss: 0.1098828865281768\n",
      "Epoch: 9, Validation_Samples: 75/722, Loss: 0.12100032562117968\n",
      "Epoch: 9, Validation_Samples: 80/722, Loss: 0.12829422976253466\n",
      "Epoch: 9, Validation_Samples: 85/722, Loss: 0.1183958070007037\n",
      "Epoch: 9, Validation_Samples: 90/722, Loss: 0.08378731578738677\n",
      "Epoch: 9, Validation_Samples: 95/722, Loss: 0.08818440892074553\n",
      "Epoch: 9, Validation_Samples: 100/722, Loss: 0.1041585216477717\n",
      "Epoch: 9, Validation_Samples: 105/722, Loss: 0.12486284382235026\n",
      "Epoch: 9, Validation_Samples: 110/722, Loss: 0.10149080446119597\n",
      "Epoch: 9, Validation_Samples: 115/722, Loss: 0.07927490229798421\n",
      "Epoch: 9, Validation_Samples: 120/722, Loss: 0.13046171404911064\n",
      "Epoch: 9, Validation_Samples: 125/722, Loss: 0.12896329554781424\n",
      "Epoch: 9, Validation_Samples: 130/722, Loss: 0.12627938873289302\n",
      "Epoch: 9, Validation_Samples: 135/722, Loss: 0.14737746365320376\n",
      "Epoch: 9, Validation_Samples: 140/722, Loss: 0.11413660507354426\n",
      "Epoch: 9, Validation_Samples: 145/722, Loss: 0.1620090223185396\n",
      "Epoch: 9, Validation_Samples: 150/722, Loss: 0.1427016303478226\n",
      "Epoch: 9, Validation_Samples: 155/722, Loss: 0.13637495129884625\n",
      "Epoch: 9, Validation_Samples: 160/722, Loss: 0.11768871227924305\n",
      "Epoch: 9, Validation_Samples: 165/722, Loss: 0.08963590191905914\n",
      "Epoch: 9, Validation_Samples: 170/722, Loss: 0.1340274851728339\n",
      "Epoch: 9, Validation_Samples: 175/722, Loss: 0.09768197652831212\n",
      "Epoch: 9, Validation_Samples: 180/722, Loss: 0.10416369814558311\n",
      "Epoch: 9, Validation_Samples: 185/722, Loss: 0.09356029835170548\n",
      "Epoch: 9, Validation_Samples: 190/722, Loss: 0.14887048552417945\n",
      "Epoch: 9, Validation_Samples: 195/722, Loss: 0.09390015325721841\n",
      "Epoch: 9, Validation_Samples: 200/722, Loss: 0.10774719545191148\n",
      "Epoch: 9, Validation_Samples: 205/722, Loss: 0.12489724352837257\n",
      "Epoch: 9, Validation_Samples: 210/722, Loss: 0.10596920571115283\n",
      "Epoch: 9, Validation_Samples: 215/722, Loss: 0.11721932194552331\n",
      "Epoch: 9, Validation_Samples: 220/722, Loss: 0.10866616314250349\n",
      "Epoch: 9, Validation_Samples: 225/722, Loss: 0.131247571021013\n",
      "Epoch: 9, Validation_Samples: 230/722, Loss: 0.13650601771343152\n",
      "Epoch: 9, Validation_Samples: 235/722, Loss: 0.12185355747183044\n",
      "Epoch: 9, Validation_Samples: 240/722, Loss: 0.11766463829209661\n",
      "Epoch: 9, Validation_Samples: 245/722, Loss: 0.09890236449211108\n",
      "Epoch: 9, Validation_Samples: 250/722, Loss: 0.11303890728516255\n",
      "Epoch: 9, Validation_Samples: 255/722, Loss: 0.1350284546929344\n",
      "Epoch: 9, Validation_Samples: 260/722, Loss: 0.10873398336397945\n",
      "Epoch: 9, Validation_Samples: 265/722, Loss: 0.14099276334911828\n",
      "Epoch: 9, Validation_Samples: 270/722, Loss: 0.13433784229891096\n",
      "Epoch: 9, Validation_Samples: 275/722, Loss: 0.1082670162261336\n",
      "Epoch: 9, Validation_Samples: 280/722, Loss: 0.1255313311678995\n",
      "Epoch: 9, Validation_Samples: 285/722, Loss: 0.13455535473672617\n",
      "Epoch: 9, Validation_Samples: 290/722, Loss: 0.1326091528488799\n",
      "Epoch: 9, Validation_Samples: 295/722, Loss: 0.10190186471278151\n",
      "Epoch: 9, Validation_Samples: 300/722, Loss: 0.10092796378731121\n",
      "Epoch: 9, Validation_Samples: 305/722, Loss: 0.08444401360878209\n",
      "Epoch: 9, Validation_Samples: 310/722, Loss: 0.09016754478707756\n",
      "Epoch: 9, Validation_Samples: 315/722, Loss: 0.12722989627921796\n",
      "Epoch: 9, Validation_Samples: 320/722, Loss: 0.0817411637675352\n",
      "Epoch: 9, Validation_Samples: 325/722, Loss: 0.12159389364232477\n",
      "Epoch: 9, Validation_Samples: 330/722, Loss: 0.11980059625726694\n",
      "Epoch: 9, Validation_Samples: 335/722, Loss: 0.09603390773010644\n",
      "Epoch: 9, Validation_Samples: 340/722, Loss: 0.1091014530367085\n",
      "Epoch: 9, Validation_Samples: 345/722, Loss: 0.10417763414938812\n",
      "Epoch: 9, Validation_Samples: 350/722, Loss: 0.12078331816920931\n",
      "Epoch: 9, Validation_Samples: 355/722, Loss: 0.13198452537129418\n",
      "Epoch: 9, Validation_Samples: 360/722, Loss: 0.14145018852843336\n",
      "Epoch: 9, Validation_Samples: 365/722, Loss: 0.1295701788347085\n",
      "Epoch: 9, Validation_Samples: 370/722, Loss: 0.10984089018841871\n",
      "Epoch: 9, Validation_Samples: 375/722, Loss: 0.11921545553016222\n",
      "Epoch: 9, Validation_Samples: 380/722, Loss: 0.08632513104398724\n",
      "Epoch: 9, Validation_Samples: 385/722, Loss: 0.12894141283557117\n",
      "Epoch: 9, Validation_Samples: 390/722, Loss: 0.12257694211257385\n",
      "Epoch: 9, Validation_Samples: 395/722, Loss: 0.1408458635371231\n",
      "Epoch: 9, Validation_Samples: 400/722, Loss: 0.11519642119326648\n",
      "Epoch: 9, Validation_Samples: 405/722, Loss: 0.12326194507661392\n",
      "Epoch: 9, Validation_Samples: 410/722, Loss: 0.13228075891100882\n",
      "Epoch: 9, Validation_Samples: 415/722, Loss: 0.1404792594629836\n",
      "Epoch: 9, Validation_Samples: 420/722, Loss: 0.10123569710990127\n",
      "Epoch: 9, Validation_Samples: 425/722, Loss: 0.11430756055507577\n",
      "Epoch: 9, Validation_Samples: 430/722, Loss: 0.12108520005300297\n",
      "Epoch: 9, Validation_Samples: 435/722, Loss: 0.12709088589213666\n",
      "Epoch: 9, Validation_Samples: 440/722, Loss: 0.12469791534667876\n",
      "Epoch: 9, Validation_Samples: 445/722, Loss: 0.09488331880162902\n",
      "Epoch: 9, Validation_Samples: 450/722, Loss: 0.15034727175051527\n",
      "Epoch: 9, Validation_Samples: 455/722, Loss: 0.13731051712920406\n",
      "Epoch: 9, Validation_Samples: 460/722, Loss: 0.1285262015894416\n",
      "Epoch: 9, Validation_Samples: 465/722, Loss: 0.13624983722340156\n",
      "Epoch: 9, Validation_Samples: 470/722, Loss: 0.11517226133635841\n",
      "Epoch: 9, Validation_Samples: 475/722, Loss: 0.10239842679265694\n",
      "Epoch: 9, Validation_Samples: 480/722, Loss: 0.11623088736171379\n",
      "Epoch: 9, Validation_Samples: 485/722, Loss: 0.14382569773846643\n",
      "Epoch: 9, Validation_Samples: 490/722, Loss: 0.14125660642853127\n",
      "Epoch: 9, Validation_Samples: 495/722, Loss: 0.11431248755861431\n",
      "Epoch: 9, Validation_Samples: 500/722, Loss: 0.10232428655406792\n",
      "Epoch: 9, Validation_Samples: 505/722, Loss: 0.1008733238582031\n",
      "Epoch: 9, Validation_Samples: 510/722, Loss: 0.14562886305719372\n",
      "Epoch: 9, Validation_Samples: 515/722, Loss: 0.09954958772688807\n",
      "Epoch: 9, Validation_Samples: 520/722, Loss: 0.07996815112119127\n",
      "Epoch: 9, Validation_Samples: 525/722, Loss: 0.11629844250663487\n",
      "Epoch: 9, Validation_Samples: 530/722, Loss: 0.12287900473843327\n",
      "Epoch: 9, Validation_Samples: 535/722, Loss: 0.09409472227084544\n",
      "Epoch: 9, Validation_Samples: 540/722, Loss: 0.11592717682137921\n",
      "Epoch: 9, Validation_Samples: 545/722, Loss: 0.1385178968465786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Validation_Samples: 550/722, Loss: 0.15133623318815154\n",
      "Epoch: 9, Validation_Samples: 555/722, Loss: 0.11418639157457602\n",
      "Epoch: 9, Validation_Samples: 560/722, Loss: 0.12290074755274492\n",
      "Epoch: 9, Validation_Samples: 565/722, Loss: 0.14169968832248528\n",
      "Epoch: 9, Validation_Samples: 570/722, Loss: 0.07262911437933817\n",
      "Epoch: 9, Validation_Samples: 575/722, Loss: 0.10107846057932827\n",
      "Epoch: 9, Validation_Samples: 580/722, Loss: 0.17744205762138393\n",
      "Epoch: 9, Validation_Samples: 585/722, Loss: 0.0919566740742249\n",
      "Epoch: 9, Validation_Samples: 590/722, Loss: 0.12170961835526246\n",
      "Epoch: 9, Validation_Samples: 595/722, Loss: 0.12261127090865832\n",
      "Epoch: 9, Validation_Samples: 600/722, Loss: 0.11571453175353495\n",
      "Epoch: 9, Validation_Samples: 605/722, Loss: 0.10509741012785156\n",
      "Epoch: 9, Validation_Samples: 610/722, Loss: 0.13070193817095108\n",
      "Epoch: 9, Validation_Samples: 615/722, Loss: 0.07733792261893041\n",
      "Epoch: 9, Validation_Samples: 620/722, Loss: 0.14395905764306477\n",
      "Epoch: 9, Validation_Samples: 625/722, Loss: 0.10550307315621678\n",
      "Epoch: 9, Validation_Samples: 630/722, Loss: 0.13827365164695538\n",
      "Epoch: 9, Validation_Samples: 635/722, Loss: 0.13370705202692654\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-2115e2251276>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_accuracies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-aa4b625a5b64>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(model, device, train_loader, optimizer, num_epochs, val_loader, loss_fun)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#         if (len(val_losses) > 0) and (val_loss < min(val_losses)):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-5b718596ec65>\u001b[0m in \u001b[0;36mvalidate\u001b[1;34m(model, device, val_loader, epoch, loss_fun)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\humantorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\humantorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\humantorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\humantorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-67246907f823>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;31m# Open the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mins_label_pairs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-67246907f823>\u001b[0m in \u001b[0;36mimage_load\u001b[1;34m(self, image_path)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# Open image and load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\humantorch\\lib\\site-packages\\PIL\\ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m                             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m                             \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m                                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train_losses, val_losses, val_accuracies = train_epoch(model, device, train_loader, optimizer, 10, val_loader, loss_fun)\n",
    "\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ins_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "from sklearn.metrics import average_precision_score\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import FiveCrop, ToTensor, Lambda, Compose, CenterCrop, Normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PascalVOC:\n",
    "    \"\"\"\n",
    "    Handle Pascal VOC dataset\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir):\n",
    "        \"\"\"\n",
    "        Summary: \n",
    "            Init the class with root dir\n",
    "        Args:\n",
    "            root_dir (string): path to your voc dataset\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.img_dir =  os.path.join(root_dir, 'JPEGImages/')\n",
    "        self.ann_dir = os.path.join(root_dir, 'Annotations')\n",
    "        self.set_dir = os.path.join(root_dir, 'ImageSets', 'Main')\n",
    "        self.cache_dir = os.path.join(root_dir, 'csvs')\n",
    "        if not os.path.exists(self.cache_dir):\n",
    "            os.makedirs(self.cache_dir)\n",
    "\n",
    "    def list_image_sets(self):\n",
    "        \"\"\"\n",
    "        Summary: \n",
    "            List all the image sets from Pascal VOC. Don't bother computing\n",
    "            this on the fly, just remember it. It's faster.\n",
    "        \"\"\"\n",
    "        return [\n",
    "            'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "            'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "            'cow', 'diningtable', 'dog', 'horse',\n",
    "            'motorbike', 'person', 'pottedplant',\n",
    "            'sheep', 'sofa', 'train',\n",
    "            'tvmonitor']\n",
    "\n",
    "    def _imgs_from_category(self, cat_name, dataset):\n",
    "        \"\"\"\n",
    "        Summary: \n",
    "        Args:\n",
    "            cat_name (string): Category name as a string (from list_image_sets())\n",
    "            dataset (string): \"train\", \"val\", \"train_val\", or \"test\" (if available)\n",
    "        Returns:\n",
    "            pandas dataframe: pandas DataFrame of all filenames from that category\n",
    "        \"\"\"\n",
    "        filename = os.path.join(self.set_dir, cat_name + \"_\" + dataset + \".txt\")\n",
    "        df = pd.read_csv(\n",
    "            filename,\n",
    "            delim_whitespace=True,\n",
    "            header=None,\n",
    "            names=['filename', cat_name])\n",
    "        return df\n",
    "\n",
    "    def imgs_from_category_as_list(self, cat_name, dataset):\n",
    "        \"\"\"\n",
    "        Summary: \n",
    "            Get a list of filenames for images in a particular category\n",
    "            as a list rather than a pandas dataframe.\n",
    "        Args:\n",
    "            cat_name (string): Category name as a string (from list_image_sets())\n",
    "            dataset (string): \"train\", \"val\", \"train_val\", or \"test\" (if available)\n",
    "        Returns:\n",
    "            list of srings: all filenames from that category\n",
    "        \"\"\"\n",
    "        df = self._imgs_from_category(cat_name, dataset)\n",
    "#         df = df[df['true'] == 1]\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandsomeBinderNet(Dataset):\n",
    "#     def __init__(self, img_root, ins_label_pairs , crop_size, transform=None):\n",
    "    def __init__(self, img_root, classes, pvc, dataset_type, transform=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        img_root: contains the path to the image root folder\n",
    "        ins_label_pairs: instance label pair that contains a list of all the image path names and their respective labels\n",
    "        crop_size: contains desired crop dimensions\n",
    "        transform: contains the transformation procedures to be applied. defaulted to be None\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.img_root = img_root\n",
    "        self.transform = transform\n",
    "        self.classes = classes\n",
    "        self.pvc = pvc\n",
    "        self.dataset_type = dataset_type\n",
    "        self.ins_label_pairs = self.instance_label_prep(self.classes, self.pvc, self.dataset_type)\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.ins_label_pairs)\n",
    "    \n",
    "    def image_load(self, image_path):\n",
    "        # Open image and load\n",
    "        img = (Image.open(image_path))\n",
    "        img.load()\n",
    "        \n",
    "        img = np.array(img)\n",
    "        if len(img.shape) == 2:\n",
    "            img = np.expand_dims(img, 2)\n",
    "            img = np.repeat(img, 3, 2)\n",
    "            \n",
    "        return Image.fromarray(img)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # Path to the image\n",
    "        image_path = self.img_root + self.ins_label_pairs[index][0] + '.jpg'\n",
    "        \n",
    "        # Open the image\n",
    "        image = self.image_load(image_path)\n",
    "        label = torch.from_numpy((self.ins_label_pairs[index][1]).astype(float))\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return [image, label]\n",
    "    \n",
    "    \n",
    "    def instance_label_prep(self, classes, pvc, dataset_type):\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        classes: a list containing the classes used\n",
    "        pvc: pascalVOC object\n",
    "        dataset_type: train, trainval or val\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Get a dataframe from within the pascalVOC dataset. It will be in a one hot encoding fashion\n",
    "        final_df = None\n",
    "\n",
    "        # Loop through each different class to get each image's classes\n",
    "        for index, x in enumerate(classes):\n",
    "            cat_name = x # category name\n",
    "\n",
    "            df = pvc.imgs_from_category_as_list(cat_name, dataset_type)\n",
    "            df[x] = df[x].replace(-1, 0)\n",
    "\n",
    "            # For the first category, we use its dataframe as the base\n",
    "            if index == 0:\n",
    "                final_df = df\n",
    "            # And merge with the rest of the following categories\n",
    "            else:        \n",
    "                final_df = final_df.merge(df, on='filename', how='inner')\n",
    "\n",
    "        # Here we get each image name and their respective labels (one hot encoding format) and store in a list\n",
    "        df_np = final_df.to_numpy()\n",
    "\n",
    "        ins_labels = []\n",
    "        for x in df_np:\n",
    "            ins_labels.append([x[0], x[1:]])\n",
    "\n",
    "        return ins_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable',\n",
    "            'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "pvc = PascalVOC('VOC2012')\n",
    "imgpath = 'VOC2012/JPEGImages/'\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')    \n",
    "tr = transforms.Compose([transforms.RandomResizedCrop(300),\n",
    "                             transforms.ToTensor(),\n",
    "                             transforms.Normalize([0.4589, 0.4355, 0.4032],[0.2239, 0.2186, 0.2206])])\n",
    "\n",
    "# Create datasets and respective dataloaders\n",
    "\n",
    "train_dataset = HandsomeBinderNet(imgpath, class_list, pvc, 'train', transform=tr)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "val_dataset = HandsomeBinderNet(imgpath, class_list, pvc, 'trainval', transform=tr)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "test_dataset = HandsomeBinderNet(imgpath, class_list, pvc, 'val', transform=tr)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(512, 20)\n",
    "model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
    "loss_fun = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, device, train_loader, optimizer, num_epochs, val_loader, loss_fun):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_ap_scores = []\n",
    "    \n",
    "    directory = 'model_' + str(datetime.now())\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss = train(model, device, train_loader, optimizer, epoch, loss_fun)\n",
    "        val_loss, val_ap_score = validate(model, device, val_loader, epoch, loss_fun)\n",
    "\n",
    "        if (len(val_losses) > 0) and (val_loss < min(val_losses)):\n",
    "            torch.save(model.state_dict(), directory + '/resnet18_model_{}.pt'.format(epoch))\n",
    "            print(\"Saving model (epoch {}) with lowest validation loss: {}\".format(epoch, val_loss))\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        val_ap_scores.append(val_ap_score)\n",
    "\n",
    "    print(\"Training and validation complete.\")\n",
    "    return train_losses, val_losses, val_ap_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, loss_fun):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for idx, batch in enumerate(train_loader):\n",
    "        data = batch[0].to(device)\n",
    "        target = batch[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fun(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "        if idx % 5 == 0:\n",
    "            print('Epoch: {}, Training_Samples: {}/{}, Loss: {}'.format(epoch, idx, len(train_loader), loss.item()))\n",
    "    train_loss = torch.mean(torch.tensor(train_losses))\n",
    "    print('\\nEpoch: {}'.format(epoch))\n",
    "    print('Training set: Average loss: {:.4f}'.format(train_loss))\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, device, val_loader, epoch, loss_fun):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(val_loader):\n",
    "            data = batch[0].to(device)\n",
    "            target = batch[1].to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            # compute the batch loss\n",
    "            batch_loss = loss_fun(output, target).item()\n",
    "            val_loss += batch_loss\n",
    "            pred = torch.sigmoid(output)\n",
    "            \n",
    "            if idx == 0:\n",
    "                predictions = pred\n",
    "                targets = target\n",
    "            else:\n",
    "                predictions = torch.cat((predictions, pred))\n",
    "                targets = torch.cat((targets, target))\n",
    "            if idx % 5 == 0:\n",
    "                print('Epoch: {}, Validation_Samples: {}/{}, Loss: {}'.format(epoch, idx, len(val_loader), batch_loss))\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    print('\\nEpoch: {}'.format(epoch))\n",
    "    print('Validation set: Average loss: {:.4f}, AP: {:.4f})'.format(val_loss, \n",
    "                                                                     average_precision_score(targets.reshape(-1, 20).cpu(), \n",
    "                                                                                             predictions.reshape(-1, 20).cpu())))\n",
    "    \n",
    "    return val_loss, predictions, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 123] The filename, directory name, or volume label syntax is incorrect: 'model_2020-03-17 00:20:10.290689'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-2115e2251276>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_accuracies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-f0e1a51f9881>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(model, device, train_loader, optimizer, num_epochs, val_loader, loss_fun)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mdirectory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'model_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\humantorch\\lib\\os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 123] The filename, directory name, or volume label syntax is incorrect: 'model_2020-03-17 00:20:10.290689'"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train_losses, val_losses, val_accuracies = train_epoch(model, device, train_loader, optimizer, 10, val_loader, loss_fun)\n",
    "\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

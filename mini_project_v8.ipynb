{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pprint as pp\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.metrics import average_precision_score\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.transforms import FiveCrop, ToTensor, Lambda, Compose, CenterCrop, Normalize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import PascalVOCLabelLoader, PascalVOCDataset, ImageOnlyDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, device, train_loader, optimizer, num_epochs, val_loader, loss_fun, class_list):\n",
    "    train_losses = []\n",
    "    train_ap_scores = []\n",
    "    val_losses = []\n",
    "    val_ap_scores = []\n",
    "    \n",
    "    now = datetime.now()\n",
    "    directory = 'model_' + now.strftime(\"%m%d%Y_%H%M%S\")\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f'\\nEpoch: {epoch}')\n",
    "        train_loss, train_ap_score = train(model, device, train_loader, optimizer, epoch, loss_fun, class_list)\n",
    "        val_loss, val_ap_score = validate(model, device, val_loader, epoch, loss_fun, class_list)\n",
    "\n",
    "        if (len(val_losses) > 0) and (val_loss < min(val_losses)):\n",
    "            torch.save(model.state_dict(), directory + f'/resnet18_model_{epoch}.pt')\n",
    "            print(f\"Saving model (epoch {epoch}) with lowest validation loss: {val_loss}\")\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_ap_scores.append(train_ap_score)\n",
    "        val_losses.append(val_loss)\n",
    "        val_ap_scores.append(val_ap_score)\n",
    "\n",
    "    print(\"Training and validation complete.\")\n",
    "    return train_losses, train_ap_scores, val_losses, val_ap_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, loss_fun, class_list):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    ap_score = 0\n",
    "    \n",
    "    for idx, batch in enumerate(train_loader):\n",
    "        data = batch[0].to(device)\n",
    "        target = batch[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fun(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "        pred = torch.sigmoid(output)\n",
    "        \n",
    "        if idx == 0:\n",
    "            predictions = pred\n",
    "            targets = target\n",
    "        else:\n",
    "            predictions = torch.cat((predictions, pred))\n",
    "            targets = torch.cat((targets, target))\n",
    "        if idx % 100 == 0:\n",
    "            print(f'Epoch: {epoch}, Training_Samples: {idx}/{len(train_loader)}, Loss: {loss.item()},\\\n",
    "            Total AP: {ap(targets, predictions, len(class_list)):.4f}')\n",
    "    \n",
    "    train_loss = torch.mean(torch.tensor(train_losses))\n",
    "    total_ap_score = ap(targets, predictions, len(class_list))\n",
    "    classwise_ap_scores = classwise_ap(targets, predictions, class_list)\n",
    "    mean_ap_score = np.mean([ 0 if np.isnan(i) else i for i in list(classwise_ap_scores.values())])\n",
    "    \n",
    "    print(f'Training set: Average loss: {train_loss:.4f}, Total AP: {total_ap_score:.4f}')\n",
    "    print('Validation set: Classwise AP:')\n",
    "    pp.pprint(classwise_ap_scores)\n",
    "    print(f'Validation set: Mean AP: {mean_ap_score:.4f})')\n",
    "    return train_loss, mean_ap_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, device, val_loader, epoch, loss_fun, class_list):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    ap_score = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(val_loader):\n",
    "            data = batch[0].to(device)\n",
    "            target = batch[1].to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            # compute the batch loss\n",
    "            batch_loss = loss_fun(output, target).item()\n",
    "            val_loss += batch_loss\n",
    "            pred = torch.sigmoid(output)\n",
    "            \n",
    "            if idx == 0:\n",
    "                predictions = pred\n",
    "                targets = target\n",
    "            else:\n",
    "                predictions = torch.cat((predictions, pred))\n",
    "                targets = torch.cat((targets, target))\n",
    "            if idx % 100 == 0:\n",
    "                print(f'Epoch: {epoch}, Validation_Samples: {idx}/{len(val_loader)}, Loss: {batch_loss},\\\n",
    "                Total AP: {ap(targets, predictions, len(class_list)):.4f}')\n",
    "                \n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    total_ap_score = ap(targets, predictions, len(class_list))\n",
    "    classwise_ap_scores = classwise_ap(targets, predictions, class_list)\n",
    "    mean_ap_score = np.mean([ 0 if np.isnan(i) else i for i in list(classwise_ap_scores.values())])\n",
    "    \n",
    "    print(f'Validation set: Average loss: {val_loss:.4f}, Total AP: {total_ap_score:.4f}')\n",
    "    print('Validation set: Classwise AP:')\n",
    "    pp.pprint(classwise_ap_scores)\n",
    "    print(f'Validation set: Mean AP: {mean_ap_score:.4f})')\n",
    "    \n",
    "    return val_loss, mean_ap_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, loss_fun, class_list):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    ap_score = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(test_loader):\n",
    "            data = batch[0].to(device)\n",
    "            target = batch[1].to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            # compute the batch loss\n",
    "            batch_loss = loss_fun(output, target).item()\n",
    "            test_loss += batch_loss\n",
    "            pred = torch.sigmoid(output)\n",
    "            \n",
    "            if idx == 0:\n",
    "                predictions = pred\n",
    "                targets = target\n",
    "                image_paths = list(batch[2])\n",
    "            else:\n",
    "                predictions = torch.cat((predictions, pred))\n",
    "                targets = torch.cat((targets, target))\n",
    "                image_paths += list(batch[2])\n",
    "            if idx % 100 == 0:\n",
    "                print(f'Test_Samples: {idx}/{len(test_loader)}, Loss: {batch_loss},\\\n",
    "                Total AP: {ap(targets, predictions, len(class_list)):.4f}')\n",
    "                \n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    total_ap_score = ap(targets, predictions, len(class_list))\n",
    "    classwise_ap_scores = classwise_ap(targets, predictions, class_list)\n",
    "    mean_ap_score = np.mean([ 0 if np.isnan(i) else i for i in list(classwise_ap_scores.values())])\n",
    "    \n",
    "    print(f'Test set: Average loss: {test_loss:.4f}, Total AP: {total_ap_score:.4f}')\n",
    "    print('Test set: Classwise AP:')\n",
    "    pp.pprint(classwise_ap_scores)\n",
    "    print(f'Test set: Mean AP: {mean_ap_score:.4f})')\n",
    "    \n",
    "    return predictions, targets, image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ap(targets, predictions, num_classes):\n",
    "    return average_precision_score(targets.reshape(-1, num_classes).cpu(), predictions.reshape(-1, num_classes).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classwise_ap(targets, predictions, class_list):\n",
    "    classwise_ap_dic = {}\n",
    "    for i, label in enumerate(class_list):\n",
    "        classwise_ap_dic[label] = average_precision_score(targets[:, i].cpu(),  predictions[:, i].cpu())\n",
    "    return classwise_ap_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_bot_scores_50(img_names, scores, class_num, top=50):\n",
    "    \"\"\"\n",
    "    img_names: a list containing the image names\n",
    "    scores: a list containing the predicted scores for each class\n",
    "    class_num: the column of the class\n",
    "    num_ins: number of instances you want\n",
    "    \n",
    "    returns: a list containing the top and bottom 50 scores and images of this class in the format\n",
    "             [top_50_scores, top_50_images, bot_50_scores, bot_50_images]\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Use the scores to get the new order in a list, from highest to lowest\n",
    "    n_scores = np.copy(scores.cpu())\n",
    "    n_img_names = np.copy(img_names)\n",
    "    \n",
    "    reorder = n_scores[:,class_num].argsort()[::-1]\n",
    "    # Reorder the img_names\n",
    "    r_img_names = n_img_names[reorder]\n",
    "    top_img = r_img_names[:top]\n",
    "    bottom_img = r_img_names[-top:]\n",
    "    \n",
    "    return top_img, bottom_img, reorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_grid_plotter(dataloader, class_name, num_img, rank_name):\n",
    "    real_batch = next(iter(dataloader))\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f'Top {num_img} {rank_name} scored images for class {class_name}')\n",
    "    plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:50], padding=2, nrow=10, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders for top and bot images\n",
    "def plot_top_images(cls_img_pairs, img_path, tr, class_list, rank_name):\n",
    "    \"\"\"\n",
    "    cls_img_pairs: a list containing the pairs of a class with its respective top or bottom x image names\n",
    "    img_path: image path\n",
    "    tr: your transform sequence\n",
    "    class_list: a list mapping for the class labels\n",
    "    rank_name: determine if the set is either highest or lowest\n",
    "    \n",
    "    returns Nothing, but plots out the random 5 classes and their top/bottom x images\n",
    "    \"\"\"\n",
    "    for x in cls_img_pairs:\n",
    "        num_img = len(x[1])\n",
    "        # Create the dataset and subsequently dataloader\n",
    "        i_dataset = ImageOnlyDataset(img_path, x[1], transform=tr)\n",
    "        i_dataloder = DataLoader(i_dataset, batch_size=num_img, shuffle=False)\n",
    "        \n",
    "        \n",
    "        # Use plotter function to print a grid of the images\n",
    "        img_grid_plotter(i_dataloder, class_list[x[0]], num_img, rank_name)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tail_acc(sorted_predictions, sorted_targets, t_min, t_max, t_num, t_vals):\n",
    "    tail_acc_list = []\n",
    "    for t_val in t_vals:\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        for (prediction, target) in zip(sorted_predictions, sorted_targets):\n",
    "            pred = 0\n",
    "            if prediction > t_val:\n",
    "                pred = 1\n",
    "                if pred == target:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "        tail_acc = 0\n",
    "        if tp+fp > 0:\n",
    "            tail_acc = tp/(tp+fp)\n",
    "        tail_acc_list.append(tail_acc)\n",
    "        \n",
    "    return tail_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "\n",
    "    ###### Global Variables (Change it if you want) ######\n",
    "    class_list = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', \n",
    "                  'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')    \n",
    "    lr = 1e-3\n",
    "    momentum = 0.9\n",
    "    imgpath = 'data/VOCdevkit/VOC2012/JPEGImages/'\n",
    "    voc_path = 'data/VOCdevkit/VOC2012'\n",
    "    rand_crop_size = 300\n",
    "    bs = 16 # Batch size not bullshit\n",
    "    epochs = 5\n",
    "\n",
    "    tr = transforms.Compose([transforms.RandomResizedCrop(rand_crop_size),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize([0.4589, 0.4355, 0.4032],[0.2239, 0.2186, 0.2206])])\n",
    "\n",
    "    ###### Create datasets and respective dataloaders ######\n",
    "    pvc = PascalVOCLabelLoader(voc_path)\n",
    "    \n",
    "    train_dataset = PascalVOCDataset(imgpath, class_list, pvc, 'train', transform=tr)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
    "\n",
    "    val_dataset = PascalVOCDataset(imgpath, class_list, pvc, 'trainval', transform=tr)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=bs, shuffle=True)\n",
    "\n",
    "    test_dataset = PascalVOCDataset(imgpath, class_list, pvc, 'val', transform=tr)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=bs, shuffle=True)\n",
    "\n",
    "    ###### Model Parameters ######\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = nn.Linear(512, len(class_list))\n",
    "    model.to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    loss_fun = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    ###### Start Taining ######\n",
    "    start = time.time()\n",
    "    train_losses, train_ap_scores, val_losses, val_ap_scores = train_epoch(model, device, train_loader, optimizer, epochs, val_loader, loss_fun, class_list)\n",
    "    print(f'Total training taken: {time.time() - start}')\n",
    "\n",
    "    ###### Plot Loss and mean AP score of training and validation dataset ######\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.subplot(121),\n",
    "    plt.plot(train_losses, label = \"Training Loss\"),\n",
    "    plt.plot(val_losses, label = \"Validation Loss\"),\n",
    "    plt.title('Loss'),\n",
    "    plt.legend(frameon = False)\n",
    "    plt.subplot(122),\n",
    "    plt.plot(train_ap_scores, label = \"Training Mean AP Score\"),\n",
    "    plt.plot(val_ap_scores, label = \"Validation Mean AP Score\"),\n",
    "    plt.title('Mean AP Score'),\n",
    "    plt.legend(frameon = False)\n",
    "    plt.show()\n",
    "\n",
    "    ###### Run the test function and get the respective predictions, targets and impage paths ######\n",
    "    test_predictions, test_targets, test_image_paths = test(model, device, test_loader, loss_fun, class_list)\n",
    "\n",
    "    # Randomly pick 5 classes\n",
    "    np.random.seed(10)\n",
    "    random_classes = np.random.choice(range(len(class_list)), 5, replace=False)\n",
    "\n",
    "    # Each of these contains 5 lists, that contain [class_number, [array of image_names]]\n",
    "    t_images_all = []\n",
    "    b_images_all = []\n",
    "    \n",
    "    # Store the sorted list of images based on scores with their respective class\n",
    "    for x in random_classes:\n",
    "        t_images, b_images, _ = top_bot_scores_50(test_image_paths, test_predictions, x)\n",
    "        t_images_all.append([x, t_images])\n",
    "        b_images_all.append([x, b_images])\n",
    "\n",
    "    ###### Plot the top 50 highest and lowest images ######\n",
    "    # Display top 50 images random 5 classes\n",
    "    plot_top_images(t_images_all, imgpath, tr, class_list, \"highest\")\n",
    "\n",
    "    # Display bottom 50 images random 5 classes\n",
    "    plot_top_images(b_images_all, imgpath, tr, class_list, \"lowest\")\n",
    "\n",
    "    # Define variables for calculating tail accuracies\n",
    "    tail_acc_classwise = []\n",
    "    t_max = np.max(test_predictions.numpy())\n",
    "    t_min=0.5\n",
    "    t_num=20\n",
    "    t_vals = np.linspace(t_min, t_max, t_num, endpoint=False)\n",
    "    \n",
    "    ###### Calculate Tail Accuracy for all classes ######\n",
    "    for i in range(len(class_list)):\n",
    "        _, _, reorder = top_bot_scores_50(test_image_paths, test_predictions, i)\n",
    "        sorted_predictions = np.copy(test_predictions.cpu())[reorder]\n",
    "        sorted_predictions = sorted_predictions[:50, i]\n",
    "        sorted_targets = np.copy(test_targets.cpu())[reorder]\n",
    "        sorted_targets = sorted_targets[:50, i]\n",
    "\n",
    "        tail_acc_classwise.append(get_tail_acc(sorted_predictions, sorted_targets, t_min, t_max, t_num, t_vals))\n",
    "\n",
    "    ###### Plot average tail accuracy of all classes ######\n",
    "    avg_tail_acc = np.mean(tail_acc_classwise, axis=0)\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(t_vals, avg_tail_acc, 'b', t_vals, avg_tail_acc, 'ro')\n",
    "    plt.xticks(t_vals)\n",
    "    plt.title('Average of classwise tail accuraries over top-50 ranked images in each class')\n",
    "    plt.ylabel('Tail Accuracy')\n",
    "    plt.xlabel('t value')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-edfdb1a7b49b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-5fa40fa0aed1>\u001b[0m in \u001b[0;36mrun\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;31m###### Start Taining ######\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_ap_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ap_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Total training taken: {time.time() - start}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-db7fd0171263>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(model, device, train_loader, optimizer, num_epochs, val_loader, loss_fun, class_list)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'\\nEpoch: {epoch}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_ap_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ap_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-af91a45330d0>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, device, train_loader, optimizer, epoch, loss_fun, class_list)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             print(f'Epoch: {epoch}, Training_Samples: {idx}/{len(train_loader)}, Loss: {loss.item()},\\\n\u001b[1;32m---> 25\u001b[1;33m             Total AP: {ap(targets, predictions, len(class_list)):.4f}')\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-27b6c83c05ef>\u001b[0m in \u001b[0;36map\u001b[1;34m(targets, predictions, num_classes)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\humantorch\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36maverage_precision_score\u001b[1;34m(y_true, y_score, average, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    213\u001b[0m                                 pos_label=pos_label)\n\u001b[0;32m    214\u001b[0m     return _average_binary_score(average_precision, y_true, y_score,\n\u001b[1;32m--> 215\u001b[1;33m                                  average, sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\humantorch\\lib\\site-packages\\sklearn\\metrics\\_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[0my_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[0mnot_average_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\humantorch\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\humantorch\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\humantorch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
